{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"..\") \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.utility import *\n",
    "from src.dataprocessing import *\n",
    "from src import rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "input_var   = [\"FT-3061-2\", \"FT-3061-3\", \"FT-3061-4\", \"FT-3062-1\"]\n",
    "output_var  = [\"TT-3061-3\", \"TT-3061-5\", \"LT-3061-2\"]\n",
    "process_var = input_var + output_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_1.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_2.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_3.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_4.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_5.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_6.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_7.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_8.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_9.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_10.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_11.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_12.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_13.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_14.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_15.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_16.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_17.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_18.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_19.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_20.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_21.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_22.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_23.csv\n",
      "csv file is loaded from ./data/3_continuous/cts_100/dataset 100_24.csv\n"
     ]
    }
   ],
   "source": [
    "min_len = 100\n",
    "continuous_path = './data/3_continuous'\n",
    "\n",
    "cts_list = []\n",
    "i = 1\n",
    "while exists(continuous_path, f\"cts_{min_len}/dataset {min_len}_{i}\", 'csv'):\n",
    "    cts_df = loadfile(continuous_path, f\"cts_{min_len}/dataset {min_len}_{i}\", 'csv')\n",
    "    cts_list.append(cts_df)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history size: 10\n",
      "future size: 10\n",
      "Epoch 1/10000\n",
      "581/581 - 10s - loss: 0.2449 - val_loss: 0.1585 - 10s/epoch - 17ms/step\n",
      "Epoch 2/10000\n",
      "581/581 - 5s - loss: 0.1506 - val_loss: 0.1376 - 5s/epoch - 8ms/step\n",
      "Epoch 3/10000\n",
      "581/581 - 5s - loss: 0.1410 - val_loss: 0.1411 - 5s/epoch - 8ms/step\n",
      "Epoch 4/10000\n",
      "581/581 - 5s - loss: 0.1324 - val_loss: 0.1270 - 5s/epoch - 8ms/step\n",
      "Epoch 5/10000\n",
      "581/581 - 5s - loss: 0.1238 - val_loss: 0.1136 - 5s/epoch - 8ms/step\n",
      "Epoch 6/10000\n",
      "581/581 - 5s - loss: 0.1181 - val_loss: 0.1062 - 5s/epoch - 8ms/step\n",
      "Epoch 7/10000\n",
      "581/581 - 5s - loss: 0.1126 - val_loss: 0.1048 - 5s/epoch - 8ms/step\n",
      "Epoch 8/10000\n",
      "581/581 - 5s - loss: 0.1078 - val_loss: 0.0990 - 5s/epoch - 9ms/step\n",
      "Epoch 9/10000\n",
      "581/581 - 5s - loss: 0.1030 - val_loss: 0.0992 - 5s/epoch - 9ms/step\n",
      "Epoch 10/10000\n",
      "581/581 - 5s - loss: 0.1003 - val_loss: 0.0938 - 5s/epoch - 9ms/step\n",
      "Epoch 11/10000\n",
      "581/581 - 5s - loss: 0.0970 - val_loss: 0.0921 - 5s/epoch - 9ms/step\n",
      "Epoch 12/10000\n",
      "581/581 - 5s - loss: 0.0950 - val_loss: 0.0941 - 5s/epoch - 8ms/step\n",
      "Epoch 13/10000\n",
      "581/581 - 5s - loss: 0.0918 - val_loss: 0.0868 - 5s/epoch - 9ms/step\n",
      "Epoch 14/10000\n",
      "581/581 - 5s - loss: 0.0913 - val_loss: 0.0878 - 5s/epoch - 8ms/step\n",
      "Epoch 15/10000\n",
      "581/581 - 5s - loss: 0.0892 - val_loss: 0.0871 - 5s/epoch - 8ms/step\n",
      "Epoch 16/10000\n",
      "581/581 - 5s - loss: 0.0862 - val_loss: 0.0843 - 5s/epoch - 8ms/step\n",
      "Epoch 17/10000\n",
      "581/581 - 5s - loss: 0.0831 - val_loss: 0.0907 - 5s/epoch - 8ms/step\n",
      "Epoch 18/10000\n",
      "581/581 - 5s - loss: 0.0804 - val_loss: 0.0872 - 5s/epoch - 8ms/step\n",
      "Epoch 19/10000\n",
      "581/581 - 5s - loss: 0.0827 - val_loss: 0.0819 - 5s/epoch - 8ms/step\n",
      "Epoch 20/10000\n",
      "581/581 - 5s - loss: 0.0791 - val_loss: 0.0796 - 5s/epoch - 8ms/step\n",
      "Epoch 21/10000\n",
      "581/581 - 5s - loss: 0.0764 - val_loss: 0.0833 - 5s/epoch - 9ms/step\n",
      "Epoch 22/10000\n",
      "581/581 - 5s - loss: 0.0761 - val_loss: 0.0802 - 5s/epoch - 9ms/step\n",
      "Epoch 23/10000\n",
      "581/581 - 5s - loss: 0.0753 - val_loss: 0.0791 - 5s/epoch - 8ms/step\n",
      "Epoch 24/10000\n",
      "581/581 - 5s - loss: 0.0749 - val_loss: 0.0779 - 5s/epoch - 8ms/step\n",
      "Epoch 25/10000\n",
      "581/581 - 5s - loss: 0.0732 - val_loss: 0.0840 - 5s/epoch - 8ms/step\n",
      "Epoch 26/10000\n",
      "581/581 - 5s - loss: 0.0709 - val_loss: 0.0741 - 5s/epoch - 8ms/step\n",
      "Epoch 27/10000\n",
      "581/581 - 4s - loss: 0.0717 - val_loss: 0.0759 - 4s/epoch - 7ms/step\n",
      "Epoch 28/10000\n",
      "581/581 - 4s - loss: 0.0682 - val_loss: 0.0790 - 4s/epoch - 7ms/step\n",
      "Epoch 29/10000\n",
      "581/581 - 4s - loss: 0.0685 - val_loss: 0.0792 - 4s/epoch - 7ms/step\n",
      "Epoch 30/10000\n",
      "581/581 - 4s - loss: 0.0686 - val_loss: 0.0760 - 4s/epoch - 7ms/step\n",
      "Epoch 31/10000\n",
      "581/581 - 4s - loss: 0.0662 - val_loss: 0.0765 - 4s/epoch - 8ms/step\n",
      "Epoch 32/10000\n",
      "581/581 - 4s - loss: 0.0676 - val_loss: 0.0819 - 4s/epoch - 8ms/step\n",
      "Epoch 33/10000\n",
      "581/581 - 4s - loss: 0.0650 - val_loss: 0.0745 - 4s/epoch - 8ms/step\n",
      "Epoch 34/10000\n",
      "581/581 - 4s - loss: 0.0651 - val_loss: 0.0763 - 4s/epoch - 8ms/step\n",
      "Epoch 35/10000\n",
      "581/581 - 4s - loss: 0.0629 - val_loss: 0.0739 - 4s/epoch - 8ms/step\n",
      "Epoch 36/10000\n",
      "581/581 - 4s - loss: 0.0616 - val_loss: 0.0739 - 4s/epoch - 7ms/step\n",
      "Epoch 37/10000\n",
      "581/581 - 4s - loss: 0.0630 - val_loss: 0.0721 - 4s/epoch - 8ms/step\n",
      "Epoch 38/10000\n",
      "581/581 - 4s - loss: 0.0618 - val_loss: 0.0757 - 4s/epoch - 8ms/step\n",
      "Epoch 39/10000\n",
      "581/581 - 4s - loss: 0.0629 - val_loss: 0.0745 - 4s/epoch - 8ms/step\n",
      "Epoch 40/10000\n",
      "581/581 - 4s - loss: 0.0604 - val_loss: 0.0698 - 4s/epoch - 8ms/step\n",
      "Epoch 41/10000\n",
      "581/581 - 4s - loss: 0.0598 - val_loss: 0.0685 - 4s/epoch - 8ms/step\n",
      "Epoch 42/10000\n",
      "581/581 - 5s - loss: 0.0578 - val_loss: 0.0707 - 5s/epoch - 8ms/step\n",
      "Epoch 43/10000\n",
      "581/581 - 4s - loss: 0.0570 - val_loss: 0.0725 - 4s/epoch - 8ms/step\n",
      "Epoch 44/10000\n",
      "581/581 - 4s - loss: 0.0632 - val_loss: 0.0718 - 4s/epoch - 8ms/step\n",
      "Epoch 45/10000\n",
      "581/581 - 4s - loss: 0.0573 - val_loss: 0.0700 - 4s/epoch - 8ms/step\n",
      "Epoch 46/10000\n",
      "581/581 - 4s - loss: 0.0545 - val_loss: 0.0709 - 4s/epoch - 8ms/step\n",
      "Epoch 47/10000\n",
      "581/581 - 4s - loss: 0.0599 - val_loss: 0.0715 - 4s/epoch - 8ms/step\n",
      "Epoch 48/10000\n",
      "581/581 - 5s - loss: 0.0573 - val_loss: 0.0704 - 5s/epoch - 8ms/step\n",
      "Epoch 49/10000\n",
      "581/581 - 5s - loss: 0.0558 - val_loss: 0.0710 - 5s/epoch - 8ms/step\n",
      "Epoch 50/10000\n",
      "581/581 - 5s - loss: 0.0555 - val_loss: 0.0673 - 5s/epoch - 8ms/step\n",
      "Epoch 51/10000\n",
      "581/581 - 5s - loss: 0.0543 - val_loss: 0.0691 - 5s/epoch - 8ms/step\n",
      "Epoch 52/10000\n",
      "581/581 - 5s - loss: 0.0559 - val_loss: 0.0679 - 5s/epoch - 8ms/step\n",
      "Epoch 53/10000\n",
      "581/581 - 5s - loss: 0.0547 - val_loss: 0.0686 - 5s/epoch - 8ms/step\n",
      "Epoch 54/10000\n",
      "581/581 - 5s - loss: 0.0517 - val_loss: 0.0672 - 5s/epoch - 8ms/step\n",
      "Epoch 55/10000\n",
      "581/581 - 5s - loss: 0.0516 - val_loss: 0.0686 - 5s/epoch - 8ms/step\n",
      "Epoch 56/10000\n",
      "581/581 - 5s - loss: 0.0517 - val_loss: 0.0672 - 5s/epoch - 8ms/step\n",
      "Epoch 57/10000\n",
      "581/581 - 5s - loss: 0.0534 - val_loss: 0.0695 - 5s/epoch - 8ms/step\n",
      "Epoch 58/10000\n",
      "581/581 - 5s - loss: 0.0527 - val_loss: 0.0660 - 5s/epoch - 8ms/step\n",
      "Epoch 59/10000\n",
      "581/581 - 5s - loss: 0.0520 - val_loss: 0.0687 - 5s/epoch - 8ms/step\n",
      "Epoch 60/10000\n",
      "581/581 - 5s - loss: 0.0511 - val_loss: 0.0657 - 5s/epoch - 8ms/step\n",
      "Epoch 61/10000\n",
      "581/581 - 5s - loss: 0.0488 - val_loss: 0.0665 - 5s/epoch - 8ms/step\n",
      "Epoch 62/10000\n",
      "581/581 - 5s - loss: 0.0515 - val_loss: 0.0665 - 5s/epoch - 8ms/step\n",
      "Epoch 63/10000\n",
      "581/581 - 5s - loss: 0.0491 - val_loss: 0.0632 - 5s/epoch - 8ms/step\n",
      "Epoch 64/10000\n",
      "581/581 - 5s - loss: 0.0488 - val_loss: 0.0658 - 5s/epoch - 8ms/step\n",
      "Epoch 65/10000\n",
      "581/581 - 5s - loss: 0.0506 - val_loss: 0.0645 - 5s/epoch - 8ms/step\n",
      "Epoch 66/10000\n",
      "581/581 - 5s - loss: 0.0500 - val_loss: 0.0660 - 5s/epoch - 8ms/step\n",
      "Epoch 67/10000\n",
      "581/581 - 5s - loss: 0.0496 - val_loss: 0.0631 - 5s/epoch - 8ms/step\n",
      "Epoch 68/10000\n",
      "581/581 - 5s - loss: 0.0485 - val_loss: 0.0636 - 5s/epoch - 8ms/step\n",
      "Epoch 69/10000\n",
      "581/581 - 5s - loss: 0.0491 - val_loss: 0.0651 - 5s/epoch - 8ms/step\n",
      "Epoch 70/10000\n",
      "581/581 - 5s - loss: 0.0492 - val_loss: 0.0697 - 5s/epoch - 8ms/step\n",
      "Epoch 71/10000\n",
      "581/581 - 5s - loss: 0.0467 - val_loss: 0.0614 - 5s/epoch - 8ms/step\n",
      "Epoch 72/10000\n",
      "581/581 - 5s - loss: 0.0452 - val_loss: 0.0645 - 5s/epoch - 8ms/step\n",
      "Epoch 73/10000\n",
      "581/581 - 5s - loss: 0.0456 - val_loss: 0.0629 - 5s/epoch - 8ms/step\n",
      "Epoch 74/10000\n",
      "581/581 - 5s - loss: 0.0464 - val_loss: 0.0655 - 5s/epoch - 8ms/step\n",
      "Epoch 75/10000\n",
      "581/581 - 5s - loss: 0.0464 - val_loss: 0.0671 - 5s/epoch - 8ms/step\n",
      "Epoch 76/10000\n",
      "581/581 - 5s - loss: 0.0462 - val_loss: 0.0656 - 5s/epoch - 8ms/step\n",
      "Epoch 77/10000\n",
      "581/581 - 5s - loss: 0.0464 - val_loss: 0.0653 - 5s/epoch - 8ms/step\n",
      "Epoch 78/10000\n",
      "581/581 - 5s - loss: 0.0443 - val_loss: 0.0635 - 5s/epoch - 8ms/step\n",
      "Epoch 79/10000\n",
      "581/581 - 5s - loss: 0.0454 - val_loss: 0.0620 - 5s/epoch - 8ms/step\n",
      "Epoch 80/10000\n",
      "581/581 - 5s - loss: 0.0440 - val_loss: 0.0624 - 5s/epoch - 8ms/step\n",
      "Epoch 81/10000\n",
      "581/581 - 5s - loss: 0.0449 - val_loss: 0.0628 - 5s/epoch - 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/10_10_1_50_1_50_datt_seq2seq_gru_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/10_10_1_50_1_50_datt_seq2seq_gru_test\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7D68BFC40> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7876BC7F0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.94855</td>\n",
       "      <td>0.954594</td>\n",
       "      <td>0.967859</td>\n",
       "      <td>0.957001</td>\n",
       "      <td>3.682886</td>\n",
       "      <td>3.726303</td>\n",
       "      <td>2.795242</td>\n",
       "      <td>3.401477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.878513</td>\n",
       "      <td>0.904571</td>\n",
       "      <td>0.918817</td>\n",
       "      <td>0.900634</td>\n",
       "      <td>5.623009</td>\n",
       "      <td>5.402695</td>\n",
       "      <td>4.441325</td>\n",
       "      <td>5.155677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.784107</td>\n",
       "      <td>0.855841</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.831423</td>\n",
       "      <td>7.393895</td>\n",
       "      <td>6.640935</td>\n",
       "      <td>5.948003</td>\n",
       "      <td>6.660944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.685083</td>\n",
       "      <td>0.816574</td>\n",
       "      <td>0.8042</td>\n",
       "      <td>0.768619</td>\n",
       "      <td>8.811611</td>\n",
       "      <td>7.492033</td>\n",
       "      <td>6.893932</td>\n",
       "      <td>7.732525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.587953</td>\n",
       "      <td>0.784423</td>\n",
       "      <td>0.779874</td>\n",
       "      <td>0.717416</td>\n",
       "      <td>9.980797</td>\n",
       "      <td>8.123277</td>\n",
       "      <td>7.307314</td>\n",
       "      <td>8.470463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4959</td>\n",
       "      <td>0.761174</td>\n",
       "      <td>0.774487</td>\n",
       "      <td>0.677187</td>\n",
       "      <td>10.933266</td>\n",
       "      <td>8.551523</td>\n",
       "      <td>7.394329</td>\n",
       "      <td>8.959706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.408534</td>\n",
       "      <td>0.744815</td>\n",
       "      <td>0.776359</td>\n",
       "      <td>0.643236</td>\n",
       "      <td>11.730636</td>\n",
       "      <td>8.840315</td>\n",
       "      <td>7.362248</td>\n",
       "      <td>9.311066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.328695</td>\n",
       "      <td>0.730533</td>\n",
       "      <td>0.777887</td>\n",
       "      <td>0.612371</td>\n",
       "      <td>12.467636</td>\n",
       "      <td>9.084667</td>\n",
       "      <td>7.33633</td>\n",
       "      <td>9.629545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.259053</td>\n",
       "      <td>0.717671</td>\n",
       "      <td>0.772577</td>\n",
       "      <td>0.583101</td>\n",
       "      <td>13.113544</td>\n",
       "      <td>9.299384</td>\n",
       "      <td>7.422933</td>\n",
       "      <td>9.945287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.198222</td>\n",
       "      <td>0.702301</td>\n",
       "      <td>0.753908</td>\n",
       "      <td>0.551477</td>\n",
       "      <td>13.657252</td>\n",
       "      <td>9.549454</td>\n",
       "      <td>7.721044</td>\n",
       "      <td>10.30925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.557461</td>\n",
       "      <td>0.79725</td>\n",
       "      <td>0.818029</td>\n",
       "      <td>0.724247</td>\n",
       "      <td>9.739453</td>\n",
       "      <td>7.671059</td>\n",
       "      <td>6.46227</td>\n",
       "      <td>7.957594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TT-3061-3 TT-3061-5 LT-3061-2      mean  TT-3061-3 TT-3061-5 LT-3061-2  \\\n",
       "index        R2        R2        R2        R2      nRMSE     nRMSE     nRMSE   \n",
       "0       0.94855  0.954594  0.967859  0.957001   3.682886  3.726303  2.795242   \n",
       "1      0.878513  0.904571  0.918817  0.900634   5.623009  5.402695  4.441325   \n",
       "2      0.784107  0.855841  0.854321  0.831423   7.393895  6.640935  5.948003   \n",
       "3      0.685083  0.816574    0.8042  0.768619   8.811611  7.492033  6.893932   \n",
       "4      0.587953  0.784423  0.779874  0.717416   9.980797  8.123277  7.307314   \n",
       "5        0.4959  0.761174  0.774487  0.677187  10.933266  8.551523  7.394329   \n",
       "6      0.408534  0.744815  0.776359  0.643236  11.730636  8.840315  7.362248   \n",
       "7      0.328695  0.730533  0.777887  0.612371  12.467636  9.084667   7.33633   \n",
       "8      0.259053  0.717671  0.772577  0.583101  13.113544  9.299384  7.422933   \n",
       "9      0.198222  0.702301  0.753908  0.551477  13.657252  9.549454  7.721044   \n",
       "mean   0.557461   0.79725  0.818029  0.724247   9.739453  7.671059   6.46227   \n",
       "\n",
       "           mean  \n",
       "index     nRMSE  \n",
       "0      3.401477  \n",
       "1      5.155677  \n",
       "2      6.660944  \n",
       "3      7.732525  \n",
       "4      8.470463  \n",
       "5      8.959706  \n",
       "6      9.311066  \n",
       "7      9.629545  \n",
       "8      9.945287  \n",
       "9      10.30925  \n",
       "mean   7.957594  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history size: 10\n",
      "future size: 20\n",
      "Epoch 1/10000\n",
      "577/577 - 8s - loss: 0.3112 - val_loss: 0.2645 - 8s/epoch - 14ms/step\n",
      "Epoch 2/10000\n",
      "577/577 - 5s - loss: 0.2273 - val_loss: 0.2372 - 5s/epoch - 8ms/step\n",
      "Epoch 3/10000\n",
      "577/577 - 4s - loss: 0.2123 - val_loss: 0.2300 - 4s/epoch - 8ms/step\n",
      "Epoch 4/10000\n",
      "577/577 - 4s - loss: 0.2036 - val_loss: 0.2134 - 4s/epoch - 7ms/step\n",
      "Epoch 5/10000\n",
      "577/577 - 4s - loss: 0.1929 - val_loss: 0.2111 - 4s/epoch - 7ms/step\n",
      "Epoch 6/10000\n",
      "577/577 - 4s - loss: 0.1854 - val_loss: 0.1975 - 4s/epoch - 7ms/step\n",
      "Epoch 7/10000\n",
      "577/577 - 4s - loss: 0.1775 - val_loss: 0.1913 - 4s/epoch - 7ms/step\n",
      "Epoch 8/10000\n",
      "577/577 - 4s - loss: 0.1723 - val_loss: 0.1910 - 4s/epoch - 7ms/step\n",
      "Epoch 9/10000\n",
      "577/577 - 4s - loss: 0.1655 - val_loss: 0.1822 - 4s/epoch - 7ms/step\n",
      "Epoch 10/10000\n",
      "577/577 - 4s - loss: 0.1613 - val_loss: 0.1812 - 4s/epoch - 7ms/step\n",
      "Epoch 11/10000\n",
      "577/577 - 4s - loss: 0.1555 - val_loss: 0.1699 - 4s/epoch - 7ms/step\n",
      "Epoch 12/10000\n",
      "577/577 - 4s - loss: 0.1500 - val_loss: 0.1646 - 4s/epoch - 7ms/step\n",
      "Epoch 13/10000\n",
      "577/577 - 4s - loss: 0.1457 - val_loss: 0.1636 - 4s/epoch - 7ms/step\n",
      "Epoch 14/10000\n",
      "577/577 - 4s - loss: 0.1413 - val_loss: 0.1577 - 4s/epoch - 7ms/step\n",
      "Epoch 15/10000\n",
      "577/577 - 4s - loss: 0.1358 - val_loss: 0.1617 - 4s/epoch - 8ms/step\n",
      "Epoch 16/10000\n",
      "577/577 - 4s - loss: 0.1398 - val_loss: 0.1587 - 4s/epoch - 8ms/step\n",
      "Epoch 17/10000\n",
      "577/577 - 4s - loss: 0.1292 - val_loss: 0.1490 - 4s/epoch - 8ms/step\n",
      "Epoch 18/10000\n",
      "577/577 - 4s - loss: 0.1270 - val_loss: 0.1437 - 4s/epoch - 7ms/step\n",
      "Epoch 19/10000\n",
      "577/577 - 5s - loss: 0.1259 - val_loss: 0.1421 - 5s/epoch - 8ms/step\n",
      "Epoch 20/10000\n",
      "577/577 - 4s - loss: 0.1203 - val_loss: 0.1392 - 4s/epoch - 7ms/step\n",
      "Epoch 21/10000\n",
      "577/577 - 4s - loss: 0.1188 - val_loss: 0.1352 - 4s/epoch - 7ms/step\n",
      "Epoch 22/10000\n",
      "577/577 - 4s - loss: 0.1153 - val_loss: 0.1348 - 4s/epoch - 8ms/step\n",
      "Epoch 23/10000\n",
      "577/577 - 4s - loss: 0.1175 - val_loss: 0.1368 - 4s/epoch - 8ms/step\n",
      "Epoch 24/10000\n",
      "577/577 - 4s - loss: 0.1115 - val_loss: 0.1297 - 4s/epoch - 8ms/step\n",
      "Epoch 25/10000\n",
      "577/577 - 4s - loss: 0.1104 - val_loss: 0.1300 - 4s/epoch - 7ms/step\n",
      "Epoch 26/10000\n",
      "577/577 - 4s - loss: 0.1056 - val_loss: 0.1308 - 4s/epoch - 7ms/step\n",
      "Epoch 27/10000\n",
      "577/577 - 4s - loss: 0.1068 - val_loss: 0.1231 - 4s/epoch - 7ms/step\n",
      "Epoch 28/10000\n",
      "577/577 - 4s - loss: 0.1052 - val_loss: 0.1270 - 4s/epoch - 8ms/step\n",
      "Epoch 29/10000\n",
      "577/577 - 4s - loss: 0.1034 - val_loss: 0.1204 - 4s/epoch - 7ms/step\n",
      "Epoch 30/10000\n",
      "577/577 - 4s - loss: 0.1039 - val_loss: 0.1224 - 4s/epoch - 8ms/step\n",
      "Epoch 31/10000\n",
      "577/577 - 4s - loss: 0.1015 - val_loss: 0.1188 - 4s/epoch - 8ms/step\n",
      "Epoch 32/10000\n",
      "577/577 - 4s - loss: 0.0996 - val_loss: 0.1212 - 4s/epoch - 7ms/step\n",
      "Epoch 33/10000\n",
      "577/577 - 4s - loss: 0.0977 - val_loss: 0.1197 - 4s/epoch - 7ms/step\n",
      "Epoch 34/10000\n",
      "577/577 - 4s - loss: 0.0951 - val_loss: 0.1132 - 4s/epoch - 8ms/step\n",
      "Epoch 35/10000\n",
      "577/577 - 4s - loss: 0.1017 - val_loss: 0.1185 - 4s/epoch - 7ms/step\n",
      "Epoch 36/10000\n",
      "577/577 - 4s - loss: 0.0943 - val_loss: 0.1167 - 4s/epoch - 7ms/step\n",
      "Epoch 37/10000\n",
      "577/577 - 4s - loss: 0.0950 - val_loss: 0.1103 - 4s/epoch - 7ms/step\n",
      "Epoch 38/10000\n",
      "577/577 - 4s - loss: 0.0919 - val_loss: 0.1069 - 4s/epoch - 8ms/step\n",
      "Epoch 39/10000\n",
      "577/577 - 4s - loss: 0.0932 - val_loss: 0.1185 - 4s/epoch - 7ms/step\n",
      "Epoch 40/10000\n",
      "577/577 - 4s - loss: 0.0916 - val_loss: 0.1080 - 4s/epoch - 7ms/step\n",
      "Epoch 41/10000\n",
      "577/577 - 4s - loss: 0.0898 - val_loss: 0.1083 - 4s/epoch - 8ms/step\n",
      "Epoch 42/10000\n",
      "577/577 - 4s - loss: 0.0887 - val_loss: 0.1101 - 4s/epoch - 7ms/step\n",
      "Epoch 43/10000\n",
      "577/577 - 4s - loss: 0.0891 - val_loss: 0.1105 - 4s/epoch - 7ms/step\n",
      "Epoch 44/10000\n",
      "577/577 - 4s - loss: 0.0881 - val_loss: 0.1084 - 4s/epoch - 8ms/step\n",
      "Epoch 45/10000\n",
      "577/577 - 4s - loss: 0.0859 - val_loss: 0.1077 - 4s/epoch - 7ms/step\n",
      "Epoch 46/10000\n",
      "577/577 - 4s - loss: 0.0843 - val_loss: 0.1050 - 4s/epoch - 7ms/step\n",
      "Epoch 47/10000\n",
      "577/577 - 4s - loss: 0.0835 - val_loss: 0.1060 - 4s/epoch - 7ms/step\n",
      "Epoch 48/10000\n",
      "577/577 - 4s - loss: 0.0839 - val_loss: 0.1072 - 4s/epoch - 7ms/step\n",
      "Epoch 49/10000\n",
      "577/577 - 4s - loss: 0.0863 - val_loss: 0.1034 - 4s/epoch - 8ms/step\n",
      "Epoch 50/10000\n",
      "577/577 - 4s - loss: 0.0819 - val_loss: 0.1013 - 4s/epoch - 8ms/step\n",
      "Epoch 51/10000\n",
      "577/577 - 4s - loss: 0.0814 - val_loss: 0.1030 - 4s/epoch - 7ms/step\n",
      "Epoch 52/10000\n",
      "577/577 - 4s - loss: 0.0816 - val_loss: 0.1038 - 4s/epoch - 7ms/step\n",
      "Epoch 53/10000\n",
      "577/577 - 5s - loss: 0.0798 - val_loss: 0.0995 - 5s/epoch - 8ms/step\n",
      "Epoch 54/10000\n",
      "577/577 - 4s - loss: 0.0806 - val_loss: 0.0994 - 4s/epoch - 8ms/step\n",
      "Epoch 55/10000\n",
      "577/577 - 4s - loss: 0.0812 - val_loss: 0.1057 - 4s/epoch - 7ms/step\n",
      "Epoch 56/10000\n",
      "577/577 - 4s - loss: 0.0818 - val_loss: 0.1146 - 4s/epoch - 7ms/step\n",
      "Epoch 57/10000\n",
      "577/577 - 4s - loss: 0.0813 - val_loss: 0.1015 - 4s/epoch - 7ms/step\n",
      "Epoch 58/10000\n",
      "577/577 - 4s - loss: 0.0774 - val_loss: 0.0984 - 4s/epoch - 7ms/step\n",
      "Epoch 59/10000\n",
      "577/577 - 4s - loss: 0.0787 - val_loss: 0.0997 - 4s/epoch - 8ms/step\n",
      "Epoch 60/10000\n",
      "577/577 - 5s - loss: 0.0767 - val_loss: 0.0961 - 5s/epoch - 8ms/step\n",
      "Epoch 61/10000\n",
      "577/577 - 4s - loss: 0.0777 - val_loss: 0.1016 - 4s/epoch - 7ms/step\n",
      "Epoch 62/10000\n",
      "577/577 - 4s - loss: 0.0751 - val_loss: 0.1021 - 4s/epoch - 8ms/step\n",
      "Epoch 63/10000\n",
      "577/577 - 4s - loss: 0.0759 - val_loss: 0.0979 - 4s/epoch - 7ms/step\n",
      "Epoch 64/10000\n",
      "577/577 - 4s - loss: 0.0803 - val_loss: 0.1051 - 4s/epoch - 8ms/step\n",
      "Epoch 65/10000\n",
      "577/577 - 4s - loss: 0.0762 - val_loss: 0.0938 - 4s/epoch - 8ms/step\n",
      "Epoch 66/10000\n",
      "577/577 - 4s - loss: 0.0748 - val_loss: 0.1030 - 4s/epoch - 7ms/step\n",
      "Epoch 67/10000\n",
      "577/577 - 4s - loss: 0.0771 - val_loss: 0.0940 - 4s/epoch - 7ms/step\n",
      "Epoch 68/10000\n",
      "577/577 - 4s - loss: 0.0731 - val_loss: 0.0952 - 4s/epoch - 8ms/step\n",
      "Epoch 69/10000\n",
      "577/577 - 4s - loss: 0.0725 - val_loss: 0.0908 - 4s/epoch - 7ms/step\n",
      "Epoch 70/10000\n",
      "577/577 - 4s - loss: 0.0705 - val_loss: 0.0974 - 4s/epoch - 8ms/step\n",
      "Epoch 71/10000\n",
      "577/577 - 4s - loss: 0.0719 - val_loss: 0.0965 - 4s/epoch - 8ms/step\n",
      "Epoch 72/10000\n",
      "577/577 - 4s - loss: 0.0720 - val_loss: 0.0945 - 4s/epoch - 8ms/step\n",
      "Epoch 73/10000\n",
      "577/577 - 4s - loss: 0.0708 - val_loss: 0.0904 - 4s/epoch - 7ms/step\n",
      "Epoch 74/10000\n",
      "577/577 - 4s - loss: 0.0718 - val_loss: 0.0917 - 4s/epoch - 7ms/step\n",
      "Epoch 75/10000\n",
      "577/577 - 4s - loss: 0.0701 - val_loss: 0.0940 - 4s/epoch - 7ms/step\n",
      "Epoch 76/10000\n",
      "577/577 - 4s - loss: 0.0704 - val_loss: 0.0878 - 4s/epoch - 7ms/step\n",
      "Epoch 77/10000\n",
      "577/577 - 4s - loss: 0.0686 - val_loss: 0.0905 - 4s/epoch - 8ms/step\n",
      "Epoch 78/10000\n",
      "577/577 - 4s - loss: 0.0723 - val_loss: 0.0985 - 4s/epoch - 7ms/step\n",
      "Epoch 79/10000\n",
      "577/577 - 4s - loss: 0.0707 - val_loss: 0.0992 - 4s/epoch - 7ms/step\n",
      "Epoch 80/10000\n",
      "577/577 - 4s - loss: 0.0737 - val_loss: 0.0983 - 4s/epoch - 7ms/step\n",
      "Epoch 81/10000\n",
      "577/577 - 4s - loss: 0.0683 - val_loss: 0.0907 - 4s/epoch - 7ms/step\n",
      "Epoch 82/10000\n",
      "577/577 - 4s - loss: 0.0662 - val_loss: 0.0868 - 4s/epoch - 7ms/step\n",
      "Epoch 83/10000\n",
      "577/577 - 4s - loss: 0.0701 - val_loss: 0.0910 - 4s/epoch - 8ms/step\n",
      "Epoch 84/10000\n",
      "577/577 - 4s - loss: 0.0685 - val_loss: 0.0885 - 4s/epoch - 8ms/step\n",
      "Epoch 85/10000\n",
      "577/577 - 4s - loss: 0.0641 - val_loss: 0.0900 - 4s/epoch - 7ms/step\n",
      "Epoch 86/10000\n",
      "577/577 - 4s - loss: 0.0664 - val_loss: 0.0914 - 4s/epoch - 8ms/step\n",
      "Epoch 87/10000\n",
      "577/577 - 4s - loss: 0.0647 - val_loss: 0.0932 - 4s/epoch - 7ms/step\n",
      "Epoch 88/10000\n",
      "577/577 - 4s - loss: 0.0673 - val_loss: 0.0891 - 4s/epoch - 7ms/step\n",
      "Epoch 89/10000\n",
      "577/577 - 4s - loss: 0.0638 - val_loss: 0.0885 - 4s/epoch - 8ms/step\n",
      "Epoch 90/10000\n",
      "577/577 - 4s - loss: 0.0650 - val_loss: 0.0970 - 4s/epoch - 8ms/step\n",
      "Epoch 91/10000\n",
      "577/577 - 4s - loss: 0.0698 - val_loss: 0.0912 - 4s/epoch - 7ms/step\n",
      "Epoch 92/10000\n",
      "577/577 - 4s - loss: 0.0622 - val_loss: 0.0941 - 4s/epoch - 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_2_layer_call_fn, gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/10_20_1_50_1_50_datt_seq2seq_gru_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/10_20_1_50_1_50_datt_seq2seq_gru_test\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7A5F74760> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7A5F3E490> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.944314</td>\n",
       "      <td>0.929582</td>\n",
       "      <td>0.952897</td>\n",
       "      <td>0.942265</td>\n",
       "      <td>4.660969</td>\n",
       "      <td>4.636108</td>\n",
       "      <td>3.376783</td>\n",
       "      <td>4.22462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.878832</td>\n",
       "      <td>0.869356</td>\n",
       "      <td>0.926556</td>\n",
       "      <td>0.891582</td>\n",
       "      <td>6.750228</td>\n",
       "      <td>6.316711</td>\n",
       "      <td>4.216103</td>\n",
       "      <td>5.761014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.781496</td>\n",
       "      <td>0.820624</td>\n",
       "      <td>0.878372</td>\n",
       "      <td>0.826831</td>\n",
       "      <td>8.668957</td>\n",
       "      <td>7.404408</td>\n",
       "      <td>5.424885</td>\n",
       "      <td>7.166083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.669341</td>\n",
       "      <td>0.781621</td>\n",
       "      <td>0.846401</td>\n",
       "      <td>0.765788</td>\n",
       "      <td>10.308094</td>\n",
       "      <td>8.172664</td>\n",
       "      <td>6.09488</td>\n",
       "      <td>8.19188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.56246</td>\n",
       "      <td>0.751121</td>\n",
       "      <td>0.831565</td>\n",
       "      <td>0.715049</td>\n",
       "      <td>11.668648</td>\n",
       "      <td>8.728632</td>\n",
       "      <td>6.380494</td>\n",
       "      <td>8.925925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.469132</td>\n",
       "      <td>0.727966</td>\n",
       "      <td>0.819837</td>\n",
       "      <td>0.672312</td>\n",
       "      <td>12.811013</td>\n",
       "      <td>9.130121</td>\n",
       "      <td>6.59651</td>\n",
       "      <td>9.512548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.390776</td>\n",
       "      <td>0.710086</td>\n",
       "      <td>0.805191</td>\n",
       "      <td>0.635351</td>\n",
       "      <td>13.456165</td>\n",
       "      <td>9.428264</td>\n",
       "      <td>6.857505</td>\n",
       "      <td>9.913978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.325055</td>\n",
       "      <td>0.69478</td>\n",
       "      <td>0.791728</td>\n",
       "      <td>0.603854</td>\n",
       "      <td>13.892488</td>\n",
       "      <td>9.677039</td>\n",
       "      <td>7.088905</td>\n",
       "      <td>10.219477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.270819</td>\n",
       "      <td>0.68026</td>\n",
       "      <td>0.779027</td>\n",
       "      <td>0.576702</td>\n",
       "      <td>14.225648</td>\n",
       "      <td>9.907808</td>\n",
       "      <td>7.300278</td>\n",
       "      <td>10.477912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.223851</td>\n",
       "      <td>0.664093</td>\n",
       "      <td>0.759048</td>\n",
       "      <td>0.548997</td>\n",
       "      <td>14.463289</td>\n",
       "      <td>10.157156</td>\n",
       "      <td>7.621033</td>\n",
       "      <td>10.747159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.178309</td>\n",
       "      <td>0.645557</td>\n",
       "      <td>0.72885</td>\n",
       "      <td>0.517572</td>\n",
       "      <td>14.726911</td>\n",
       "      <td>10.43536</td>\n",
       "      <td>8.082685</td>\n",
       "      <td>11.081652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.132843</td>\n",
       "      <td>0.627406</td>\n",
       "      <td>0.693683</td>\n",
       "      <td>0.484644</td>\n",
       "      <td>15.03272</td>\n",
       "      <td>10.700551</td>\n",
       "      <td>8.589286</td>\n",
       "      <td>11.440852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.609714</td>\n",
       "      <td>0.661019</td>\n",
       "      <td>0.453428</td>\n",
       "      <td>15.193957</td>\n",
       "      <td>10.952784</td>\n",
       "      <td>9.033773</td>\n",
       "      <td>11.726838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.052456</td>\n",
       "      <td>0.592202</td>\n",
       "      <td>0.63812</td>\n",
       "      <td>0.427593</td>\n",
       "      <td>15.294281</td>\n",
       "      <td>11.197533</td>\n",
       "      <td>9.331889</td>\n",
       "      <td>11.941234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.020476</td>\n",
       "      <td>0.573917</td>\n",
       "      <td>0.625314</td>\n",
       "      <td>0.406569</td>\n",
       "      <td>15.395798</td>\n",
       "      <td>11.447412</td>\n",
       "      <td>9.49329</td>\n",
       "      <td>12.112167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.007474</td>\n",
       "      <td>0.556392</td>\n",
       "      <td>0.619909</td>\n",
       "      <td>0.389609</td>\n",
       "      <td>15.45996</td>\n",
       "      <td>11.682202</td>\n",
       "      <td>9.559741</td>\n",
       "      <td>12.233968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.031489</td>\n",
       "      <td>0.539273</td>\n",
       "      <td>0.617346</td>\n",
       "      <td>0.375043</td>\n",
       "      <td>15.491537</td>\n",
       "      <td>11.906085</td>\n",
       "      <td>9.590837</td>\n",
       "      <td>12.329487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.050254</td>\n",
       "      <td>0.521881</td>\n",
       "      <td>0.6137</td>\n",
       "      <td>0.361776</td>\n",
       "      <td>15.59238</td>\n",
       "      <td>12.128977</td>\n",
       "      <td>9.635982</td>\n",
       "      <td>12.452446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.066253</td>\n",
       "      <td>0.505187</td>\n",
       "      <td>0.603938</td>\n",
       "      <td>0.347624</td>\n",
       "      <td>15.726263</td>\n",
       "      <td>12.339369</td>\n",
       "      <td>9.756598</td>\n",
       "      <td>12.60741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.079402</td>\n",
       "      <td>0.488437</td>\n",
       "      <td>0.586704</td>\n",
       "      <td>0.331913</td>\n",
       "      <td>15.838392</td>\n",
       "      <td>12.546689</td>\n",
       "      <td>9.966353</td>\n",
       "      <td>12.783811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.287742</td>\n",
       "      <td>0.664473</td>\n",
       "      <td>0.73896</td>\n",
       "      <td>0.563725</td>\n",
       "      <td>13.232885</td>\n",
       "      <td>9.944794</td>\n",
       "      <td>7.699891</td>\n",
       "      <td>10.292523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TT-3061-3 TT-3061-5 LT-3061-2      mean  TT-3061-3  TT-3061-5 LT-3061-2  \\\n",
       "index        R2        R2        R2        R2      nRMSE      nRMSE     nRMSE   \n",
       "0      0.944314  0.929582  0.952897  0.942265   4.660969   4.636108  3.376783   \n",
       "1      0.878832  0.869356  0.926556  0.891582   6.750228   6.316711  4.216103   \n",
       "2      0.781496  0.820624  0.878372  0.826831   8.668957   7.404408  5.424885   \n",
       "3      0.669341  0.781621  0.846401  0.765788  10.308094   8.172664   6.09488   \n",
       "4       0.56246  0.751121  0.831565  0.715049  11.668648   8.728632  6.380494   \n",
       "5      0.469132  0.727966  0.819837  0.672312  12.811013   9.130121   6.59651   \n",
       "6      0.390776  0.710086  0.805191  0.635351  13.456165   9.428264  6.857505   \n",
       "7      0.325055   0.69478  0.791728  0.603854  13.892488   9.677039  7.088905   \n",
       "8      0.270819   0.68026  0.779027  0.576702  14.225648   9.907808  7.300278   \n",
       "9      0.223851  0.664093  0.759048  0.548997  14.463289  10.157156  7.621033   \n",
       "10     0.178309  0.645557   0.72885  0.517572  14.726911   10.43536  8.082685   \n",
       "11     0.132843  0.627406  0.693683  0.484644   15.03272  10.700551  8.589286   \n",
       "12     0.089552  0.609714  0.661019  0.453428  15.193957  10.952784  9.033773   \n",
       "13     0.052456  0.592202   0.63812  0.427593  15.294281  11.197533  9.331889   \n",
       "14     0.020476  0.573917  0.625314  0.406569  15.395798  11.447412   9.49329   \n",
       "15    -0.007474  0.556392  0.619909  0.389609   15.45996  11.682202  9.559741   \n",
       "16    -0.031489  0.539273  0.617346  0.375043  15.491537  11.906085  9.590837   \n",
       "17    -0.050254  0.521881    0.6137  0.361776   15.59238  12.128977  9.635982   \n",
       "18    -0.066253  0.505187  0.603938  0.347624  15.726263  12.339369  9.756598   \n",
       "19    -0.079402  0.488437  0.586704  0.331913  15.838392  12.546689  9.966353   \n",
       "mean   0.287742  0.664473   0.73896  0.563725  13.232885   9.944794  7.699891   \n",
       "\n",
       "            mean  \n",
       "index      nRMSE  \n",
       "0        4.22462  \n",
       "1       5.761014  \n",
       "2       7.166083  \n",
       "3        8.19188  \n",
       "4       8.925925  \n",
       "5       9.512548  \n",
       "6       9.913978  \n",
       "7      10.219477  \n",
       "8      10.477912  \n",
       "9      10.747159  \n",
       "10     11.081652  \n",
       "11     11.440852  \n",
       "12     11.726838  \n",
       "13     11.941234  \n",
       "14     12.112167  \n",
       "15     12.233968  \n",
       "16     12.329487  \n",
       "17     12.452446  \n",
       "18      12.60741  \n",
       "19     12.783811  \n",
       "mean   10.292523  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history size: 10\n",
      "future size: 30\n",
      "Epoch 1/10000\n",
      "572/572 - 8s - loss: 0.3802 - val_loss: 0.2989 - 8s/epoch - 14ms/step\n",
      "Epoch 2/10000\n",
      "572/572 - 5s - loss: 0.2988 - val_loss: 0.2863 - 5s/epoch - 8ms/step\n",
      "Epoch 3/10000\n",
      "572/572 - 5s - loss: 0.2783 - val_loss: 0.2686 - 5s/epoch - 8ms/step\n",
      "Epoch 4/10000\n",
      "572/572 - 5s - loss: 0.2624 - val_loss: 0.2489 - 5s/epoch - 8ms/step\n",
      "Epoch 5/10000\n",
      "572/572 - 5s - loss: 0.2508 - val_loss: 0.2444 - 5s/epoch - 8ms/step\n",
      "Epoch 6/10000\n",
      "572/572 - 5s - loss: 0.2402 - val_loss: 0.2383 - 5s/epoch - 8ms/step\n",
      "Epoch 7/10000\n",
      "572/572 - 5s - loss: 0.2297 - val_loss: 0.2285 - 5s/epoch - 8ms/step\n",
      "Epoch 8/10000\n",
      "572/572 - 5s - loss: 0.2211 - val_loss: 0.2204 - 5s/epoch - 8ms/step\n",
      "Epoch 9/10000\n",
      "572/572 - 5s - loss: 0.2132 - val_loss: 0.2120 - 5s/epoch - 8ms/step\n",
      "Epoch 10/10000\n",
      "572/572 - 5s - loss: 0.2052 - val_loss: 0.2060 - 5s/epoch - 8ms/step\n",
      "Epoch 11/10000\n",
      "572/572 - 5s - loss: 0.1993 - val_loss: 0.1989 - 5s/epoch - 8ms/step\n",
      "Epoch 12/10000\n",
      "572/572 - 5s - loss: 0.1920 - val_loss: 0.1935 - 5s/epoch - 8ms/step\n",
      "Epoch 13/10000\n",
      "572/572 - 5s - loss: 0.1884 - val_loss: 0.1916 - 5s/epoch - 8ms/step\n",
      "Epoch 14/10000\n",
      "572/572 - 5s - loss: 0.1798 - val_loss: 0.1966 - 5s/epoch - 8ms/step\n",
      "Epoch 15/10000\n",
      "572/572 - 4s - loss: 0.1780 - val_loss: 0.1849 - 4s/epoch - 8ms/step\n",
      "Epoch 16/10000\n",
      "572/572 - 4s - loss: 0.1707 - val_loss: 0.1819 - 4s/epoch - 8ms/step\n",
      "Epoch 17/10000\n",
      "572/572 - 4s - loss: 0.1670 - val_loss: 0.1728 - 4s/epoch - 8ms/step\n",
      "Epoch 18/10000\n",
      "572/572 - 4s - loss: 0.1656 - val_loss: 0.1667 - 4s/epoch - 8ms/step\n",
      "Epoch 19/10000\n",
      "572/572 - 4s - loss: 0.1591 - val_loss: 0.1741 - 4s/epoch - 8ms/step\n",
      "Epoch 20/10000\n",
      "572/572 - 4s - loss: 0.1540 - val_loss: 0.1683 - 4s/epoch - 8ms/step\n",
      "Epoch 21/10000\n",
      "572/572 - 4s - loss: 0.1534 - val_loss: 0.1601 - 4s/epoch - 8ms/step\n",
      "Epoch 22/10000\n",
      "572/572 - 4s - loss: 0.1478 - val_loss: 0.1620 - 4s/epoch - 8ms/step\n",
      "Epoch 23/10000\n",
      "572/572 - 4s - loss: 0.1501 - val_loss: 0.1656 - 4s/epoch - 8ms/step\n",
      "Epoch 24/10000\n",
      "572/572 - 4s - loss: 0.1447 - val_loss: 0.1623 - 4s/epoch - 8ms/step\n",
      "Epoch 25/10000\n",
      "572/572 - 4s - loss: 0.1467 - val_loss: 0.1580 - 4s/epoch - 8ms/step\n",
      "Epoch 26/10000\n",
      "572/572 - 5s - loss: 0.1386 - val_loss: 0.1493 - 5s/epoch - 8ms/step\n",
      "Epoch 27/10000\n",
      "572/572 - 4s - loss: 0.1369 - val_loss: 0.1485 - 4s/epoch - 8ms/step\n",
      "Epoch 28/10000\n",
      "572/572 - 4s - loss: 0.1416 - val_loss: 0.1545 - 4s/epoch - 8ms/step\n",
      "Epoch 29/10000\n",
      "572/572 - 4s - loss: 0.1372 - val_loss: 0.1431 - 4s/epoch - 8ms/step\n",
      "Epoch 30/10000\n",
      "572/572 - 4s - loss: 0.1316 - val_loss: 0.1435 - 4s/epoch - 8ms/step\n",
      "Epoch 31/10000\n",
      "572/572 - 5s - loss: 0.1295 - val_loss: 0.1481 - 5s/epoch - 8ms/step\n",
      "Epoch 32/10000\n",
      "572/572 - 4s - loss: 0.1302 - val_loss: 0.1382 - 4s/epoch - 8ms/step\n",
      "Epoch 33/10000\n",
      "572/572 - 5s - loss: 0.1295 - val_loss: 0.1428 - 5s/epoch - 8ms/step\n",
      "Epoch 34/10000\n",
      "572/572 - 5s - loss: 0.1250 - val_loss: 0.1356 - 5s/epoch - 8ms/step\n",
      "Epoch 35/10000\n",
      "572/572 - 4s - loss: 0.1265 - val_loss: 0.1404 - 4s/epoch - 8ms/step\n",
      "Epoch 36/10000\n",
      "572/572 - 4s - loss: 0.1247 - val_loss: 0.1351 - 4s/epoch - 8ms/step\n",
      "Epoch 37/10000\n",
      "572/572 - 5s - loss: 0.1228 - val_loss: 0.1408 - 5s/epoch - 8ms/step\n",
      "Epoch 38/10000\n",
      "572/572 - 4s - loss: 0.1236 - val_loss: 0.1408 - 4s/epoch - 8ms/step\n",
      "Epoch 39/10000\n",
      "572/572 - 5s - loss: 0.1223 - val_loss: 0.1317 - 5s/epoch - 8ms/step\n",
      "Epoch 40/10000\n",
      "572/572 - 5s - loss: 0.1191 - val_loss: 0.1334 - 5s/epoch - 8ms/step\n",
      "Epoch 41/10000\n",
      "572/572 - 5s - loss: 0.1172 - val_loss: 0.1393 - 5s/epoch - 8ms/step\n",
      "Epoch 42/10000\n",
      "572/572 - 4s - loss: 0.1163 - val_loss: 0.1286 - 4s/epoch - 8ms/step\n",
      "Epoch 43/10000\n",
      "572/572 - 4s - loss: 0.1179 - val_loss: 0.1368 - 4s/epoch - 8ms/step\n",
      "Epoch 44/10000\n",
      "572/572 - 5s - loss: 0.1167 - val_loss: 0.1317 - 5s/epoch - 8ms/step\n",
      "Epoch 45/10000\n",
      "572/572 - 4s - loss: 0.1141 - val_loss: 0.1408 - 4s/epoch - 8ms/step\n",
      "Epoch 46/10000\n",
      "572/572 - 4s - loss: 0.1158 - val_loss: 0.1217 - 4s/epoch - 8ms/step\n",
      "Epoch 47/10000\n",
      "572/572 - 4s - loss: 0.1153 - val_loss: 0.1376 - 4s/epoch - 8ms/step\n",
      "Epoch 48/10000\n",
      "572/572 - 4s - loss: 0.1114 - val_loss: 0.1254 - 4s/epoch - 8ms/step\n",
      "Epoch 49/10000\n",
      "572/572 - 5s - loss: 0.1109 - val_loss: 0.1320 - 5s/epoch - 8ms/step\n",
      "Epoch 50/10000\n",
      "572/572 - 5s - loss: 0.1096 - val_loss: 0.1382 - 5s/epoch - 8ms/step\n",
      "Epoch 51/10000\n",
      "572/572 - 4s - loss: 0.1106 - val_loss: 0.1194 - 4s/epoch - 8ms/step\n",
      "Epoch 52/10000\n",
      "572/572 - 5s - loss: 0.1096 - val_loss: 0.1285 - 5s/epoch - 8ms/step\n",
      "Epoch 53/10000\n",
      "572/572 - 4s - loss: 0.1055 - val_loss: 0.1177 - 4s/epoch - 8ms/step\n",
      "Epoch 54/10000\n",
      "572/572 - 4s - loss: 0.1083 - val_loss: 0.1237 - 4s/epoch - 8ms/step\n",
      "Epoch 55/10000\n",
      "572/572 - 4s - loss: 0.1072 - val_loss: 0.1181 - 4s/epoch - 8ms/step\n",
      "Epoch 56/10000\n",
      "572/572 - 4s - loss: 0.1013 - val_loss: 0.1167 - 4s/epoch - 8ms/step\n",
      "Epoch 57/10000\n",
      "572/572 - 4s - loss: 0.1015 - val_loss: 0.1150 - 4s/epoch - 8ms/step\n",
      "Epoch 58/10000\n",
      "572/572 - 4s - loss: 0.1019 - val_loss: 0.1351 - 4s/epoch - 8ms/step\n",
      "Epoch 59/10000\n",
      "572/572 - 4s - loss: 0.1024 - val_loss: 0.1206 - 4s/epoch - 8ms/step\n",
      "Epoch 60/10000\n",
      "572/572 - 5s - loss: 0.1014 - val_loss: 0.1182 - 5s/epoch - 8ms/step\n",
      "Epoch 61/10000\n",
      "572/572 - 4s - loss: 0.1004 - val_loss: 0.1126 - 4s/epoch - 8ms/step\n",
      "Epoch 62/10000\n",
      "572/572 - 5s - loss: 0.1002 - val_loss: 0.1114 - 5s/epoch - 8ms/step\n",
      "Epoch 63/10000\n",
      "572/572 - 5s - loss: 0.1033 - val_loss: 0.1212 - 5s/epoch - 8ms/step\n",
      "Epoch 64/10000\n",
      "572/572 - 4s - loss: 0.0998 - val_loss: 0.1290 - 4s/epoch - 8ms/step\n",
      "Epoch 65/10000\n",
      "572/572 - 4s - loss: 0.0988 - val_loss: 0.1336 - 4s/epoch - 8ms/step\n",
      "Epoch 66/10000\n",
      "572/572 - 5s - loss: 0.1020 - val_loss: 0.1157 - 5s/epoch - 8ms/step\n",
      "Epoch 67/10000\n",
      "572/572 - 4s - loss: 0.0947 - val_loss: 0.1121 - 4s/epoch - 8ms/step\n",
      "Epoch 68/10000\n",
      "572/572 - 4s - loss: 0.0959 - val_loss: 0.1136 - 4s/epoch - 8ms/step\n",
      "Epoch 69/10000\n",
      "572/572 - 4s - loss: 0.0933 - val_loss: 0.1076 - 4s/epoch - 8ms/step\n",
      "Epoch 70/10000\n",
      "572/572 - 4s - loss: 0.0929 - val_loss: 0.1157 - 4s/epoch - 8ms/step\n",
      "Epoch 71/10000\n",
      "572/572 - 5s - loss: 0.0939 - val_loss: 0.1106 - 5s/epoch - 8ms/step\n",
      "Epoch 72/10000\n",
      "572/572 - 4s - loss: 0.0946 - val_loss: 0.1241 - 4s/epoch - 8ms/step\n",
      "Epoch 73/10000\n",
      "572/572 - 5s - loss: 0.1052 - val_loss: 0.1213 - 5s/epoch - 8ms/step\n",
      "Epoch 74/10000\n",
      "572/572 - 5s - loss: 0.0983 - val_loss: 0.1085 - 5s/epoch - 8ms/step\n",
      "Epoch 75/10000\n",
      "572/572 - 5s - loss: 0.0916 - val_loss: 0.1004 - 5s/epoch - 8ms/step\n",
      "Epoch 76/10000\n",
      "572/572 - 5s - loss: 0.0911 - val_loss: 0.1110 - 5s/epoch - 8ms/step\n",
      "Epoch 77/10000\n",
      "572/572 - 5s - loss: 0.0941 - val_loss: 0.1027 - 5s/epoch - 8ms/step\n",
      "Epoch 78/10000\n",
      "572/572 - 5s - loss: 0.0914 - val_loss: 0.1099 - 5s/epoch - 8ms/step\n",
      "Epoch 79/10000\n",
      "572/572 - 4s - loss: 0.0885 - val_loss: 0.1053 - 4s/epoch - 8ms/step\n",
      "Epoch 80/10000\n",
      "572/572 - 5s - loss: 0.0894 - val_loss: 0.1043 - 5s/epoch - 8ms/step\n",
      "Epoch 81/10000\n",
      "572/572 - 5s - loss: 0.0887 - val_loss: 0.1058 - 5s/epoch - 8ms/step\n",
      "Epoch 82/10000\n",
      "572/572 - 4s - loss: 0.0930 - val_loss: 0.1199 - 4s/epoch - 8ms/step\n",
      "Epoch 83/10000\n",
      "572/572 - 4s - loss: 0.0881 - val_loss: 0.1056 - 4s/epoch - 8ms/step\n",
      "Epoch 84/10000\n",
      "572/572 - 5s - loss: 0.0985 - val_loss: 0.1096 - 5s/epoch - 8ms/step\n",
      "Epoch 85/10000\n",
      "572/572 - 5s - loss: 0.0892 - val_loss: 0.1058 - 5s/epoch - 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/10_30_1_50_1_50_datt_seq2seq_gru_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/10_30_1_50_1_50_datt_seq2seq_gru_test\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7A5F3EEE0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B878561DF0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.890237</td>\n",
       "      <td>0.92838</td>\n",
       "      <td>0.944273</td>\n",
       "      <td>0.920963</td>\n",
       "      <td>6.540492</td>\n",
       "      <td>4.674615</td>\n",
       "      <td>3.659059</td>\n",
       "      <td>4.958055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.827649</td>\n",
       "      <td>0.868481</td>\n",
       "      <td>0.9169</td>\n",
       "      <td>0.87101</td>\n",
       "      <td>8.195833</td>\n",
       "      <td>6.334961</td>\n",
       "      <td>4.468303</td>\n",
       "      <td>6.333032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.723747</td>\n",
       "      <td>0.838015</td>\n",
       "      <td>0.888151</td>\n",
       "      <td>0.816638</td>\n",
       "      <td>10.377828</td>\n",
       "      <td>7.031036</td>\n",
       "      <td>5.183409</td>\n",
       "      <td>7.530758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.62213</td>\n",
       "      <td>0.81305</td>\n",
       "      <td>0.862197</td>\n",
       "      <td>0.765792</td>\n",
       "      <td>12.139678</td>\n",
       "      <td>7.55439</td>\n",
       "      <td>5.752069</td>\n",
       "      <td>8.482045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.525754</td>\n",
       "      <td>0.789554</td>\n",
       "      <td>0.839373</td>\n",
       "      <td>0.718227</td>\n",
       "      <td>13.6017</td>\n",
       "      <td>8.016529</td>\n",
       "      <td>6.208252</td>\n",
       "      <td>9.275494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.431997</td>\n",
       "      <td>0.767344</td>\n",
       "      <td>0.819242</td>\n",
       "      <td>0.672861</td>\n",
       "      <td>14.886898</td>\n",
       "      <td>8.431304</td>\n",
       "      <td>6.583772</td>\n",
       "      <td>9.967325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.34425</td>\n",
       "      <td>0.746167</td>\n",
       "      <td>0.798687</td>\n",
       "      <td>0.629701</td>\n",
       "      <td>15.99684</td>\n",
       "      <td>8.809286</td>\n",
       "      <td>6.946418</td>\n",
       "      <td>10.584181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.263614</td>\n",
       "      <td>0.724768</td>\n",
       "      <td>0.775539</td>\n",
       "      <td>0.587974</td>\n",
       "      <td>16.951715</td>\n",
       "      <td>9.17586</td>\n",
       "      <td>7.33372</td>\n",
       "      <td>11.153765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.191231</td>\n",
       "      <td>0.702399</td>\n",
       "      <td>0.748257</td>\n",
       "      <td>0.547296</td>\n",
       "      <td>17.764434</td>\n",
       "      <td>9.545294</td>\n",
       "      <td>7.76517</td>\n",
       "      <td>11.691633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.128086</td>\n",
       "      <td>0.679583</td>\n",
       "      <td>0.715611</td>\n",
       "      <td>0.50776</td>\n",
       "      <td>18.445859</td>\n",
       "      <td>9.907828</td>\n",
       "      <td>8.251701</td>\n",
       "      <td>12.201796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.070052</td>\n",
       "      <td>0.656706</td>\n",
       "      <td>0.676492</td>\n",
       "      <td>0.46775</td>\n",
       "      <td>19.054052</td>\n",
       "      <td>10.258168</td>\n",
       "      <td>8.799581</td>\n",
       "      <td>12.703933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.013992</td>\n",
       "      <td>0.635269</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.427305</td>\n",
       "      <td>19.264049</td>\n",
       "      <td>10.576995</td>\n",
       "      <td>9.375575</td>\n",
       "      <td>13.072206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.038628</td>\n",
       "      <td>0.613779</td>\n",
       "      <td>0.587691</td>\n",
       "      <td>0.387614</td>\n",
       "      <td>18.908714</td>\n",
       "      <td>10.888204</td>\n",
       "      <td>9.931407</td>\n",
       "      <td>13.242775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.088199</td>\n",
       "      <td>0.59389</td>\n",
       "      <td>0.545153</td>\n",
       "      <td>0.350281</td>\n",
       "      <td>18.708112</td>\n",
       "      <td>11.168978</td>\n",
       "      <td>10.429738</td>\n",
       "      <td>13.435609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.133406</td>\n",
       "      <td>0.572317</td>\n",
       "      <td>0.505762</td>\n",
       "      <td>0.314891</td>\n",
       "      <td>18.786309</td>\n",
       "      <td>11.466927</td>\n",
       "      <td>10.87092</td>\n",
       "      <td>13.708052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.173255</td>\n",
       "      <td>0.550118</td>\n",
       "      <td>0.470012</td>\n",
       "      <td>0.282292</td>\n",
       "      <td>19.047213</td>\n",
       "      <td>11.766626</td>\n",
       "      <td>11.255497</td>\n",
       "      <td>14.023112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.208717</td>\n",
       "      <td>0.52899</td>\n",
       "      <td>0.436222</td>\n",
       "      <td>0.252165</td>\n",
       "      <td>18.951796</td>\n",
       "      <td>12.043204</td>\n",
       "      <td>11.607209</td>\n",
       "      <td>14.200736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.238411</td>\n",
       "      <td>0.508743</td>\n",
       "      <td>0.401922</td>\n",
       "      <td>0.224085</td>\n",
       "      <td>18.813133</td>\n",
       "      <td>12.303239</td>\n",
       "      <td>11.95265</td>\n",
       "      <td>14.356341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.261579</td>\n",
       "      <td>0.488139</td>\n",
       "      <td>0.367656</td>\n",
       "      <td>0.198072</td>\n",
       "      <td>18.703006</td>\n",
       "      <td>12.562758</td>\n",
       "      <td>12.287206</td>\n",
       "      <td>14.517657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.281028</td>\n",
       "      <td>0.467724</td>\n",
       "      <td>0.335151</td>\n",
       "      <td>0.173949</td>\n",
       "      <td>18.568396</td>\n",
       "      <td>12.813293</td>\n",
       "      <td>12.595089</td>\n",
       "      <td>14.658926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.298031</td>\n",
       "      <td>0.44855</td>\n",
       "      <td>0.304003</td>\n",
       "      <td>0.151507</td>\n",
       "      <td>18.491222</td>\n",
       "      <td>13.044239</td>\n",
       "      <td>12.883248</td>\n",
       "      <td>14.806236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.314865</td>\n",
       "      <td>0.429391</td>\n",
       "      <td>0.274436</td>\n",
       "      <td>0.129654</td>\n",
       "      <td>18.48719</td>\n",
       "      <td>13.270515</td>\n",
       "      <td>13.151799</td>\n",
       "      <td>14.969835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.330556</td>\n",
       "      <td>0.408863</td>\n",
       "      <td>0.248053</td>\n",
       "      <td>0.108787</td>\n",
       "      <td>18.339266</td>\n",
       "      <td>13.508376</td>\n",
       "      <td>13.387746</td>\n",
       "      <td>15.078463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.344992</td>\n",
       "      <td>0.387129</td>\n",
       "      <td>0.225512</td>\n",
       "      <td>0.089217</td>\n",
       "      <td>18.190062</td>\n",
       "      <td>13.756252</td>\n",
       "      <td>13.587046</td>\n",
       "      <td>15.177786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.359958</td>\n",
       "      <td>0.364616</td>\n",
       "      <td>0.207215</td>\n",
       "      <td>0.070624</td>\n",
       "      <td>18.10943</td>\n",
       "      <td>14.008488</td>\n",
       "      <td>13.746223</td>\n",
       "      <td>15.288047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.373102</td>\n",
       "      <td>0.343146</td>\n",
       "      <td>0.192857</td>\n",
       "      <td>0.0543</td>\n",
       "      <td>18.020659</td>\n",
       "      <td>14.245363</td>\n",
       "      <td>13.870253</td>\n",
       "      <td>15.378758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.384392</td>\n",
       "      <td>0.32415</td>\n",
       "      <td>0.180474</td>\n",
       "      <td>0.040077</td>\n",
       "      <td>17.923534</td>\n",
       "      <td>14.450913</td>\n",
       "      <td>13.976905</td>\n",
       "      <td>15.45045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.392717</td>\n",
       "      <td>0.308516</td>\n",
       "      <td>0.168258</td>\n",
       "      <td>0.028019</td>\n",
       "      <td>17.937816</td>\n",
       "      <td>14.617482</td>\n",
       "      <td>14.081938</td>\n",
       "      <td>15.545746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.398038</td>\n",
       "      <td>0.296029</td>\n",
       "      <td>0.154948</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>17.997282</td>\n",
       "      <td>14.749284</td>\n",
       "      <td>14.195121</td>\n",
       "      <td>15.647229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.40195</td>\n",
       "      <td>0.284886</td>\n",
       "      <td>0.13942</td>\n",
       "      <td>0.007452</td>\n",
       "      <td>18.048357</td>\n",
       "      <td>14.865656</td>\n",
       "      <td>14.326579</td>\n",
       "      <td>15.746864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.568956</td>\n",
       "      <td>0.512071</td>\n",
       "      <td>0.360464</td>\n",
       "      <td>16.841696</td>\n",
       "      <td>11.194869</td>\n",
       "      <td>10.28212</td>\n",
       "      <td>12.772895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TT-3061-3 TT-3061-5 LT-3061-2      mean  TT-3061-3  TT-3061-5  \\\n",
       "index        R2        R2        R2        R2      nRMSE      nRMSE   \n",
       "0      0.890237   0.92838  0.944273  0.920963   6.540492   4.674615   \n",
       "1      0.827649  0.868481    0.9169   0.87101   8.195833   6.334961   \n",
       "2      0.723747  0.838015  0.888151  0.816638  10.377828   7.031036   \n",
       "3       0.62213   0.81305  0.862197  0.765792  12.139678    7.55439   \n",
       "4      0.525754  0.789554  0.839373  0.718227    13.6017   8.016529   \n",
       "5      0.431997  0.767344  0.819242  0.672861  14.886898   8.431304   \n",
       "6       0.34425  0.746167  0.798687  0.629701   15.99684   8.809286   \n",
       "7      0.263614  0.724768  0.775539  0.587974  16.951715    9.17586   \n",
       "8      0.191231  0.702399  0.748257  0.547296  17.764434   9.545294   \n",
       "9      0.128086  0.679583  0.715611   0.50776  18.445859   9.907828   \n",
       "10     0.070052  0.656706  0.676492   0.46775  19.054052  10.258168   \n",
       "11     0.013992  0.635269  0.632653  0.427305  19.264049  10.576995   \n",
       "12    -0.038628  0.613779  0.587691  0.387614  18.908714  10.888204   \n",
       "13    -0.088199   0.59389  0.545153  0.350281  18.708112  11.168978   \n",
       "14    -0.133406  0.572317  0.505762  0.314891  18.786309  11.466927   \n",
       "15    -0.173255  0.550118  0.470012  0.282292  19.047213  11.766626   \n",
       "16    -0.208717   0.52899  0.436222  0.252165  18.951796  12.043204   \n",
       "17    -0.238411  0.508743  0.401922  0.224085  18.813133  12.303239   \n",
       "18    -0.261579  0.488139  0.367656  0.198072  18.703006  12.562758   \n",
       "19    -0.281028  0.467724  0.335151  0.173949  18.568396  12.813293   \n",
       "20    -0.298031   0.44855  0.304003  0.151507  18.491222  13.044239   \n",
       "21    -0.314865  0.429391  0.274436  0.129654   18.48719  13.270515   \n",
       "22    -0.330556  0.408863  0.248053  0.108787  18.339266  13.508376   \n",
       "23    -0.344992  0.387129  0.225512  0.089217  18.190062  13.756252   \n",
       "24    -0.359958  0.364616  0.207215  0.070624   18.10943  14.008488   \n",
       "25    -0.373102  0.343146  0.192857    0.0543  18.020659  14.245363   \n",
       "26    -0.384392   0.32415  0.180474  0.040077  17.923534  14.450913   \n",
       "27    -0.392717  0.308516  0.168258  0.028019  17.937816  14.617482   \n",
       "28    -0.398038  0.296029  0.154948  0.017647  17.997282  14.749284   \n",
       "29     -0.40195  0.284886   0.13942  0.007452  18.048357  14.865656   \n",
       "mean   0.000364  0.568956  0.512071  0.360464  16.841696  11.194869   \n",
       "\n",
       "       LT-3061-2       mean  \n",
       "index      nRMSE      nRMSE  \n",
       "0       3.659059   4.958055  \n",
       "1       4.468303   6.333032  \n",
       "2       5.183409   7.530758  \n",
       "3       5.752069   8.482045  \n",
       "4       6.208252   9.275494  \n",
       "5       6.583772   9.967325  \n",
       "6       6.946418  10.584181  \n",
       "7        7.33372  11.153765  \n",
       "8        7.76517  11.691633  \n",
       "9       8.251701  12.201796  \n",
       "10      8.799581  12.703933  \n",
       "11      9.375575  13.072206  \n",
       "12      9.931407  13.242775  \n",
       "13     10.429738  13.435609  \n",
       "14      10.87092  13.708052  \n",
       "15     11.255497  14.023112  \n",
       "16     11.607209  14.200736  \n",
       "17      11.95265  14.356341  \n",
       "18     12.287206  14.517657  \n",
       "19     12.595089  14.658926  \n",
       "20     12.883248  14.806236  \n",
       "21     13.151799  14.969835  \n",
       "22     13.387746  15.078463  \n",
       "23     13.587046  15.177786  \n",
       "24     13.746223  15.288047  \n",
       "25     13.870253  15.378758  \n",
       "26     13.976905   15.45045  \n",
       "27     14.081938  15.545746  \n",
       "28     14.195121  15.647229  \n",
       "29     14.326579  15.746864  \n",
       "mean    10.28212  12.772895  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history size: 20\n",
      "future size: 10\n",
      "Epoch 1/10000\n",
      "577/577 - 8s - loss: 0.2322 - val_loss: 0.1644 - 8s/epoch - 14ms/step\n",
      "Epoch 2/10000\n",
      "577/577 - 5s - loss: 0.1511 - val_loss: 0.1487 - 5s/epoch - 8ms/step\n",
      "Epoch 3/10000\n",
      "577/577 - 4s - loss: 0.1404 - val_loss: 0.1406 - 4s/epoch - 7ms/step\n",
      "Epoch 4/10000\n",
      "577/577 - 4s - loss: 0.1309 - val_loss: 0.1326 - 4s/epoch - 7ms/step\n",
      "Epoch 5/10000\n",
      "577/577 - 4s - loss: 0.1198 - val_loss: 0.1271 - 4s/epoch - 7ms/step\n",
      "Epoch 6/10000\n",
      "577/577 - 4s - loss: 0.1140 - val_loss: 0.1178 - 4s/epoch - 8ms/step\n",
      "Epoch 7/10000\n",
      "577/577 - 4s - loss: 0.1058 - val_loss: 0.1093 - 4s/epoch - 7ms/step\n",
      "Epoch 8/10000\n",
      "577/577 - 4s - loss: 0.1003 - val_loss: 0.1046 - 4s/epoch - 7ms/step\n",
      "Epoch 9/10000\n",
      "577/577 - 4s - loss: 0.0964 - val_loss: 0.1017 - 4s/epoch - 7ms/step\n",
      "Epoch 10/10000\n",
      "577/577 - 4s - loss: 0.0942 - val_loss: 0.0954 - 4s/epoch - 7ms/step\n",
      "Epoch 11/10000\n",
      "577/577 - 4s - loss: 0.0898 - val_loss: 0.1053 - 4s/epoch - 7ms/step\n",
      "Epoch 12/10000\n",
      "577/577 - 4s - loss: 0.0870 - val_loss: 0.0950 - 4s/epoch - 8ms/step\n",
      "Epoch 13/10000\n",
      "577/577 - 4s - loss: 0.0846 - val_loss: 0.0911 - 4s/epoch - 7ms/step\n",
      "Epoch 14/10000\n",
      "577/577 - 4s - loss: 0.0814 - val_loss: 0.0905 - 4s/epoch - 8ms/step\n",
      "Epoch 15/10000\n",
      "577/577 - 4s - loss: 0.0806 - val_loss: 0.1020 - 4s/epoch - 7ms/step\n",
      "Epoch 16/10000\n",
      "577/577 - 4s - loss: 0.0784 - val_loss: 0.1020 - 4s/epoch - 7ms/step\n",
      "Epoch 17/10000\n",
      "577/577 - 4s - loss: 0.0764 - val_loss: 0.0843 - 4s/epoch - 7ms/step\n",
      "Epoch 18/10000\n",
      "577/577 - 4s - loss: 0.0736 - val_loss: 0.0795 - 4s/epoch - 8ms/step\n",
      "Epoch 19/10000\n",
      "577/577 - 4s - loss: 0.0725 - val_loss: 0.0841 - 4s/epoch - 8ms/step\n",
      "Epoch 20/10000\n",
      "577/577 - 4s - loss: 0.0716 - val_loss: 0.0812 - 4s/epoch - 8ms/step\n",
      "Epoch 21/10000\n",
      "577/577 - 4s - loss: 0.0711 - val_loss: 0.0843 - 4s/epoch - 8ms/step\n",
      "Epoch 22/10000\n",
      "577/577 - 5s - loss: 0.0684 - val_loss: 0.0788 - 5s/epoch - 8ms/step\n",
      "Epoch 23/10000\n",
      "577/577 - 4s - loss: 0.0668 - val_loss: 0.0789 - 4s/epoch - 7ms/step\n",
      "Epoch 24/10000\n",
      "577/577 - 4s - loss: 0.0659 - val_loss: 0.0764 - 4s/epoch - 8ms/step\n",
      "Epoch 25/10000\n",
      "577/577 - 4s - loss: 0.0629 - val_loss: 0.0761 - 4s/epoch - 8ms/step\n",
      "Epoch 26/10000\n",
      "577/577 - 4s - loss: 0.0641 - val_loss: 0.0848 - 4s/epoch - 8ms/step\n",
      "Epoch 27/10000\n",
      "577/577 - 5s - loss: 0.0634 - val_loss: 0.0812 - 5s/epoch - 8ms/step\n",
      "Epoch 28/10000\n",
      "577/577 - 5s - loss: 0.0623 - val_loss: 0.0731 - 5s/epoch - 8ms/step\n",
      "Epoch 29/10000\n",
      "577/577 - 4s - loss: 0.0603 - val_loss: 0.0725 - 4s/epoch - 7ms/step\n",
      "Epoch 30/10000\n",
      "577/577 - 4s - loss: 0.0578 - val_loss: 0.0694 - 4s/epoch - 8ms/step\n",
      "Epoch 31/10000\n",
      "577/577 - 4s - loss: 0.0583 - val_loss: 0.0684 - 4s/epoch - 8ms/step\n",
      "Epoch 32/10000\n",
      "577/577 - 4s - loss: 0.0570 - val_loss: 0.0709 - 4s/epoch - 8ms/step\n",
      "Epoch 33/10000\n",
      "577/577 - 4s - loss: 0.0577 - val_loss: 0.0712 - 4s/epoch - 8ms/step\n",
      "Epoch 34/10000\n",
      "577/577 - 4s - loss: 0.0571 - val_loss: 0.0675 - 4s/epoch - 8ms/step\n",
      "Epoch 35/10000\n",
      "577/577 - 4s - loss: 0.0541 - val_loss: 0.0665 - 4s/epoch - 8ms/step\n",
      "Epoch 36/10000\n",
      "577/577 - 4s - loss: 0.0539 - val_loss: 0.0657 - 4s/epoch - 7ms/step\n",
      "Epoch 37/10000\n",
      "577/577 - 4s - loss: 0.0531 - val_loss: 0.0687 - 4s/epoch - 8ms/step\n",
      "Epoch 38/10000\n",
      "577/577 - 4s - loss: 0.0526 - val_loss: 0.0705 - 4s/epoch - 8ms/step\n",
      "Epoch 39/10000\n",
      "577/577 - 4s - loss: 0.0532 - val_loss: 0.0653 - 4s/epoch - 7ms/step\n",
      "Epoch 40/10000\n",
      "577/577 - 4s - loss: 0.0509 - val_loss: 0.0659 - 4s/epoch - 8ms/step\n",
      "Epoch 41/10000\n",
      "577/577 - 5s - loss: 0.0503 - val_loss: 0.0624 - 5s/epoch - 8ms/step\n",
      "Epoch 42/10000\n",
      "577/577 - 4s - loss: 0.0518 - val_loss: 0.0629 - 4s/epoch - 8ms/step\n",
      "Epoch 43/10000\n",
      "577/577 - 4s - loss: 0.0510 - val_loss: 0.0684 - 4s/epoch - 8ms/step\n",
      "Epoch 44/10000\n",
      "577/577 - 4s - loss: 0.0499 - val_loss: 0.0642 - 4s/epoch - 8ms/step\n",
      "Epoch 45/10000\n",
      "577/577 - 4s - loss: 0.0480 - val_loss: 0.0600 - 4s/epoch - 7ms/step\n",
      "Epoch 46/10000\n",
      "577/577 - 4s - loss: 0.0477 - val_loss: 0.0605 - 4s/epoch - 8ms/step\n",
      "Epoch 47/10000\n",
      "577/577 - 4s - loss: 0.0470 - val_loss: 0.0670 - 4s/epoch - 8ms/step\n",
      "Epoch 48/10000\n",
      "577/577 - 4s - loss: 0.0477 - val_loss: 0.0619 - 4s/epoch - 8ms/step\n",
      "Epoch 49/10000\n",
      "577/577 - 4s - loss: 0.0462 - val_loss: 0.0603 - 4s/epoch - 8ms/step\n",
      "Epoch 50/10000\n",
      "577/577 - 4s - loss: 0.0464 - val_loss: 0.0618 - 4s/epoch - 8ms/step\n",
      "Epoch 51/10000\n",
      "577/577 - 4s - loss: 0.0459 - val_loss: 0.0599 - 4s/epoch - 8ms/step\n",
      "Epoch 52/10000\n",
      "577/577 - 5s - loss: 0.0472 - val_loss: 0.0651 - 5s/epoch - 8ms/step\n",
      "Epoch 53/10000\n",
      "577/577 - 5s - loss: 0.0451 - val_loss: 0.0592 - 5s/epoch - 8ms/step\n",
      "Epoch 54/10000\n",
      "577/577 - 4s - loss: 0.0453 - val_loss: 0.0605 - 4s/epoch - 8ms/step\n",
      "Epoch 55/10000\n",
      "577/577 - 5s - loss: 0.0441 - val_loss: 0.0595 - 5s/epoch - 8ms/step\n",
      "Epoch 56/10000\n",
      "577/577 - 4s - loss: 0.0437 - val_loss: 0.0585 - 4s/epoch - 8ms/step\n",
      "Epoch 57/10000\n",
      "577/577 - 4s - loss: 0.0435 - val_loss: 0.0577 - 4s/epoch - 8ms/step\n",
      "Epoch 58/10000\n",
      "577/577 - 4s - loss: 0.0438 - val_loss: 0.0580 - 4s/epoch - 8ms/step\n",
      "Epoch 59/10000\n",
      "577/577 - 4s - loss: 0.0426 - val_loss: 0.0586 - 4s/epoch - 8ms/step\n",
      "Epoch 60/10000\n",
      "577/577 - 4s - loss: 0.0445 - val_loss: 0.0650 - 4s/epoch - 8ms/step\n",
      "Epoch 61/10000\n",
      "577/577 - 4s - loss: 0.0438 - val_loss: 0.0545 - 4s/epoch - 8ms/step\n",
      "Epoch 62/10000\n",
      "577/577 - 4s - loss: 0.0408 - val_loss: 0.0550 - 4s/epoch - 8ms/step\n",
      "Epoch 63/10000\n",
      "577/577 - 4s - loss: 0.0413 - val_loss: 0.0576 - 4s/epoch - 8ms/step\n",
      "Epoch 64/10000\n",
      "577/577 - 4s - loss: 0.0424 - val_loss: 0.0573 - 4s/epoch - 8ms/step\n",
      "Epoch 65/10000\n",
      "577/577 - 5s - loss: 0.0421 - val_loss: 0.0574 - 5s/epoch - 8ms/step\n",
      "Epoch 66/10000\n",
      "577/577 - 4s - loss: 0.0409 - val_loss: 0.0560 - 4s/epoch - 8ms/step\n",
      "Epoch 67/10000\n",
      "577/577 - 4s - loss: 0.0405 - val_loss: 0.0533 - 4s/epoch - 8ms/step\n",
      "Epoch 68/10000\n",
      "577/577 - 4s - loss: 0.0397 - val_loss: 0.0546 - 4s/epoch - 7ms/step\n",
      "Epoch 69/10000\n",
      "577/577 - 4s - loss: 0.0406 - val_loss: 0.0618 - 4s/epoch - 8ms/step\n",
      "Epoch 70/10000\n",
      "577/577 - 4s - loss: 0.0408 - val_loss: 0.0524 - 4s/epoch - 8ms/step\n",
      "Epoch 71/10000\n",
      "577/577 - 4s - loss: 0.0388 - val_loss: 0.0567 - 4s/epoch - 8ms/step\n",
      "Epoch 72/10000\n",
      "577/577 - 4s - loss: 0.0409 - val_loss: 0.0597 - 4s/epoch - 8ms/step\n",
      "Epoch 73/10000\n",
      "577/577 - 4s - loss: 0.0398 - val_loss: 0.0523 - 4s/epoch - 8ms/step\n",
      "Epoch 74/10000\n",
      "577/577 - 4s - loss: 0.0390 - val_loss: 0.0532 - 4s/epoch - 8ms/step\n",
      "Epoch 75/10000\n",
      "577/577 - 4s - loss: 0.0384 - val_loss: 0.0569 - 4s/epoch - 8ms/step\n",
      "Epoch 76/10000\n",
      "577/577 - 4s - loss: 0.0442 - val_loss: 0.0546 - 4s/epoch - 8ms/step\n",
      "Epoch 77/10000\n",
      "577/577 - 4s - loss: 0.0376 - val_loss: 0.0516 - 4s/epoch - 8ms/step\n",
      "Epoch 78/10000\n",
      "577/577 - 4s - loss: 0.0378 - val_loss: 0.0528 - 4s/epoch - 8ms/step\n",
      "Epoch 79/10000\n",
      "577/577 - 4s - loss: 0.0370 - val_loss: 0.0516 - 4s/epoch - 8ms/step\n",
      "Epoch 80/10000\n",
      "577/577 - 4s - loss: 0.0377 - val_loss: 0.0557 - 4s/epoch - 8ms/step\n",
      "Epoch 81/10000\n",
      "577/577 - 5s - loss: 0.0393 - val_loss: 0.0566 - 5s/epoch - 8ms/step\n",
      "Epoch 82/10000\n",
      "577/577 - 5s - loss: 0.0384 - val_loss: 0.0611 - 5s/epoch - 8ms/step\n",
      "Epoch 83/10000\n",
      "577/577 - 5s - loss: 0.0377 - val_loss: 0.0522 - 5s/epoch - 8ms/step\n",
      "Epoch 84/10000\n",
      "577/577 - 5s - loss: 0.0353 - val_loss: 0.0515 - 5s/epoch - 8ms/step\n",
      "Epoch 85/10000\n",
      "577/577 - 4s - loss: 0.0366 - val_loss: 0.0528 - 4s/epoch - 8ms/step\n",
      "Epoch 86/10000\n",
      "577/577 - 5s - loss: 0.0358 - val_loss: 0.0531 - 5s/epoch - 8ms/step\n",
      "Epoch 87/10000\n",
      "577/577 - 4s - loss: 0.0367 - val_loss: 0.0542 - 4s/epoch - 8ms/step\n",
      "Epoch 88/10000\n",
      "577/577 - 4s - loss: 0.0368 - val_loss: 0.0556 - 4s/epoch - 8ms/step\n",
      "Epoch 89/10000\n",
      "577/577 - 4s - loss: 0.0362 - val_loss: 0.0519 - 4s/epoch - 8ms/step\n",
      "Epoch 90/10000\n",
      "577/577 - 5s - loss: 0.0354 - val_loss: 0.0573 - 5s/epoch - 8ms/step\n",
      "Epoch 91/10000\n",
      "577/577 - 4s - loss: 0.0348 - val_loss: 0.0509 - 4s/epoch - 8ms/step\n",
      "Epoch 92/10000\n",
      "577/577 - 5s - loss: 0.0352 - val_loss: 0.0560 - 5s/epoch - 8ms/step\n",
      "Epoch 93/10000\n",
      "577/577 - 4s - loss: 0.0351 - val_loss: 0.0496 - 4s/epoch - 8ms/step\n",
      "Epoch 94/10000\n",
      "577/577 - 4s - loss: 0.0351 - val_loss: 0.0565 - 4s/epoch - 8ms/step\n",
      "Epoch 95/10000\n",
      "577/577 - 4s - loss: 0.0351 - val_loss: 0.0516 - 4s/epoch - 8ms/step\n",
      "Epoch 96/10000\n",
      "577/577 - 4s - loss: 0.0340 - val_loss: 0.0505 - 4s/epoch - 8ms/step\n",
      "Epoch 97/10000\n",
      "577/577 - 5s - loss: 0.0340 - val_loss: 0.0497 - 5s/epoch - 8ms/step\n",
      "Epoch 98/10000\n",
      "577/577 - 4s - loss: 0.0342 - val_loss: 0.0531 - 4s/epoch - 8ms/step\n",
      "Epoch 99/10000\n",
      "577/577 - 4s - loss: 0.0350 - val_loss: 0.0503 - 4s/epoch - 8ms/step\n",
      "Epoch 100/10000\n",
      "577/577 - 4s - loss: 0.0336 - val_loss: 0.0481 - 4s/epoch - 8ms/step\n",
      "Epoch 101/10000\n",
      "577/577 - 4s - loss: 0.0336 - val_loss: 0.0486 - 4s/epoch - 8ms/step\n",
      "Epoch 102/10000\n",
      "577/577 - 4s - loss: 0.0329 - val_loss: 0.0503 - 4s/epoch - 8ms/step\n",
      "Epoch 103/10000\n",
      "577/577 - 4s - loss: 0.0347 - val_loss: 0.0503 - 4s/epoch - 7ms/step\n",
      "Epoch 104/10000\n",
      "577/577 - 4s - loss: 0.0401 - val_loss: 0.0492 - 4s/epoch - 7ms/step\n",
      "Epoch 105/10000\n",
      "577/577 - 4s - loss: 0.0323 - val_loss: 0.0477 - 4s/epoch - 7ms/step\n",
      "Epoch 106/10000\n",
      "577/577 - 4s - loss: 0.0316 - val_loss: 0.0480 - 4s/epoch - 7ms/step\n",
      "Epoch 107/10000\n",
      "577/577 - 4s - loss: 0.0321 - val_loss: 0.0509 - 4s/epoch - 7ms/step\n",
      "Epoch 108/10000\n",
      "577/577 - 4s - loss: 0.0332 - val_loss: 0.0479 - 4s/epoch - 8ms/step\n",
      "Epoch 109/10000\n",
      "577/577 - 4s - loss: 0.0322 - val_loss: 0.0501 - 4s/epoch - 8ms/step\n",
      "Epoch 110/10000\n",
      "577/577 - 4s - loss: 0.0319 - val_loss: 0.0481 - 4s/epoch - 8ms/step\n",
      "Epoch 111/10000\n",
      "577/577 - 4s - loss: 0.0335 - val_loss: 0.0487 - 4s/epoch - 8ms/step\n",
      "Epoch 112/10000\n",
      "577/577 - 4s - loss: 0.0324 - val_loss: 0.0490 - 4s/epoch - 8ms/step\n",
      "Epoch 113/10000\n",
      "577/577 - 4s - loss: 0.0336 - val_loss: 0.0503 - 4s/epoch - 8ms/step\n",
      "Epoch 114/10000\n",
      "577/577 - 4s - loss: 0.0311 - val_loss: 0.0517 - 4s/epoch - 8ms/step\n",
      "Epoch 115/10000\n",
      "577/577 - 4s - loss: 0.0325 - val_loss: 0.0498 - 4s/epoch - 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_6_layer_call_fn, gru_cell_6_layer_call_and_return_conditional_losses, gru_cell_7_layer_call_fn, gru_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/20_10_1_50_1_50_datt_seq2seq_gru_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/20_10_1_50_1_50_datt_seq2seq_gru_test\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B892391160> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B892397760> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.939896</td>\n",
       "      <td>0.938575</td>\n",
       "      <td>0.966197</td>\n",
       "      <td>0.948222</td>\n",
       "      <td>3.983003</td>\n",
       "      <td>4.344171</td>\n",
       "      <td>2.853851</td>\n",
       "      <td>3.727008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.865909</td>\n",
       "      <td>0.888874</td>\n",
       "      <td>0.924119</td>\n",
       "      <td>0.892968</td>\n",
       "      <td>5.911371</td>\n",
       "      <td>5.843801</td>\n",
       "      <td>4.275013</td>\n",
       "      <td>5.343395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.770797</td>\n",
       "      <td>0.847084</td>\n",
       "      <td>0.867419</td>\n",
       "      <td>0.828433</td>\n",
       "      <td>7.623488</td>\n",
       "      <td>6.855827</td>\n",
       "      <td>5.649665</td>\n",
       "      <td>6.70966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.670718</td>\n",
       "      <td>0.814696</td>\n",
       "      <td>0.825032</td>\n",
       "      <td>0.770149</td>\n",
       "      <td>9.015987</td>\n",
       "      <td>7.548185</td>\n",
       "      <td>6.488838</td>\n",
       "      <td>7.684337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.573647</td>\n",
       "      <td>0.789861</td>\n",
       "      <td>0.802964</td>\n",
       "      <td>0.722157</td>\n",
       "      <td>10.15732</td>\n",
       "      <td>8.039219</td>\n",
       "      <td>6.88424</td>\n",
       "      <td>8.36026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.481977</td>\n",
       "      <td>0.77107</td>\n",
       "      <td>0.793658</td>\n",
       "      <td>0.682235</td>\n",
       "      <td>11.085772</td>\n",
       "      <td>8.392205</td>\n",
       "      <td>7.043618</td>\n",
       "      <td>8.840532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.398036</td>\n",
       "      <td>0.754914</td>\n",
       "      <td>0.786835</td>\n",
       "      <td>0.646595</td>\n",
       "      <td>11.834433</td>\n",
       "      <td>8.683728</td>\n",
       "      <td>7.158318</td>\n",
       "      <td>9.225493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.322348</td>\n",
       "      <td>0.738591</td>\n",
       "      <td>0.778232</td>\n",
       "      <td>0.613057</td>\n",
       "      <td>12.524737</td>\n",
       "      <td>8.968427</td>\n",
       "      <td>7.301008</td>\n",
       "      <td>9.598057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.254897</td>\n",
       "      <td>0.720638</td>\n",
       "      <td>0.765273</td>\n",
       "      <td>0.580269</td>\n",
       "      <td>13.146295</td>\n",
       "      <td>9.271635</td>\n",
       "      <td>7.511012</td>\n",
       "      <td>9.976314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.196639</td>\n",
       "      <td>0.698618</td>\n",
       "      <td>0.745051</td>\n",
       "      <td>0.546769</td>\n",
       "      <td>13.663907</td>\n",
       "      <td>9.630267</td>\n",
       "      <td>7.827676</td>\n",
       "      <td>10.37395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.547486</td>\n",
       "      <td>0.796292</td>\n",
       "      <td>0.825478</td>\n",
       "      <td>0.723085</td>\n",
       "      <td>9.894631</td>\n",
       "      <td>7.757747</td>\n",
       "      <td>6.299324</td>\n",
       "      <td>7.983901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TT-3061-3 TT-3061-5 LT-3061-2      mean  TT-3061-3 TT-3061-5 LT-3061-2  \\\n",
       "index        R2        R2        R2        R2      nRMSE     nRMSE     nRMSE   \n",
       "0      0.939896  0.938575  0.966197  0.948222   3.983003  4.344171  2.853851   \n",
       "1      0.865909  0.888874  0.924119  0.892968   5.911371  5.843801  4.275013   \n",
       "2      0.770797  0.847084  0.867419  0.828433   7.623488  6.855827  5.649665   \n",
       "3      0.670718  0.814696  0.825032  0.770149   9.015987  7.548185  6.488838   \n",
       "4      0.573647  0.789861  0.802964  0.722157   10.15732  8.039219   6.88424   \n",
       "5      0.481977   0.77107  0.793658  0.682235  11.085772  8.392205  7.043618   \n",
       "6      0.398036  0.754914  0.786835  0.646595  11.834433  8.683728  7.158318   \n",
       "7      0.322348  0.738591  0.778232  0.613057  12.524737  8.968427  7.301008   \n",
       "8      0.254897  0.720638  0.765273  0.580269  13.146295  9.271635  7.511012   \n",
       "9      0.196639  0.698618  0.745051  0.546769  13.663907  9.630267  7.827676   \n",
       "mean   0.547486  0.796292  0.825478  0.723085   9.894631  7.757747  6.299324   \n",
       "\n",
       "           mean  \n",
       "index     nRMSE  \n",
       "0      3.727008  \n",
       "1      5.343395  \n",
       "2       6.70966  \n",
       "3      7.684337  \n",
       "4       8.36026  \n",
       "5      8.840532  \n",
       "6      9.225493  \n",
       "7      9.598057  \n",
       "8      9.976314  \n",
       "9      10.37395  \n",
       "mean   7.983901  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history size: 20\n",
      "future size: 20\n",
      "Epoch 1/10000\n",
      "572/572 - 8s - loss: 0.3117 - val_loss: 0.2381 - 8s/epoch - 14ms/step\n",
      "Epoch 2/10000\n",
      "572/572 - 5s - loss: 0.2293 - val_loss: 0.2273 - 5s/epoch - 8ms/step\n",
      "Epoch 3/10000\n",
      "572/572 - 5s - loss: 0.2132 - val_loss: 0.2100 - 5s/epoch - 8ms/step\n",
      "Epoch 4/10000\n",
      "572/572 - 5s - loss: 0.2033 - val_loss: 0.2048 - 5s/epoch - 8ms/step\n",
      "Epoch 5/10000\n",
      "572/572 - 5s - loss: 0.1921 - val_loss: 0.1919 - 5s/epoch - 8ms/step\n",
      "Epoch 6/10000\n",
      "572/572 - 5s - loss: 0.1823 - val_loss: 0.1900 - 5s/epoch - 8ms/step\n",
      "Epoch 7/10000\n",
      "572/572 - 5s - loss: 0.1759 - val_loss: 0.1856 - 5s/epoch - 8ms/step\n",
      "Epoch 8/10000\n",
      "572/572 - 5s - loss: 0.1676 - val_loss: 0.1766 - 5s/epoch - 8ms/step\n",
      "Epoch 9/10000\n",
      "572/572 - 5s - loss: 0.1615 - val_loss: 0.1728 - 5s/epoch - 8ms/step\n",
      "Epoch 10/10000\n",
      "572/572 - 5s - loss: 0.1538 - val_loss: 0.1640 - 5s/epoch - 8ms/step\n",
      "Epoch 11/10000\n",
      "572/572 - 4s - loss: 0.1487 - val_loss: 0.1565 - 4s/epoch - 8ms/step\n",
      "Epoch 12/10000\n",
      "572/572 - 4s - loss: 0.1425 - val_loss: 0.1505 - 4s/epoch - 8ms/step\n",
      "Epoch 13/10000\n",
      "572/572 - 4s - loss: 0.1369 - val_loss: 0.1560 - 4s/epoch - 8ms/step\n",
      "Epoch 14/10000\n",
      "572/572 - 4s - loss: 0.1327 - val_loss: 0.1479 - 4s/epoch - 8ms/step\n",
      "Epoch 15/10000\n",
      "572/572 - 4s - loss: 0.1274 - val_loss: 0.1379 - 4s/epoch - 8ms/step\n",
      "Epoch 16/10000\n",
      "572/572 - 4s - loss: 0.1219 - val_loss: 0.1348 - 4s/epoch - 8ms/step\n",
      "Epoch 17/10000\n",
      "572/572 - 4s - loss: 0.1215 - val_loss: 0.1329 - 4s/epoch - 8ms/step\n",
      "Epoch 18/10000\n",
      "572/572 - 5s - loss: 0.1156 - val_loss: 0.1302 - 5s/epoch - 8ms/step\n",
      "Epoch 19/10000\n",
      "572/572 - 4s - loss: 0.1144 - val_loss: 0.1306 - 4s/epoch - 8ms/step\n",
      "Epoch 20/10000\n",
      "572/572 - 5s - loss: 0.1089 - val_loss: 0.1312 - 5s/epoch - 8ms/step\n",
      "Epoch 21/10000\n",
      "572/572 - 5s - loss: 0.1070 - val_loss: 0.1248 - 5s/epoch - 8ms/step\n",
      "Epoch 22/10000\n",
      "572/572 - 5s - loss: 0.1092 - val_loss: 0.1270 - 5s/epoch - 8ms/step\n",
      "Epoch 23/10000\n",
      "572/572 - 5s - loss: 0.1061 - val_loss: 0.1169 - 5s/epoch - 8ms/step\n",
      "Epoch 24/10000\n",
      "572/572 - 5s - loss: 0.1000 - val_loss: 0.1212 - 5s/epoch - 8ms/step\n",
      "Epoch 25/10000\n",
      "572/572 - 5s - loss: 0.0996 - val_loss: 0.1127 - 5s/epoch - 8ms/step\n",
      "Epoch 26/10000\n",
      "572/572 - 5s - loss: 0.0998 - val_loss: 0.1143 - 5s/epoch - 8ms/step\n",
      "Epoch 27/10000\n",
      "572/572 - 5s - loss: 0.0980 - val_loss: 0.1150 - 5s/epoch - 8ms/step\n",
      "Epoch 28/10000\n",
      "572/572 - 5s - loss: 0.0963 - val_loss: 0.1096 - 5s/epoch - 8ms/step\n",
      "Epoch 29/10000\n",
      "572/572 - 4s - loss: 0.0937 - val_loss: 0.1100 - 4s/epoch - 8ms/step\n",
      "Epoch 30/10000\n",
      "572/572 - 5s - loss: 0.0922 - val_loss: 0.1105 - 5s/epoch - 8ms/step\n",
      "Epoch 31/10000\n",
      "572/572 - 4s - loss: 0.0920 - val_loss: 0.1032 - 4s/epoch - 8ms/step\n",
      "Epoch 32/10000\n",
      "572/572 - 5s - loss: 0.0897 - val_loss: 0.1094 - 5s/epoch - 8ms/step\n",
      "Epoch 33/10000\n",
      "572/572 - 5s - loss: 0.0898 - val_loss: 0.1070 - 5s/epoch - 8ms/step\n",
      "Epoch 34/10000\n",
      "572/572 - 5s - loss: 0.0870 - val_loss: 0.1039 - 5s/epoch - 8ms/step\n",
      "Epoch 35/10000\n",
      "572/572 - 5s - loss: 0.0872 - val_loss: 0.1030 - 5s/epoch - 8ms/step\n",
      "Epoch 36/10000\n",
      "572/572 - 5s - loss: 0.0866 - val_loss: 0.0990 - 5s/epoch - 8ms/step\n",
      "Epoch 37/10000\n",
      "572/572 - 4s - loss: 0.0841 - val_loss: 0.1004 - 4s/epoch - 8ms/step\n",
      "Epoch 38/10000\n",
      "572/572 - 5s - loss: 0.0834 - val_loss: 0.1021 - 5s/epoch - 8ms/step\n",
      "Epoch 39/10000\n",
      "572/572 - 5s - loss: 0.0840 - val_loss: 0.0987 - 5s/epoch - 8ms/step\n",
      "Epoch 40/10000\n",
      "572/572 - 5s - loss: 0.0829 - val_loss: 0.0954 - 5s/epoch - 8ms/step\n",
      "Epoch 41/10000\n",
      "572/572 - 5s - loss: 0.0810 - val_loss: 0.0989 - 5s/epoch - 8ms/step\n",
      "Epoch 42/10000\n",
      "572/572 - 5s - loss: 0.0807 - val_loss: 0.0946 - 5s/epoch - 8ms/step\n",
      "Epoch 43/10000\n",
      "572/572 - 5s - loss: 0.0785 - val_loss: 0.0942 - 5s/epoch - 8ms/step\n",
      "Epoch 44/10000\n",
      "572/572 - 5s - loss: 0.0803 - val_loss: 0.0944 - 5s/epoch - 8ms/step\n",
      "Epoch 45/10000\n",
      "572/572 - 5s - loss: 0.0782 - val_loss: 0.0993 - 5s/epoch - 8ms/step\n",
      "Epoch 46/10000\n",
      "572/572 - 4s - loss: 0.0784 - val_loss: 0.0915 - 4s/epoch - 8ms/step\n",
      "Epoch 47/10000\n",
      "572/572 - 4s - loss: 0.0767 - val_loss: 0.0906 - 4s/epoch - 8ms/step\n",
      "Epoch 48/10000\n",
      "572/572 - 5s - loss: 0.0763 - val_loss: 0.0910 - 5s/epoch - 8ms/step\n",
      "Epoch 49/10000\n",
      "572/572 - 5s - loss: 0.0752 - val_loss: 0.0922 - 5s/epoch - 8ms/step\n",
      "Epoch 50/10000\n",
      "572/572 - 5s - loss: 0.0744 - val_loss: 0.0874 - 5s/epoch - 8ms/step\n",
      "Epoch 51/10000\n",
      "572/572 - 5s - loss: 0.0736 - val_loss: 0.0905 - 5s/epoch - 8ms/step\n",
      "Epoch 52/10000\n",
      "572/572 - 5s - loss: 0.0753 - val_loss: 0.0867 - 5s/epoch - 8ms/step\n",
      "Epoch 53/10000\n",
      "572/572 - 5s - loss: 0.0711 - val_loss: 0.0839 - 5s/epoch - 8ms/step\n",
      "Epoch 54/10000\n",
      "572/572 - 4s - loss: 0.0736 - val_loss: 0.0883 - 4s/epoch - 8ms/step\n",
      "Epoch 55/10000\n",
      "572/572 - 5s - loss: 0.0709 - val_loss: 0.0864 - 5s/epoch - 8ms/step\n",
      "Epoch 56/10000\n",
      "572/572 - 4s - loss: 0.0755 - val_loss: 0.0862 - 4s/epoch - 8ms/step\n",
      "Epoch 57/10000\n",
      "572/572 - 4s - loss: 0.0753 - val_loss: 0.0852 - 4s/epoch - 8ms/step\n",
      "Epoch 58/10000\n",
      "572/572 - 5s - loss: 0.0686 - val_loss: 0.0783 - 5s/epoch - 8ms/step\n",
      "Epoch 59/10000\n",
      "572/572 - 5s - loss: 0.0693 - val_loss: 0.0829 - 5s/epoch - 8ms/step\n",
      "Epoch 60/10000\n",
      "572/572 - 5s - loss: 0.0687 - val_loss: 0.0779 - 5s/epoch - 8ms/step\n",
      "Epoch 61/10000\n",
      "572/572 - 4s - loss: 0.0665 - val_loss: 0.0922 - 4s/epoch - 8ms/step\n",
      "Epoch 62/10000\n",
      "572/572 - 5s - loss: 0.0709 - val_loss: 0.0979 - 5s/epoch - 8ms/step\n",
      "Epoch 63/10000\n",
      "572/572 - 5s - loss: 0.0690 - val_loss: 0.0765 - 5s/epoch - 8ms/step\n",
      "Epoch 64/10000\n",
      "572/572 - 5s - loss: 0.0647 - val_loss: 0.0946 - 5s/epoch - 8ms/step\n",
      "Epoch 65/10000\n",
      "572/572 - 4s - loss: 0.0670 - val_loss: 0.0766 - 4s/epoch - 8ms/step\n",
      "Epoch 66/10000\n",
      "572/572 - 5s - loss: 0.0639 - val_loss: 0.0798 - 5s/epoch - 8ms/step\n",
      "Epoch 67/10000\n",
      "572/572 - 5s - loss: 0.0642 - val_loss: 0.0828 - 5s/epoch - 8ms/step\n",
      "Epoch 68/10000\n",
      "572/572 - 4s - loss: 0.0646 - val_loss: 0.0754 - 4s/epoch - 8ms/step\n",
      "Epoch 69/10000\n",
      "572/572 - 5s - loss: 0.0703 - val_loss: 0.0769 - 5s/epoch - 8ms/step\n",
      "Epoch 70/10000\n",
      "572/572 - 5s - loss: 0.0630 - val_loss: 0.0749 - 5s/epoch - 8ms/step\n",
      "Epoch 71/10000\n",
      "572/572 - 4s - loss: 0.0622 - val_loss: 0.0720 - 4s/epoch - 8ms/step\n",
      "Epoch 72/10000\n",
      "572/572 - 5s - loss: 0.0600 - val_loss: 0.0736 - 5s/epoch - 8ms/step\n",
      "Epoch 73/10000\n",
      "572/572 - 5s - loss: 0.0622 - val_loss: 0.0731 - 5s/epoch - 8ms/step\n",
      "Epoch 74/10000\n",
      "572/572 - 5s - loss: 0.0634 - val_loss: 0.0717 - 5s/epoch - 8ms/step\n",
      "Epoch 75/10000\n",
      "572/572 - 4s - loss: 0.0659 - val_loss: 0.0770 - 4s/epoch - 8ms/step\n",
      "Epoch 76/10000\n",
      "572/572 - 4s - loss: 0.0619 - val_loss: 0.0720 - 4s/epoch - 8ms/step\n",
      "Epoch 77/10000\n",
      "572/572 - 4s - loss: 0.0619 - val_loss: 0.0716 - 4s/epoch - 8ms/step\n",
      "Epoch 78/10000\n",
      "572/572 - 4s - loss: 0.0588 - val_loss: 0.0724 - 4s/epoch - 8ms/step\n",
      "Epoch 79/10000\n",
      "572/572 - 4s - loss: 0.0585 - val_loss: 0.0768 - 4s/epoch - 8ms/step\n",
      "Epoch 80/10000\n",
      "572/572 - 4s - loss: 0.0590 - val_loss: 0.0692 - 4s/epoch - 8ms/step\n",
      "Epoch 81/10000\n",
      "572/572 - 4s - loss: 0.0574 - val_loss: 0.0724 - 4s/epoch - 8ms/step\n",
      "Epoch 82/10000\n",
      "572/572 - 4s - loss: 0.0631 - val_loss: 0.0725 - 4s/epoch - 8ms/step\n",
      "Epoch 83/10000\n",
      "572/572 - 5s - loss: 0.0621 - val_loss: 0.0688 - 5s/epoch - 8ms/step\n",
      "Epoch 84/10000\n",
      "572/572 - 5s - loss: 0.0557 - val_loss: 0.0680 - 5s/epoch - 8ms/step\n",
      "Epoch 85/10000\n",
      "572/572 - 5s - loss: 0.0553 - val_loss: 0.0697 - 5s/epoch - 8ms/step\n",
      "Epoch 86/10000\n",
      "572/572 - 4s - loss: 0.0561 - val_loss: 0.0681 - 4s/epoch - 8ms/step\n",
      "Epoch 87/10000\n",
      "572/572 - 5s - loss: 0.0632 - val_loss: 0.0928 - 5s/epoch - 8ms/step\n",
      "Epoch 88/10000\n",
      "572/572 - 5s - loss: 0.0650 - val_loss: 0.0702 - 5s/epoch - 8ms/step\n",
      "Epoch 89/10000\n",
      "572/572 - 5s - loss: 0.0553 - val_loss: 0.0729 - 5s/epoch - 8ms/step\n",
      "Epoch 90/10000\n",
      "572/572 - 5s - loss: 0.0555 - val_loss: 0.0687 - 5s/epoch - 8ms/step\n",
      "Epoch 91/10000\n",
      "572/572 - 5s - loss: 0.0563 - val_loss: 0.0667 - 5s/epoch - 8ms/step\n",
      "Epoch 92/10000\n",
      "572/572 - 5s - loss: 0.0538 - val_loss: 0.0760 - 5s/epoch - 8ms/step\n",
      "Epoch 93/10000\n",
      "572/572 - 5s - loss: 0.0573 - val_loss: 0.0682 - 5s/epoch - 8ms/step\n",
      "Epoch 94/10000\n",
      "572/572 - 5s - loss: 0.0532 - val_loss: 0.0645 - 5s/epoch - 8ms/step\n",
      "Epoch 95/10000\n",
      "572/572 - 5s - loss: 0.0539 - val_loss: 0.0655 - 5s/epoch - 8ms/step\n",
      "Epoch 96/10000\n",
      "572/572 - 5s - loss: 0.0524 - val_loss: 0.0679 - 5s/epoch - 8ms/step\n",
      "Epoch 97/10000\n",
      "572/572 - 4s - loss: 0.0533 - val_loss: 0.0661 - 4s/epoch - 8ms/step\n",
      "Epoch 98/10000\n",
      "572/572 - 5s - loss: 0.0605 - val_loss: 0.0861 - 5s/epoch - 8ms/step\n",
      "Epoch 99/10000\n",
      "572/572 - 5s - loss: 0.0692 - val_loss: 0.0811 - 5s/epoch - 8ms/step\n",
      "Epoch 100/10000\n",
      "572/572 - 5s - loss: 0.0606 - val_loss: 0.0869 - 5s/epoch - 8ms/step\n",
      "Epoch 101/10000\n",
      "572/572 - 5s - loss: 0.0543 - val_loss: 0.0653 - 5s/epoch - 8ms/step\n",
      "Epoch 102/10000\n",
      "572/572 - 4s - loss: 0.0517 - val_loss: 0.0640 - 4s/epoch - 8ms/step\n",
      "Epoch 103/10000\n",
      "572/572 - 5s - loss: 0.0506 - val_loss: 0.0626 - 5s/epoch - 8ms/step\n",
      "Epoch 104/10000\n",
      "572/572 - 5s - loss: 0.0523 - val_loss: 0.0656 - 5s/epoch - 8ms/step\n",
      "Epoch 105/10000\n",
      "572/572 - 5s - loss: 0.0513 - val_loss: 0.0625 - 5s/epoch - 8ms/step\n",
      "Epoch 106/10000\n",
      "572/572 - 5s - loss: 0.0510 - val_loss: 0.0675 - 5s/epoch - 8ms/step\n",
      "Epoch 107/10000\n",
      "572/572 - 4s - loss: 0.0517 - val_loss: 0.0637 - 4s/epoch - 8ms/step\n",
      "Epoch 108/10000\n",
      "572/572 - 5s - loss: 0.0504 - val_loss: 0.0621 - 5s/epoch - 8ms/step\n",
      "Epoch 109/10000\n",
      "572/572 - 4s - loss: 0.0526 - val_loss: 0.0771 - 4s/epoch - 8ms/step\n",
      "Epoch 110/10000\n",
      "572/572 - 5s - loss: 0.0571 - val_loss: 0.0719 - 5s/epoch - 8ms/step\n",
      "Epoch 111/10000\n",
      "572/572 - 4s - loss: 0.0523 - val_loss: 0.0744 - 4s/epoch - 8ms/step\n",
      "Epoch 112/10000\n",
      "572/572 - 5s - loss: 0.0614 - val_loss: 0.0634 - 5s/epoch - 8ms/step\n",
      "Epoch 113/10000\n",
      "572/572 - 5s - loss: 0.0501 - val_loss: 0.0651 - 5s/epoch - 8ms/step\n",
      "Epoch 114/10000\n",
      "572/572 - 5s - loss: 0.0532 - val_loss: 0.0595 - 5s/epoch - 8ms/step\n",
      "Epoch 115/10000\n",
      "572/572 - 4s - loss: 0.0504 - val_loss: 0.0620 - 4s/epoch - 8ms/step\n",
      "Epoch 116/10000\n",
      "572/572 - 4s - loss: 0.0489 - val_loss: 0.0599 - 4s/epoch - 8ms/step\n",
      "Epoch 117/10000\n",
      "572/572 - 4s - loss: 0.0504 - val_loss: 0.0630 - 4s/epoch - 8ms/step\n",
      "Epoch 118/10000\n",
      "572/572 - 4s - loss: 0.0505 - val_loss: 0.0617 - 4s/epoch - 8ms/step\n",
      "Epoch 119/10000\n",
      "572/572 - 4s - loss: 0.0515 - val_loss: 0.0851 - 4s/epoch - 8ms/step\n",
      "Epoch 120/10000\n",
      "572/572 - 4s - loss: 0.0539 - val_loss: 0.0633 - 4s/epoch - 8ms/step\n",
      "Epoch 121/10000\n",
      "572/572 - 4s - loss: 0.0484 - val_loss: 0.0654 - 4s/epoch - 8ms/step\n",
      "Epoch 122/10000\n",
      "572/572 - 4s - loss: 0.0564 - val_loss: 0.0586 - 4s/epoch - 8ms/step\n",
      "Epoch 123/10000\n",
      "572/572 - 4s - loss: 0.0469 - val_loss: 0.0608 - 4s/epoch - 8ms/step\n",
      "Epoch 124/10000\n",
      "572/572 - 5s - loss: 0.0476 - val_loss: 0.0604 - 5s/epoch - 8ms/step\n",
      "Epoch 125/10000\n",
      "572/572 - 5s - loss: 0.0485 - val_loss: 0.0617 - 5s/epoch - 8ms/step\n",
      "Epoch 126/10000\n",
      "572/572 - 4s - loss: 0.0479 - val_loss: 0.0597 - 4s/epoch - 8ms/step\n",
      "Epoch 127/10000\n",
      "572/572 - 4s - loss: 0.0479 - val_loss: 0.0628 - 4s/epoch - 8ms/step\n",
      "Epoch 128/10000\n",
      "572/572 - 5s - loss: 0.0485 - val_loss: 0.0638 - 5s/epoch - 8ms/step\n",
      "Epoch 129/10000\n",
      "572/572 - 5s - loss: 0.0567 - val_loss: 0.0619 - 5s/epoch - 8ms/step\n",
      "Epoch 130/10000\n",
      "572/572 - 5s - loss: 0.0477 - val_loss: 0.0604 - 5s/epoch - 8ms/step\n",
      "Epoch 131/10000\n",
      "572/572 - 5s - loss: 0.0452 - val_loss: 0.0592 - 5s/epoch - 8ms/step\n",
      "Epoch 132/10000\n",
      "572/572 - 5s - loss: 0.0464 - val_loss: 0.0619 - 5s/epoch - 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_8_layer_call_fn, gru_cell_8_layer_call_and_return_conditional_losses, gru_cell_9_layer_call_fn, gru_cell_9_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/20_20_1_50_1_50_datt_seq2seq_gru_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/20_20_1_50_1_50_datt_seq2seq_gru_test\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7ED85D250> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B87855D7C0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.881752</td>\n",
       "      <td>0.928888</td>\n",
       "      <td>0.952048</td>\n",
       "      <td>0.920896</td>\n",
       "      <td>6.794471</td>\n",
       "      <td>4.668829</td>\n",
       "      <td>3.387834</td>\n",
       "      <td>4.950378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.788771</td>\n",
       "      <td>0.865603</td>\n",
       "      <td>0.916635</td>\n",
       "      <td>0.857003</td>\n",
       "      <td>8.916298</td>\n",
       "      <td>6.420532</td>\n",
       "      <td>4.466337</td>\n",
       "      <td>6.601056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.65967</td>\n",
       "      <td>0.816956</td>\n",
       "      <td>0.878636</td>\n",
       "      <td>0.785087</td>\n",
       "      <td>10.823862</td>\n",
       "      <td>7.495765</td>\n",
       "      <td>5.388206</td>\n",
       "      <td>7.902611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.543054</td>\n",
       "      <td>0.78344</td>\n",
       "      <td>0.846654</td>\n",
       "      <td>0.724383</td>\n",
       "      <td>12.12295</td>\n",
       "      <td>8.156062</td>\n",
       "      <td>6.05587</td>\n",
       "      <td>8.778294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.444603</td>\n",
       "      <td>0.755349</td>\n",
       "      <td>0.822983</td>\n",
       "      <td>0.674312</td>\n",
       "      <td>13.150751</td>\n",
       "      <td>8.672811</td>\n",
       "      <td>6.505865</td>\n",
       "      <td>9.443142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.356287</td>\n",
       "      <td>0.729544</td>\n",
       "      <td>0.805797</td>\n",
       "      <td>0.630543</td>\n",
       "      <td>14.10852</td>\n",
       "      <td>9.12327</td>\n",
       "      <td>6.813337</td>\n",
       "      <td>10.015042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.27567</td>\n",
       "      <td>0.707194</td>\n",
       "      <td>0.79164</td>\n",
       "      <td>0.591502</td>\n",
       "      <td>14.670884</td>\n",
       "      <td>9.49548</td>\n",
       "      <td>7.05636</td>\n",
       "      <td>10.407575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.203402</td>\n",
       "      <td>0.686527</td>\n",
       "      <td>0.77621</td>\n",
       "      <td>0.555379</td>\n",
       "      <td>15.088581</td>\n",
       "      <td>9.828003</td>\n",
       "      <td>7.31149</td>\n",
       "      <td>10.742692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.138477</td>\n",
       "      <td>0.666333</td>\n",
       "      <td>0.755348</td>\n",
       "      <td>0.520052</td>\n",
       "      <td>15.455667</td>\n",
       "      <td>10.142988</td>\n",
       "      <td>7.642776</td>\n",
       "      <td>11.080477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.080726</td>\n",
       "      <td>0.645219</td>\n",
       "      <td>0.722551</td>\n",
       "      <td>0.482832</td>\n",
       "      <td>15.729598</td>\n",
       "      <td>10.460988</td>\n",
       "      <td>8.136379</td>\n",
       "      <td>11.442322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.024657</td>\n",
       "      <td>0.624069</td>\n",
       "      <td>0.677074</td>\n",
       "      <td>0.441933</td>\n",
       "      <td>16.028824</td>\n",
       "      <td>10.770108</td>\n",
       "      <td>8.775524</td>\n",
       "      <td>11.858152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.031201</td>\n",
       "      <td>0.604475</td>\n",
       "      <td>0.627279</td>\n",
       "      <td>0.400184</td>\n",
       "      <td>16.372014</td>\n",
       "      <td>11.048548</td>\n",
       "      <td>9.426251</td>\n",
       "      <td>12.282271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.087473</td>\n",
       "      <td>0.583326</td>\n",
       "      <td>0.58368</td>\n",
       "      <td>0.359844</td>\n",
       "      <td>16.579625</td>\n",
       "      <td>11.34116</td>\n",
       "      <td>9.961565</td>\n",
       "      <td>12.62745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.141901</td>\n",
       "      <td>0.560716</td>\n",
       "      <td>0.549568</td>\n",
       "      <td>0.322794</td>\n",
       "      <td>16.76056</td>\n",
       "      <td>11.646306</td>\n",
       "      <td>10.361738</td>\n",
       "      <td>12.922868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.190646</td>\n",
       "      <td>0.536104</td>\n",
       "      <td>0.522589</td>\n",
       "      <td>0.289349</td>\n",
       "      <td>16.944682</td>\n",
       "      <td>11.969698</td>\n",
       "      <td>10.667235</td>\n",
       "      <td>13.193871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.229624</td>\n",
       "      <td>0.510454</td>\n",
       "      <td>0.50145</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>17.053182</td>\n",
       "      <td>12.298032</td>\n",
       "      <td>10.900923</td>\n",
       "      <td>13.417379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.258326</td>\n",
       "      <td>0.483368</td>\n",
       "      <td>0.484831</td>\n",
       "      <td>0.236624</td>\n",
       "      <td>17.087979</td>\n",
       "      <td>12.634575</td>\n",
       "      <td>11.08165</td>\n",
       "      <td>13.601401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.280921</td>\n",
       "      <td>0.456121</td>\n",
       "      <td>0.471026</td>\n",
       "      <td>0.215409</td>\n",
       "      <td>17.202808</td>\n",
       "      <td>12.963811</td>\n",
       "      <td>11.230141</td>\n",
       "      <td>13.79892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.300174</td>\n",
       "      <td>0.430933</td>\n",
       "      <td>0.4575</td>\n",
       "      <td>0.196086</td>\n",
       "      <td>17.355946</td>\n",
       "      <td>13.260972</td>\n",
       "      <td>11.373583</td>\n",
       "      <td>13.996834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.317135</td>\n",
       "      <td>0.411149</td>\n",
       "      <td>0.444552</td>\n",
       "      <td>0.179522</td>\n",
       "      <td>17.493895</td>\n",
       "      <td>13.489596</td>\n",
       "      <td>11.509813</td>\n",
       "      <td>14.164435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.127983</td>\n",
       "      <td>0.639288</td>\n",
       "      <td>0.679403</td>\n",
       "      <td>0.482225</td>\n",
       "      <td>14.787055</td>\n",
       "      <td>10.294377</td>\n",
       "      <td>8.402644</td>\n",
       "      <td>11.161358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TT-3061-3 TT-3061-5 LT-3061-2      mean  TT-3061-3  TT-3061-5  \\\n",
       "index        R2        R2        R2        R2      nRMSE      nRMSE   \n",
       "0      0.881752  0.928888  0.952048  0.920896   6.794471   4.668829   \n",
       "1      0.788771  0.865603  0.916635  0.857003   8.916298   6.420532   \n",
       "2       0.65967  0.816956  0.878636  0.785087  10.823862   7.495765   \n",
       "3      0.543054   0.78344  0.846654  0.724383   12.12295   8.156062   \n",
       "4      0.444603  0.755349  0.822983  0.674312  13.150751   8.672811   \n",
       "5      0.356287  0.729544  0.805797  0.630543   14.10852    9.12327   \n",
       "6       0.27567  0.707194   0.79164  0.591502  14.670884    9.49548   \n",
       "7      0.203402  0.686527   0.77621  0.555379  15.088581   9.828003   \n",
       "8      0.138477  0.666333  0.755348  0.520052  15.455667  10.142988   \n",
       "9      0.080726  0.645219  0.722551  0.482832  15.729598  10.460988   \n",
       "10     0.024657  0.624069  0.677074  0.441933  16.028824  10.770108   \n",
       "11    -0.031201  0.604475  0.627279  0.400184  16.372014  11.048548   \n",
       "12    -0.087473  0.583326   0.58368  0.359844  16.579625   11.34116   \n",
       "13    -0.141901  0.560716  0.549568  0.322794   16.76056  11.646306   \n",
       "14    -0.190646  0.536104  0.522589  0.289349  16.944682  11.969698   \n",
       "15    -0.229624  0.510454   0.50145   0.26076  17.053182  12.298032   \n",
       "16    -0.258326  0.483368  0.484831  0.236624  17.087979  12.634575   \n",
       "17    -0.280921  0.456121  0.471026  0.215409  17.202808  12.963811   \n",
       "18    -0.300174  0.430933    0.4575  0.196086  17.355946  13.260972   \n",
       "19    -0.317135  0.411149  0.444552  0.179522  17.493895  13.489596   \n",
       "mean   0.127983  0.639288  0.679403  0.482225  14.787055  10.294377   \n",
       "\n",
       "       LT-3061-2       mean  \n",
       "index      nRMSE      nRMSE  \n",
       "0       3.387834   4.950378  \n",
       "1       4.466337   6.601056  \n",
       "2       5.388206   7.902611  \n",
       "3        6.05587   8.778294  \n",
       "4       6.505865   9.443142  \n",
       "5       6.813337  10.015042  \n",
       "6        7.05636  10.407575  \n",
       "7        7.31149  10.742692  \n",
       "8       7.642776  11.080477  \n",
       "9       8.136379  11.442322  \n",
       "10      8.775524  11.858152  \n",
       "11      9.426251  12.282271  \n",
       "12      9.961565   12.62745  \n",
       "13     10.361738  12.922868  \n",
       "14     10.667235  13.193871  \n",
       "15     10.900923  13.417379  \n",
       "16      11.08165  13.601401  \n",
       "17     11.230141   13.79892  \n",
       "18     11.373583  13.996834  \n",
       "19     11.509813  14.164435  \n",
       "mean    8.402644  11.161358  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history size: 20\n",
      "future size: 30\n",
      "Epoch 1/10000\n",
      "568/568 - 8s - loss: 0.3765 - val_loss: 0.3190 - 8s/epoch - 14ms/step\n",
      "Epoch 2/10000\n",
      "568/568 - 5s - loss: 0.2878 - val_loss: 0.3024 - 5s/epoch - 8ms/step\n",
      "Epoch 3/10000\n",
      "568/568 - 4s - loss: 0.2659 - val_loss: 0.2868 - 4s/epoch - 7ms/step\n",
      "Epoch 4/10000\n",
      "568/568 - 4s - loss: 0.2516 - val_loss: 0.2801 - 4s/epoch - 7ms/step\n",
      "Epoch 5/10000\n",
      "568/568 - 4s - loss: 0.2394 - val_loss: 0.2504 - 4s/epoch - 8ms/step\n",
      "Epoch 6/10000\n",
      "568/568 - 4s - loss: 0.2230 - val_loss: 0.2510 - 4s/epoch - 7ms/step\n",
      "Epoch 7/10000\n",
      "568/568 - 4s - loss: 0.2114 - val_loss: 0.2314 - 4s/epoch - 7ms/step\n",
      "Epoch 8/10000\n",
      "568/568 - 4s - loss: 0.2024 - val_loss: 0.2256 - 4s/epoch - 7ms/step\n",
      "Epoch 9/10000\n",
      "568/568 - 4s - loss: 0.1931 - val_loss: 0.2267 - 4s/epoch - 7ms/step\n",
      "Epoch 10/10000\n",
      "568/568 - 4s - loss: 0.1848 - val_loss: 0.2155 - 4s/epoch - 7ms/step\n",
      "Epoch 11/10000\n",
      "568/568 - 4s - loss: 0.1793 - val_loss: 0.1983 - 4s/epoch - 7ms/step\n",
      "Epoch 12/10000\n",
      "568/568 - 4s - loss: 0.1746 - val_loss: 0.1921 - 4s/epoch - 8ms/step\n",
      "Epoch 13/10000\n",
      "568/568 - 4s - loss: 0.1653 - val_loss: 0.1873 - 4s/epoch - 7ms/step\n",
      "Epoch 14/10000\n",
      "568/568 - 4s - loss: 0.1638 - val_loss: 0.1861 - 4s/epoch - 7ms/step\n",
      "Epoch 15/10000\n",
      "568/568 - 4s - loss: 0.1566 - val_loss: 0.1828 - 4s/epoch - 7ms/step\n",
      "Epoch 16/10000\n",
      "568/568 - 4s - loss: 0.1516 - val_loss: 0.1733 - 4s/epoch - 7ms/step\n",
      "Epoch 17/10000\n",
      "568/568 - 4s - loss: 0.1505 - val_loss: 0.1715 - 4s/epoch - 7ms/step\n",
      "Epoch 18/10000\n",
      "568/568 - 4s - loss: 0.1465 - val_loss: 0.1636 - 4s/epoch - 8ms/step\n",
      "Epoch 19/10000\n",
      "568/568 - 4s - loss: 0.1414 - val_loss: 0.1615 - 4s/epoch - 7ms/step\n",
      "Epoch 20/10000\n",
      "568/568 - 4s - loss: 0.1392 - val_loss: 0.1723 - 4s/epoch - 7ms/step\n",
      "Epoch 21/10000\n",
      "568/568 - 4s - loss: 0.1394 - val_loss: 0.1652 - 4s/epoch - 7ms/step\n",
      "Epoch 22/10000\n",
      "568/568 - 4s - loss: 0.1360 - val_loss: 0.1575 - 4s/epoch - 7ms/step\n",
      "Epoch 23/10000\n",
      "568/568 - 4s - loss: 0.1316 - val_loss: 0.1820 - 4s/epoch - 7ms/step\n",
      "Epoch 24/10000\n",
      "568/568 - 4s - loss: 0.1317 - val_loss: 0.1518 - 4s/epoch - 7ms/step\n",
      "Epoch 25/10000\n",
      "568/568 - 4s - loss: 0.1267 - val_loss: 0.1470 - 4s/epoch - 7ms/step\n",
      "Epoch 26/10000\n",
      "568/568 - 4s - loss: 0.1245 - val_loss: 0.1593 - 4s/epoch - 7ms/step\n",
      "Epoch 27/10000\n",
      "568/568 - 4s - loss: 0.1241 - val_loss: 0.1395 - 4s/epoch - 8ms/step\n",
      "Epoch 28/10000\n",
      "568/568 - 4s - loss: 0.1219 - val_loss: 0.1519 - 4s/epoch - 7ms/step\n",
      "Epoch 29/10000\n",
      "568/568 - 4s - loss: 0.1207 - val_loss: 0.1434 - 4s/epoch - 7ms/step\n",
      "Epoch 30/10000\n",
      "568/568 - 4s - loss: 0.1169 - val_loss: 0.1411 - 4s/epoch - 7ms/step\n",
      "Epoch 31/10000\n",
      "568/568 - 4s - loss: 0.1163 - val_loss: 0.1354 - 4s/epoch - 7ms/step\n",
      "Epoch 32/10000\n",
      "568/568 - 4s - loss: 0.1197 - val_loss: 0.1330 - 4s/epoch - 8ms/step\n",
      "Epoch 33/10000\n",
      "568/568 - 4s - loss: 0.1145 - val_loss: 0.1362 - 4s/epoch - 7ms/step\n",
      "Epoch 34/10000\n",
      "568/568 - 4s - loss: 0.1107 - val_loss: 0.1362 - 4s/epoch - 7ms/step\n",
      "Epoch 35/10000\n",
      "568/568 - 4s - loss: 0.1099 - val_loss: 0.1306 - 4s/epoch - 7ms/step\n",
      "Epoch 36/10000\n",
      "568/568 - 4s - loss: 0.1093 - val_loss: 0.1342 - 4s/epoch - 7ms/step\n",
      "Epoch 37/10000\n",
      "568/568 - 4s - loss: 0.1070 - val_loss: 0.1284 - 4s/epoch - 7ms/step\n",
      "Epoch 38/10000\n",
      "568/568 - 4s - loss: 0.1092 - val_loss: 0.1286 - 4s/epoch - 7ms/step\n",
      "Epoch 39/10000\n",
      "568/568 - 4s - loss: 0.1040 - val_loss: 0.1310 - 4s/epoch - 7ms/step\n",
      "Epoch 40/10000\n",
      "568/568 - 4s - loss: 0.1035 - val_loss: 0.1226 - 4s/epoch - 7ms/step\n",
      "Epoch 41/10000\n",
      "568/568 - 4s - loss: 0.1010 - val_loss: 0.1228 - 4s/epoch - 8ms/step\n",
      "Epoch 42/10000\n",
      "568/568 - 4s - loss: 0.1018 - val_loss: 0.1189 - 4s/epoch - 7ms/step\n",
      "Epoch 43/10000\n",
      "568/568 - 4s - loss: 0.1002 - val_loss: 0.1236 - 4s/epoch - 7ms/step\n",
      "Epoch 44/10000\n",
      "568/568 - 4s - loss: 0.0994 - val_loss: 0.1233 - 4s/epoch - 7ms/step\n",
      "Epoch 45/10000\n",
      "568/568 - 4s - loss: 0.0972 - val_loss: 0.1233 - 4s/epoch - 7ms/step\n",
      "Epoch 46/10000\n",
      "568/568 - 4s - loss: 0.0949 - val_loss: 0.1141 - 4s/epoch - 7ms/step\n",
      "Epoch 47/10000\n",
      "568/568 - 4s - loss: 0.0968 - val_loss: 0.1201 - 4s/epoch - 7ms/step\n",
      "Epoch 48/10000\n",
      "568/568 - 4s - loss: 0.0955 - val_loss: 0.1234 - 4s/epoch - 8ms/step\n",
      "Epoch 49/10000\n",
      "568/568 - 4s - loss: 0.0928 - val_loss: 0.1118 - 4s/epoch - 7ms/step\n",
      "Epoch 50/10000\n",
      "568/568 - 4s - loss: 0.0927 - val_loss: 0.1219 - 4s/epoch - 8ms/step\n",
      "Epoch 51/10000\n",
      "568/568 - 4s - loss: 0.0948 - val_loss: 0.1055 - 4s/epoch - 7ms/step\n",
      "Epoch 52/10000\n",
      "568/568 - 4s - loss: 0.0923 - val_loss: 0.1205 - 4s/epoch - 7ms/step\n",
      "Epoch 53/10000\n",
      "568/568 - 4s - loss: 0.0928 - val_loss: 0.1024 - 4s/epoch - 7ms/step\n",
      "Epoch 54/10000\n",
      "568/568 - 4s - loss: 0.0956 - val_loss: 0.1197 - 4s/epoch - 7ms/step\n",
      "Epoch 55/10000\n",
      "568/568 - 4s - loss: 0.0854 - val_loss: 0.1053 - 4s/epoch - 7ms/step\n",
      "Epoch 56/10000\n",
      "568/568 - 4s - loss: 0.0883 - val_loss: 0.1022 - 4s/epoch - 7ms/step\n",
      "Epoch 57/10000\n",
      "568/568 - 4s - loss: 0.0876 - val_loss: 0.0989 - 4s/epoch - 7ms/step\n",
      "Epoch 58/10000\n",
      "568/568 - 4s - loss: 0.0856 - val_loss: 0.1032 - 4s/epoch - 7ms/step\n",
      "Epoch 59/10000\n",
      "568/568 - 4s - loss: 0.0826 - val_loss: 0.1001 - 4s/epoch - 7ms/step\n",
      "Epoch 60/10000\n",
      "568/568 - 4s - loss: 0.0840 - val_loss: 0.0984 - 4s/epoch - 7ms/step\n",
      "Epoch 61/10000\n",
      "568/568 - 4s - loss: 0.0826 - val_loss: 0.1095 - 4s/epoch - 7ms/step\n",
      "Epoch 62/10000\n",
      "568/568 - 4s - loss: 0.0859 - val_loss: 0.1049 - 4s/epoch - 7ms/step\n",
      "Epoch 63/10000\n",
      "568/568 - 4s - loss: 0.0829 - val_loss: 0.0973 - 4s/epoch - 7ms/step\n",
      "Epoch 64/10000\n",
      "568/568 - 4s - loss: 0.0840 - val_loss: 0.1724 - 4s/epoch - 7ms/step\n",
      "Epoch 65/10000\n",
      "568/568 - 4s - loss: 0.0935 - val_loss: 0.1122 - 4s/epoch - 7ms/step\n",
      "Epoch 66/10000\n",
      "568/568 - 4s - loss: 0.0807 - val_loss: 0.1130 - 4s/epoch - 7ms/step\n",
      "Epoch 67/10000\n",
      "568/568 - 4s - loss: 0.0870 - val_loss: 0.0970 - 4s/epoch - 7ms/step\n",
      "Epoch 68/10000\n",
      "568/568 - 4s - loss: 0.0781 - val_loss: 0.0953 - 4s/epoch - 7ms/step\n",
      "Epoch 69/10000\n",
      "568/568 - 4s - loss: 0.0784 - val_loss: 0.0931 - 4s/epoch - 7ms/step\n",
      "Epoch 70/10000\n",
      "568/568 - 4s - loss: 0.0776 - val_loss: 0.1318 - 4s/epoch - 7ms/step\n",
      "Epoch 71/10000\n",
      "568/568 - 4s - loss: 0.0819 - val_loss: 0.0978 - 4s/epoch - 8ms/step\n",
      "Epoch 72/10000\n",
      "568/568 - 4s - loss: 0.0767 - val_loss: 0.0963 - 4s/epoch - 7ms/step\n",
      "Epoch 73/10000\n",
      "568/568 - 4s - loss: 0.0755 - val_loss: 0.0970 - 4s/epoch - 7ms/step\n",
      "Epoch 74/10000\n",
      "568/568 - 4s - loss: 0.0762 - val_loss: 0.0890 - 4s/epoch - 7ms/step\n",
      "Epoch 75/10000\n",
      "568/568 - 4s - loss: 0.0766 - val_loss: 0.0966 - 4s/epoch - 7ms/step\n",
      "Epoch 76/10000\n",
      "568/568 - 4s - loss: 0.0743 - val_loss: 0.1122 - 4s/epoch - 8ms/step\n",
      "Epoch 77/10000\n",
      "568/568 - 4s - loss: 0.0801 - val_loss: 0.1067 - 4s/epoch - 7ms/step\n",
      "Epoch 78/10000\n",
      "568/568 - 4s - loss: 0.0771 - val_loss: 0.0904 - 4s/epoch - 7ms/step\n",
      "Epoch 79/10000\n",
      "568/568 - 4s - loss: 0.0749 - val_loss: 0.0867 - 4s/epoch - 7ms/step\n",
      "Epoch 80/10000\n",
      "568/568 - 4s - loss: 0.0731 - val_loss: 0.0921 - 4s/epoch - 7ms/step\n",
      "Epoch 81/10000\n",
      "568/568 - 4s - loss: 0.0716 - val_loss: 0.0920 - 4s/epoch - 7ms/step\n",
      "Epoch 82/10000\n",
      "568/568 - 4s - loss: 0.0716 - val_loss: 0.0908 - 4s/epoch - 7ms/step\n",
      "Epoch 83/10000\n",
      "568/568 - 4s - loss: 0.0719 - val_loss: 0.1264 - 4s/epoch - 7ms/step\n",
      "Epoch 84/10000\n",
      "568/568 - 4s - loss: 0.0733 - val_loss: 0.0867 - 4s/epoch - 7ms/step\n",
      "Epoch 85/10000\n",
      "568/568 - 4s - loss: 0.0686 - val_loss: 0.0939 - 4s/epoch - 8ms/step\n",
      "Epoch 86/10000\n",
      "568/568 - 4s - loss: 0.0726 - val_loss: 0.0897 - 4s/epoch - 7ms/step\n",
      "Epoch 87/10000\n",
      "568/568 - 4s - loss: 0.0723 - val_loss: 0.0983 - 4s/epoch - 7ms/step\n",
      "Epoch 88/10000\n",
      "568/568 - 4s - loss: 0.0686 - val_loss: 0.1008 - 4s/epoch - 7ms/step\n",
      "Epoch 89/10000\n",
      "568/568 - 4s - loss: 0.0728 - val_loss: 0.0879 - 4s/epoch - 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_10_layer_call_fn, gru_cell_10_layer_call_and_return_conditional_losses, gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/20_30_1_50_1_50_datt_seq2seq_gru_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/20_30_1_50_1_50_datt_seq2seq_gru_test\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7A56AFAC0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7D73979D0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.852478</td>\n",
       "      <td>0.902995</td>\n",
       "      <td>0.926258</td>\n",
       "      <td>0.89391</td>\n",
       "      <td>7.583359</td>\n",
       "      <td>5.451708</td>\n",
       "      <td>4.181887</td>\n",
       "      <td>5.738985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753595</td>\n",
       "      <td>0.857701</td>\n",
       "      <td>0.880467</td>\n",
       "      <td>0.830588</td>\n",
       "      <td>9.800899</td>\n",
       "      <td>6.603318</td>\n",
       "      <td>5.324407</td>\n",
       "      <td>7.242874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.631774</td>\n",
       "      <td>0.813157</td>\n",
       "      <td>0.827102</td>\n",
       "      <td>0.757344</td>\n",
       "      <td>11.982584</td>\n",
       "      <td>7.567274</td>\n",
       "      <td>6.403841</td>\n",
       "      <td>8.651233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.510765</td>\n",
       "      <td>0.78129</td>\n",
       "      <td>0.775022</td>\n",
       "      <td>0.689025</td>\n",
       "      <td>13.813823</td>\n",
       "      <td>8.188238</td>\n",
       "      <td>7.305088</td>\n",
       "      <td>9.76905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.401095</td>\n",
       "      <td>0.76058</td>\n",
       "      <td>0.735651</td>\n",
       "      <td>0.632442</td>\n",
       "      <td>15.283418</td>\n",
       "      <td>8.568757</td>\n",
       "      <td>7.918456</td>\n",
       "      <td>10.59021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.305571</td>\n",
       "      <td>0.745263</td>\n",
       "      <td>0.707273</td>\n",
       "      <td>0.586036</td>\n",
       "      <td>16.454471</td>\n",
       "      <td>8.841209</td>\n",
       "      <td>8.331821</td>\n",
       "      <td>11.209167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.222267</td>\n",
       "      <td>0.729832</td>\n",
       "      <td>0.685643</td>\n",
       "      <td>0.545914</td>\n",
       "      <td>17.410377</td>\n",
       "      <td>9.107701</td>\n",
       "      <td>8.632973</td>\n",
       "      <td>11.717017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.147915</td>\n",
       "      <td>0.713002</td>\n",
       "      <td>0.668821</td>\n",
       "      <td>0.509913</td>\n",
       "      <td>18.21969</td>\n",
       "      <td>9.389923</td>\n",
       "      <td>8.859266</td>\n",
       "      <td>12.156293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.084238</td>\n",
       "      <td>0.694333</td>\n",
       "      <td>0.65269</td>\n",
       "      <td>0.477087</td>\n",
       "      <td>18.88279</td>\n",
       "      <td>9.694376</td>\n",
       "      <td>9.070326</td>\n",
       "      <td>12.549164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.029535</td>\n",
       "      <td>0.673002</td>\n",
       "      <td>0.634399</td>\n",
       "      <td>0.445646</td>\n",
       "      <td>19.434238</td>\n",
       "      <td>10.030325</td>\n",
       "      <td>9.304867</td>\n",
       "      <td>12.923143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.018747</td>\n",
       "      <td>0.649795</td>\n",
       "      <td>0.613299</td>\n",
       "      <td>0.414782</td>\n",
       "      <td>19.90925</td>\n",
       "      <td>10.382993</td>\n",
       "      <td>9.569163</td>\n",
       "      <td>13.287135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.063492</td>\n",
       "      <td>0.627084</td>\n",
       "      <td>0.589711</td>\n",
       "      <td>0.384434</td>\n",
       "      <td>19.966638</td>\n",
       "      <td>10.717634</td>\n",
       "      <td>9.857327</td>\n",
       "      <td>13.513866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.105841</td>\n",
       "      <td>0.603757</td>\n",
       "      <td>0.564605</td>\n",
       "      <td>0.354174</td>\n",
       "      <td>19.465975</td>\n",
       "      <td>11.051804</td>\n",
       "      <td>10.155544</td>\n",
       "      <td>13.557774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.145637</td>\n",
       "      <td>0.579969</td>\n",
       "      <td>0.539312</td>\n",
       "      <td>0.324548</td>\n",
       "      <td>19.147517</td>\n",
       "      <td>11.382522</td>\n",
       "      <td>10.44736</td>\n",
       "      <td>13.659133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.182466</td>\n",
       "      <td>0.555276</td>\n",
       "      <td>0.515166</td>\n",
       "      <td>0.295992</td>\n",
       "      <td>19.140493</td>\n",
       "      <td>11.717491</td>\n",
       "      <td>10.718337</td>\n",
       "      <td>13.858774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.216538</td>\n",
       "      <td>0.530946</td>\n",
       "      <td>0.49181</td>\n",
       "      <td>0.268739</td>\n",
       "      <td>19.350408</td>\n",
       "      <td>12.039546</td>\n",
       "      <td>10.973291</td>\n",
       "      <td>14.121082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.247256</td>\n",
       "      <td>0.506878</td>\n",
       "      <td>0.468822</td>\n",
       "      <td>0.242815</td>\n",
       "      <td>19.212044</td>\n",
       "      <td>12.348171</td>\n",
       "      <td>11.218819</td>\n",
       "      <td>14.259678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.273345</td>\n",
       "      <td>0.483887</td>\n",
       "      <td>0.446424</td>\n",
       "      <td>0.218989</td>\n",
       "      <td>19.044762</td>\n",
       "      <td>12.636593</td>\n",
       "      <td>11.453178</td>\n",
       "      <td>14.378178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.296805</td>\n",
       "      <td>0.461814</td>\n",
       "      <td>0.425299</td>\n",
       "      <td>0.196769</td>\n",
       "      <td>18.939557</td>\n",
       "      <td>12.90791</td>\n",
       "      <td>11.670334</td>\n",
       "      <td>14.505934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.318867</td>\n",
       "      <td>0.440925</td>\n",
       "      <td>0.405361</td>\n",
       "      <td>0.175806</td>\n",
       "      <td>18.827677</td>\n",
       "      <td>13.158315</td>\n",
       "      <td>11.87176</td>\n",
       "      <td>14.619251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.340319</td>\n",
       "      <td>0.420705</td>\n",
       "      <td>0.386859</td>\n",
       "      <td>0.155748</td>\n",
       "      <td>18.787597</td>\n",
       "      <td>13.396258</td>\n",
       "      <td>12.056029</td>\n",
       "      <td>14.746628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.36147</td>\n",
       "      <td>0.400125</td>\n",
       "      <td>0.370052</td>\n",
       "      <td>0.136235</td>\n",
       "      <td>18.81857</td>\n",
       "      <td>13.633562</td>\n",
       "      <td>12.221701</td>\n",
       "      <td>14.891277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.382128</td>\n",
       "      <td>0.37856</td>\n",
       "      <td>0.354872</td>\n",
       "      <td>0.117101</td>\n",
       "      <td>18.704755</td>\n",
       "      <td>13.877643</td>\n",
       "      <td>12.369827</td>\n",
       "      <td>14.984075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.402292</td>\n",
       "      <td>0.358017</td>\n",
       "      <td>0.341345</td>\n",
       "      <td>0.099023</td>\n",
       "      <td>18.590842</td>\n",
       "      <td>14.107166</td>\n",
       "      <td>12.500392</td>\n",
       "      <td>15.066133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.422999</td>\n",
       "      <td>0.338967</td>\n",
       "      <td>0.329744</td>\n",
       "      <td>0.081904</td>\n",
       "      <td>18.542663</td>\n",
       "      <td>14.316815</td>\n",
       "      <td>12.610846</td>\n",
       "      <td>15.156775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.444821</td>\n",
       "      <td>0.320518</td>\n",
       "      <td>0.320326</td>\n",
       "      <td>0.065341</td>\n",
       "      <td>18.501885</td>\n",
       "      <td>14.516715</td>\n",
       "      <td>12.700515</td>\n",
       "      <td>15.239705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.465831</td>\n",
       "      <td>0.301924</td>\n",
       "      <td>0.312772</td>\n",
       "      <td>0.049622</td>\n",
       "      <td>18.456465</td>\n",
       "      <td>14.713842</td>\n",
       "      <td>12.773154</td>\n",
       "      <td>15.314487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.485658</td>\n",
       "      <td>0.283811</td>\n",
       "      <td>0.306014</td>\n",
       "      <td>0.034722</td>\n",
       "      <td>18.535873</td>\n",
       "      <td>14.902397</td>\n",
       "      <td>12.839509</td>\n",
       "      <td>15.425927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.503755</td>\n",
       "      <td>0.267511</td>\n",
       "      <td>0.298931</td>\n",
       "      <td>0.020896</td>\n",
       "      <td>18.670234</td>\n",
       "      <td>15.069311</td>\n",
       "      <td>12.908961</td>\n",
       "      <td>15.549502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.520501</td>\n",
       "      <td>0.252313</td>\n",
       "      <td>0.29067</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>18.795495</td>\n",
       "      <td>15.222285</td>\n",
       "      <td>12.989324</td>\n",
       "      <td>15.669035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.075318</td>\n",
       "      <td>0.547798</td>\n",
       "      <td>0.528824</td>\n",
       "      <td>0.333768</td>\n",
       "      <td>17.609145</td>\n",
       "      <td>11.51806</td>\n",
       "      <td>10.307943</td>\n",
       "      <td>13.14505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TT-3061-3 TT-3061-5 LT-3061-2      mean  TT-3061-3  TT-3061-5  \\\n",
       "index        R2        R2        R2        R2      nRMSE      nRMSE   \n",
       "0      0.852478  0.902995  0.926258   0.89391   7.583359   5.451708   \n",
       "1      0.753595  0.857701  0.880467  0.830588   9.800899   6.603318   \n",
       "2      0.631774  0.813157  0.827102  0.757344  11.982584   7.567274   \n",
       "3      0.510765   0.78129  0.775022  0.689025  13.813823   8.188238   \n",
       "4      0.401095   0.76058  0.735651  0.632442  15.283418   8.568757   \n",
       "5      0.305571  0.745263  0.707273  0.586036  16.454471   8.841209   \n",
       "6      0.222267  0.729832  0.685643  0.545914  17.410377   9.107701   \n",
       "7      0.147915  0.713002  0.668821  0.509913   18.21969   9.389923   \n",
       "8      0.084238  0.694333   0.65269  0.477087   18.88279   9.694376   \n",
       "9      0.029535  0.673002  0.634399  0.445646  19.434238  10.030325   \n",
       "10    -0.018747  0.649795  0.613299  0.414782   19.90925  10.382993   \n",
       "11    -0.063492  0.627084  0.589711  0.384434  19.966638  10.717634   \n",
       "12    -0.105841  0.603757  0.564605  0.354174  19.465975  11.051804   \n",
       "13    -0.145637  0.579969  0.539312  0.324548  19.147517  11.382522   \n",
       "14    -0.182466  0.555276  0.515166  0.295992  19.140493  11.717491   \n",
       "15    -0.216538  0.530946   0.49181  0.268739  19.350408  12.039546   \n",
       "16    -0.247256  0.506878  0.468822  0.242815  19.212044  12.348171   \n",
       "17    -0.273345  0.483887  0.446424  0.218989  19.044762  12.636593   \n",
       "18    -0.296805  0.461814  0.425299  0.196769  18.939557   12.90791   \n",
       "19    -0.318867  0.440925  0.405361  0.175806  18.827677  13.158315   \n",
       "20    -0.340319  0.420705  0.386859  0.155748  18.787597  13.396258   \n",
       "21     -0.36147  0.400125  0.370052  0.136235   18.81857  13.633562   \n",
       "22    -0.382128   0.37856  0.354872  0.117101  18.704755  13.877643   \n",
       "23    -0.402292  0.358017  0.341345  0.099023  18.590842  14.107166   \n",
       "24    -0.422999  0.338967  0.329744  0.081904  18.542663  14.316815   \n",
       "25    -0.444821  0.320518  0.320326  0.065341  18.501885  14.516715   \n",
       "26    -0.465831  0.301924  0.312772  0.049622  18.456465  14.713842   \n",
       "27    -0.485658  0.283811  0.306014  0.034722  18.535873  14.902397   \n",
       "28    -0.503755  0.267511  0.298931  0.020896  18.670234  15.069311   \n",
       "29    -0.520501  0.252313   0.29067  0.007494  18.795495  15.222285   \n",
       "mean  -0.075318  0.547798  0.528824  0.333768  17.609145   11.51806   \n",
       "\n",
       "       LT-3061-2       mean  \n",
       "index      nRMSE      nRMSE  \n",
       "0       4.181887   5.738985  \n",
       "1       5.324407   7.242874  \n",
       "2       6.403841   8.651233  \n",
       "3       7.305088    9.76905  \n",
       "4       7.918456   10.59021  \n",
       "5       8.331821  11.209167  \n",
       "6       8.632973  11.717017  \n",
       "7       8.859266  12.156293  \n",
       "8       9.070326  12.549164  \n",
       "9       9.304867  12.923143  \n",
       "10      9.569163  13.287135  \n",
       "11      9.857327  13.513866  \n",
       "12     10.155544  13.557774  \n",
       "13      10.44736  13.659133  \n",
       "14     10.718337  13.858774  \n",
       "15     10.973291  14.121082  \n",
       "16     11.218819  14.259678  \n",
       "17     11.453178  14.378178  \n",
       "18     11.670334  14.505934  \n",
       "19      11.87176  14.619251  \n",
       "20     12.056029  14.746628  \n",
       "21     12.221701  14.891277  \n",
       "22     12.369827  14.984075  \n",
       "23     12.500392  15.066133  \n",
       "24     12.610846  15.156775  \n",
       "25     12.700515  15.239705  \n",
       "26     12.773154  15.314487  \n",
       "27     12.839509  15.425927  \n",
       "28     12.908961  15.549502  \n",
       "29     12.989324  15.669035  \n",
       "mean   10.307943   13.14505  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history size: 30\n",
      "future size: 10\n",
      "Epoch 1/10000\n",
      "572/572 - 8s - loss: 0.2250 - val_loss: 0.1537 - 8s/epoch - 15ms/step\n",
      "Epoch 2/10000\n",
      "572/572 - 5s - loss: 0.1497 - val_loss: 0.1464 - 5s/epoch - 8ms/step\n",
      "Epoch 3/10000\n",
      "572/572 - 4s - loss: 0.1394 - val_loss: 0.1306 - 4s/epoch - 8ms/step\n",
      "Epoch 4/10000\n",
      "572/572 - 4s - loss: 0.1301 - val_loss: 0.1255 - 4s/epoch - 8ms/step\n",
      "Epoch 5/10000\n",
      "572/572 - 4s - loss: 0.1215 - val_loss: 0.1160 - 4s/epoch - 8ms/step\n",
      "Epoch 6/10000\n",
      "572/572 - 4s - loss: 0.1121 - val_loss: 0.1054 - 4s/epoch - 8ms/step\n",
      "Epoch 7/10000\n",
      "572/572 - 4s - loss: 0.1055 - val_loss: 0.0991 - 4s/epoch - 8ms/step\n",
      "Epoch 8/10000\n",
      "572/572 - 4s - loss: 0.0998 - val_loss: 0.0977 - 4s/epoch - 8ms/step\n",
      "Epoch 9/10000\n",
      "572/572 - 4s - loss: 0.0965 - val_loss: 0.0942 - 4s/epoch - 8ms/step\n",
      "Epoch 10/10000\n",
      "572/572 - 4s - loss: 0.0928 - val_loss: 0.0962 - 4s/epoch - 8ms/step\n",
      "Epoch 11/10000\n",
      "572/572 - 4s - loss: 0.0893 - val_loss: 0.0909 - 4s/epoch - 8ms/step\n",
      "Epoch 12/10000\n",
      "572/572 - 4s - loss: 0.0874 - val_loss: 0.0939 - 4s/epoch - 8ms/step\n",
      "Epoch 13/10000\n",
      "572/572 - 4s - loss: 0.0846 - val_loss: 0.0910 - 4s/epoch - 8ms/step\n",
      "Epoch 14/10000\n",
      "572/572 - 4s - loss: 0.0835 - val_loss: 0.0853 - 4s/epoch - 8ms/step\n",
      "Epoch 15/10000\n",
      "572/572 - 4s - loss: 0.0799 - val_loss: 0.0929 - 4s/epoch - 8ms/step\n",
      "Epoch 16/10000\n",
      "572/572 - 4s - loss: 0.0786 - val_loss: 0.0909 - 4s/epoch - 8ms/step\n",
      "Epoch 17/10000\n",
      "572/572 - 4s - loss: 0.0747 - val_loss: 0.0810 - 4s/epoch - 8ms/step\n",
      "Epoch 18/10000\n",
      "572/572 - 4s - loss: 0.0740 - val_loss: 0.0812 - 4s/epoch - 8ms/step\n",
      "Epoch 19/10000\n",
      "572/572 - 4s - loss: 0.0721 - val_loss: 0.0829 - 4s/epoch - 8ms/step\n",
      "Epoch 20/10000\n",
      "572/572 - 5s - loss: 0.0709 - val_loss: 0.0787 - 5s/epoch - 8ms/step\n",
      "Epoch 21/10000\n",
      "572/572 - 4s - loss: 0.0673 - val_loss: 0.0761 - 4s/epoch - 8ms/step\n",
      "Epoch 22/10000\n",
      "572/572 - 4s - loss: 0.0730 - val_loss: 0.0774 - 4s/epoch - 8ms/step\n",
      "Epoch 23/10000\n",
      "572/572 - 4s - loss: 0.0647 - val_loss: 0.0750 - 4s/epoch - 8ms/step\n",
      "Epoch 24/10000\n",
      "572/572 - 4s - loss: 0.0624 - val_loss: 0.0763 - 4s/epoch - 8ms/step\n",
      "Epoch 25/10000\n",
      "572/572 - 4s - loss: 0.0626 - val_loss: 0.0694 - 4s/epoch - 8ms/step\n",
      "Epoch 26/10000\n",
      "572/572 - 4s - loss: 0.0616 - val_loss: 0.0698 - 4s/epoch - 8ms/step\n",
      "Epoch 27/10000\n",
      "572/572 - 4s - loss: 0.0636 - val_loss: 0.0683 - 4s/epoch - 8ms/step\n",
      "Epoch 28/10000\n",
      "572/572 - 5s - loss: 0.0585 - val_loss: 0.0678 - 5s/epoch - 8ms/step\n",
      "Epoch 29/10000\n",
      "572/572 - 4s - loss: 0.0592 - val_loss: 0.0670 - 4s/epoch - 8ms/step\n",
      "Epoch 30/10000\n",
      "572/572 - 4s - loss: 0.0582 - val_loss: 0.0674 - 4s/epoch - 8ms/step\n",
      "Epoch 31/10000\n",
      "572/572 - 4s - loss: 0.0572 - val_loss: 0.0693 - 4s/epoch - 8ms/step\n",
      "Epoch 32/10000\n",
      "572/572 - 4s - loss: 0.0554 - val_loss: 0.0677 - 4s/epoch - 8ms/step\n",
      "Epoch 33/10000\n",
      "572/572 - 4s - loss: 0.0563 - val_loss: 0.0655 - 4s/epoch - 8ms/step\n",
      "Epoch 34/10000\n",
      "572/572 - 4s - loss: 0.0539 - val_loss: 0.0637 - 4s/epoch - 7ms/step\n",
      "Epoch 35/10000\n",
      "572/572 - 4s - loss: 0.0532 - val_loss: 0.0622 - 4s/epoch - 8ms/step\n",
      "Epoch 36/10000\n",
      "572/572 - 4s - loss: 0.0528 - val_loss: 0.0641 - 4s/epoch - 8ms/step\n",
      "Epoch 37/10000\n",
      "572/572 - 4s - loss: 0.0543 - val_loss: 0.0637 - 4s/epoch - 8ms/step\n",
      "Epoch 38/10000\n",
      "572/572 - 4s - loss: 0.0509 - val_loss: 0.0616 - 4s/epoch - 8ms/step\n",
      "Epoch 39/10000\n",
      "572/572 - 4s - loss: 0.0512 - val_loss: 0.0621 - 4s/epoch - 8ms/step\n",
      "Epoch 40/10000\n",
      "572/572 - 4s - loss: 0.0506 - val_loss: 0.0591 - 4s/epoch - 8ms/step\n",
      "Epoch 41/10000\n",
      "572/572 - 4s - loss: 0.0498 - val_loss: 0.0585 - 4s/epoch - 8ms/step\n",
      "Epoch 42/10000\n",
      "572/572 - 4s - loss: 0.0496 - val_loss: 0.0630 - 4s/epoch - 8ms/step\n",
      "Epoch 43/10000\n",
      "572/572 - 4s - loss: 0.0484 - val_loss: 0.0586 - 4s/epoch - 8ms/step\n",
      "Epoch 44/10000\n",
      "572/572 - 4s - loss: 0.0481 - val_loss: 0.0582 - 4s/epoch - 8ms/step\n",
      "Epoch 45/10000\n",
      "572/572 - 5s - loss: 0.0472 - val_loss: 0.0628 - 5s/epoch - 8ms/step\n",
      "Epoch 46/10000\n",
      "572/572 - 4s - loss: 0.0482 - val_loss: 0.0611 - 4s/epoch - 8ms/step\n",
      "Epoch 47/10000\n",
      "572/572 - 4s - loss: 0.0467 - val_loss: 0.0551 - 4s/epoch - 8ms/step\n",
      "Epoch 48/10000\n",
      "572/572 - 4s - loss: 0.0453 - val_loss: 0.0557 - 4s/epoch - 8ms/step\n",
      "Epoch 49/10000\n",
      "572/572 - 4s - loss: 0.0465 - val_loss: 0.0624 - 4s/epoch - 8ms/step\n",
      "Epoch 50/10000\n",
      "572/572 - 4s - loss: 0.0454 - val_loss: 0.0553 - 4s/epoch - 8ms/step\n",
      "Epoch 51/10000\n",
      "572/572 - 4s - loss: 0.0450 - val_loss: 0.0551 - 4s/epoch - 8ms/step\n",
      "Epoch 52/10000\n",
      "572/572 - 4s - loss: 0.0443 - val_loss: 0.0542 - 4s/epoch - 8ms/step\n",
      "Epoch 53/10000\n",
      "572/572 - 5s - loss: 0.0440 - val_loss: 0.0546 - 5s/epoch - 8ms/step\n",
      "Epoch 54/10000\n",
      "572/572 - 4s - loss: 0.0439 - val_loss: 0.0537 - 4s/epoch - 8ms/step\n",
      "Epoch 55/10000\n",
      "572/572 - 4s - loss: 0.0438 - val_loss: 0.0542 - 4s/epoch - 8ms/step\n",
      "Epoch 56/10000\n",
      "572/572 - 4s - loss: 0.0433 - val_loss: 0.0523 - 4s/epoch - 8ms/step\n",
      "Epoch 57/10000\n",
      "572/572 - 4s - loss: 0.0423 - val_loss: 0.0530 - 4s/epoch - 8ms/step\n",
      "Epoch 58/10000\n",
      "572/572 - 4s - loss: 0.0418 - val_loss: 0.0543 - 4s/epoch - 8ms/step\n",
      "Epoch 59/10000\n",
      "572/572 - 4s - loss: 0.0426 - val_loss: 0.0516 - 4s/epoch - 8ms/step\n",
      "Epoch 60/10000\n",
      "572/572 - 4s - loss: 0.0411 - val_loss: 0.0535 - 4s/epoch - 8ms/step\n",
      "Epoch 61/10000\n",
      "572/572 - 4s - loss: 0.0414 - val_loss: 0.0527 - 4s/epoch - 8ms/step\n",
      "Epoch 62/10000\n",
      "572/572 - 4s - loss: 0.0411 - val_loss: 0.0556 - 4s/epoch - 8ms/step\n",
      "Epoch 63/10000\n",
      "572/572 - 4s - loss: 0.0410 - val_loss: 0.0514 - 4s/epoch - 8ms/step\n",
      "Epoch 64/10000\n",
      "572/572 - 4s - loss: 0.0411 - val_loss: 0.0533 - 4s/epoch - 8ms/step\n",
      "Epoch 65/10000\n",
      "572/572 - 4s - loss: 0.0402 - val_loss: 0.0516 - 4s/epoch - 8ms/step\n",
      "Epoch 66/10000\n",
      "572/572 - 4s - loss: 0.0405 - val_loss: 0.0546 - 4s/epoch - 8ms/step\n",
      "Epoch 67/10000\n",
      "572/572 - 4s - loss: 0.0403 - val_loss: 0.0504 - 4s/epoch - 8ms/step\n",
      "Epoch 68/10000\n",
      "572/572 - 4s - loss: 0.0388 - val_loss: 0.0503 - 4s/epoch - 8ms/step\n",
      "Epoch 69/10000\n",
      "572/572 - 4s - loss: 0.0384 - val_loss: 0.0504 - 4s/epoch - 8ms/step\n",
      "Epoch 70/10000\n",
      "572/572 - 4s - loss: 0.0389 - val_loss: 0.0496 - 4s/epoch - 8ms/step\n",
      "Epoch 71/10000\n",
      "572/572 - 4s - loss: 0.0392 - val_loss: 0.0513 - 4s/epoch - 8ms/step\n",
      "Epoch 72/10000\n",
      "572/572 - 4s - loss: 0.0383 - val_loss: 0.0503 - 4s/epoch - 8ms/step\n",
      "Epoch 73/10000\n",
      "572/572 - 4s - loss: 0.0387 - val_loss: 0.0493 - 4s/epoch - 8ms/step\n",
      "Epoch 74/10000\n",
      "572/572 - 4s - loss: 0.0416 - val_loss: 0.0583 - 4s/epoch - 8ms/step\n",
      "Epoch 75/10000\n",
      "572/572 - 4s - loss: 0.0385 - val_loss: 0.0485 - 4s/epoch - 8ms/step\n",
      "Epoch 76/10000\n",
      "572/572 - 5s - loss: 0.0372 - val_loss: 0.0485 - 5s/epoch - 8ms/step\n",
      "Epoch 77/10000\n",
      "572/572 - 4s - loss: 0.0370 - val_loss: 0.0483 - 4s/epoch - 8ms/step\n",
      "Epoch 78/10000\n",
      "572/572 - 4s - loss: 0.0365 - val_loss: 0.0496 - 4s/epoch - 8ms/step\n",
      "Epoch 79/10000\n",
      "572/572 - 4s - loss: 0.0373 - val_loss: 0.0472 - 4s/epoch - 8ms/step\n",
      "Epoch 80/10000\n",
      "572/572 - 4s - loss: 0.0363 - val_loss: 0.0492 - 4s/epoch - 8ms/step\n",
      "Epoch 81/10000\n",
      "572/572 - 4s - loss: 0.0366 - val_loss: 0.0476 - 4s/epoch - 8ms/step\n",
      "Epoch 82/10000\n",
      "572/572 - 4s - loss: 0.0362 - val_loss: 0.0473 - 4s/epoch - 8ms/step\n",
      "Epoch 83/10000\n",
      "572/572 - 4s - loss: 0.0364 - val_loss: 0.0499 - 4s/epoch - 8ms/step\n",
      "Epoch 84/10000\n",
      "572/572 - 5s - loss: 0.0351 - val_loss: 0.0469 - 5s/epoch - 8ms/step\n",
      "Epoch 85/10000\n",
      "572/572 - 4s - loss: 0.0356 - val_loss: 0.0495 - 4s/epoch - 8ms/step\n",
      "Epoch 86/10000\n",
      "572/572 - 4s - loss: 0.0350 - val_loss: 0.0506 - 4s/epoch - 8ms/step\n",
      "Epoch 87/10000\n",
      "572/572 - 4s - loss: 0.0351 - val_loss: 0.0453 - 4s/epoch - 8ms/step\n",
      "Epoch 88/10000\n",
      "572/572 - 5s - loss: 0.0351 - val_loss: 0.0534 - 5s/epoch - 8ms/step\n",
      "Epoch 89/10000\n",
      "572/572 - 4s - loss: 0.0358 - val_loss: 0.0481 - 4s/epoch - 8ms/step\n",
      "Epoch 90/10000\n",
      "572/572 - 4s - loss: 0.0378 - val_loss: 0.0485 - 4s/epoch - 8ms/step\n",
      "Epoch 91/10000\n",
      "572/572 - 4s - loss: 0.0342 - val_loss: 0.0467 - 4s/epoch - 8ms/step\n",
      "Epoch 92/10000\n",
      "572/572 - 4s - loss: 0.0336 - val_loss: 0.0447 - 4s/epoch - 8ms/step\n",
      "Epoch 93/10000\n",
      "572/572 - 4s - loss: 0.0334 - val_loss: 0.0456 - 4s/epoch - 8ms/step\n",
      "Epoch 94/10000\n",
      "572/572 - 4s - loss: 0.0336 - val_loss: 0.0473 - 4s/epoch - 8ms/step\n",
      "Epoch 95/10000\n",
      "572/572 - 4s - loss: 0.0335 - val_loss: 0.0442 - 4s/epoch - 8ms/step\n",
      "Epoch 96/10000\n",
      "572/572 - 4s - loss: 0.0336 - val_loss: 0.0455 - 4s/epoch - 8ms/step\n",
      "Epoch 97/10000\n",
      "572/572 - 4s - loss: 0.0336 - val_loss: 0.0448 - 4s/epoch - 8ms/step\n",
      "Epoch 98/10000\n",
      "572/572 - 4s - loss: 0.0331 - val_loss: 0.0445 - 4s/epoch - 8ms/step\n",
      "Epoch 99/10000\n",
      "572/572 - 4s - loss: 0.0327 - val_loss: 0.0469 - 4s/epoch - 8ms/step\n",
      "Epoch 100/10000\n",
      "572/572 - 4s - loss: 0.0327 - val_loss: 0.0453 - 4s/epoch - 8ms/step\n",
      "Epoch 101/10000\n",
      "572/572 - 4s - loss: 0.0381 - val_loss: 0.0529 - 4s/epoch - 8ms/step\n",
      "Epoch 102/10000\n",
      "572/572 - 4s - loss: 0.0370 - val_loss: 0.0453 - 4s/epoch - 8ms/step\n",
      "Epoch 103/10000\n",
      "572/572 - 4s - loss: 0.0317 - val_loss: 0.0440 - 4s/epoch - 8ms/step\n",
      "Epoch 104/10000\n",
      "572/572 - 4s - loss: 0.0309 - val_loss: 0.0423 - 4s/epoch - 8ms/step\n",
      "Epoch 105/10000\n",
      "572/572 - 4s - loss: 0.0311 - val_loss: 0.0427 - 4s/epoch - 8ms/step\n",
      "Epoch 106/10000\n",
      "572/572 - 4s - loss: 0.0324 - val_loss: 0.0441 - 4s/epoch - 8ms/step\n",
      "Epoch 107/10000\n",
      "572/572 - 4s - loss: 0.0316 - val_loss: 0.0439 - 4s/epoch - 8ms/step\n",
      "Epoch 108/10000\n",
      "572/572 - 5s - loss: 0.0317 - val_loss: 0.0465 - 5s/epoch - 8ms/step\n",
      "Epoch 109/10000\n",
      "572/572 - 4s - loss: 0.0312 - val_loss: 0.0429 - 4s/epoch - 8ms/step\n",
      "Epoch 110/10000\n",
      "572/572 - 4s - loss: 0.0315 - val_loss: 0.0452 - 4s/epoch - 8ms/step\n",
      "Epoch 111/10000\n",
      "572/572 - 4s - loss: 0.0313 - val_loss: 0.0452 - 4s/epoch - 8ms/step\n",
      "Epoch 112/10000\n",
      "572/572 - 4s - loss: 0.0312 - val_loss: 0.0427 - 4s/epoch - 8ms/step\n",
      "Epoch 113/10000\n",
      "572/572 - 4s - loss: 0.0312 - val_loss: 0.0448 - 4s/epoch - 8ms/step\n",
      "Epoch 114/10000\n",
      "572/572 - 4s - loss: 0.0300 - val_loss: 0.0432 - 4s/epoch - 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_12_layer_call_fn, gru_cell_12_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/30_10_1_50_1_50_datt_seq2seq_gru_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/30_10_1_50_1_50_datt_seq2seq_gru_test\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7DB9D05E0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7A586FCA0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.942641</td>\n",
       "      <td>0.941104</td>\n",
       "      <td>0.96838</td>\n",
       "      <td>0.950708</td>\n",
       "      <td>3.887085</td>\n",
       "      <td>4.262941</td>\n",
       "      <td>2.746024</td>\n",
       "      <td>3.632017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.858991</td>\n",
       "      <td>0.880448</td>\n",
       "      <td>0.942538</td>\n",
       "      <td>0.893992</td>\n",
       "      <td>6.054161</td>\n",
       "      <td>6.074296</td>\n",
       "      <td>3.701159</td>\n",
       "      <td>5.276539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.728938</td>\n",
       "      <td>0.827605</td>\n",
       "      <td>0.908562</td>\n",
       "      <td>0.821702</td>\n",
       "      <td>8.277516</td>\n",
       "      <td>7.29493</td>\n",
       "      <td>4.668489</td>\n",
       "      <td>6.746978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.586619</td>\n",
       "      <td>0.782875</td>\n",
       "      <td>0.879348</td>\n",
       "      <td>0.749614</td>\n",
       "      <td>10.084382</td>\n",
       "      <td>8.187869</td>\n",
       "      <td>5.362709</td>\n",
       "      <td>7.87832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.465231</td>\n",
       "      <td>0.747919</td>\n",
       "      <td>0.857437</td>\n",
       "      <td>0.690195</td>\n",
       "      <td>11.355997</td>\n",
       "      <td>8.82355</td>\n",
       "      <td>5.829201</td>\n",
       "      <td>8.669583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.365171</td>\n",
       "      <td>0.715235</td>\n",
       "      <td>0.843213</td>\n",
       "      <td>0.641206</td>\n",
       "      <td>12.25315</td>\n",
       "      <td>9.379549</td>\n",
       "      <td>6.113131</td>\n",
       "      <td>9.24861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.284531</td>\n",
       "      <td>0.686578</td>\n",
       "      <td>0.833635</td>\n",
       "      <td>0.601581</td>\n",
       "      <td>12.88515</td>\n",
       "      <td>9.840893</td>\n",
       "      <td>6.297399</td>\n",
       "      <td>9.674481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.220656</td>\n",
       "      <td>0.664328</td>\n",
       "      <td>0.825693</td>\n",
       "      <td>0.570226</td>\n",
       "      <td>13.418461</td>\n",
       "      <td>10.184476</td>\n",
       "      <td>6.446517</td>\n",
       "      <td>10.016485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.165265</td>\n",
       "      <td>0.64441</td>\n",
       "      <td>0.816098</td>\n",
       "      <td>0.541924</td>\n",
       "      <td>13.906625</td>\n",
       "      <td>10.482584</td>\n",
       "      <td>6.622031</td>\n",
       "      <td>10.33708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.116417</td>\n",
       "      <td>0.62212</td>\n",
       "      <td>0.80226</td>\n",
       "      <td>0.513599</td>\n",
       "      <td>14.328315</td>\n",
       "      <td>10.806206</td>\n",
       "      <td>6.867424</td>\n",
       "      <td>10.667315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.473446</td>\n",
       "      <td>0.751262</td>\n",
       "      <td>0.867716</td>\n",
       "      <td>0.697475</td>\n",
       "      <td>10.645084</td>\n",
       "      <td>8.533729</td>\n",
       "      <td>5.465408</td>\n",
       "      <td>8.214741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TT-3061-3 TT-3061-5 LT-3061-2      mean  TT-3061-3  TT-3061-5 LT-3061-2  \\\n",
       "index        R2        R2        R2        R2      nRMSE      nRMSE     nRMSE   \n",
       "0      0.942641  0.941104   0.96838  0.950708   3.887085   4.262941  2.746024   \n",
       "1      0.858991  0.880448  0.942538  0.893992   6.054161   6.074296  3.701159   \n",
       "2      0.728938  0.827605  0.908562  0.821702   8.277516    7.29493  4.668489   \n",
       "3      0.586619  0.782875  0.879348  0.749614  10.084382   8.187869  5.362709   \n",
       "4      0.465231  0.747919  0.857437  0.690195  11.355997    8.82355  5.829201   \n",
       "5      0.365171  0.715235  0.843213  0.641206   12.25315   9.379549  6.113131   \n",
       "6      0.284531  0.686578  0.833635  0.601581   12.88515   9.840893  6.297399   \n",
       "7      0.220656  0.664328  0.825693  0.570226  13.418461  10.184476  6.446517   \n",
       "8      0.165265   0.64441  0.816098  0.541924  13.906625  10.482584  6.622031   \n",
       "9      0.116417   0.62212   0.80226  0.513599  14.328315  10.806206  6.867424   \n",
       "mean   0.473446  0.751262  0.867716  0.697475  10.645084   8.533729  5.465408   \n",
       "\n",
       "            mean  \n",
       "index      nRMSE  \n",
       "0       3.632017  \n",
       "1       5.276539  \n",
       "2       6.746978  \n",
       "3        7.87832  \n",
       "4       8.669583  \n",
       "5        9.24861  \n",
       "6       9.674481  \n",
       "7      10.016485  \n",
       "8       10.33708  \n",
       "9      10.667315  \n",
       "mean    8.214741  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history size: 30\n",
      "future size: 20\n",
      "Epoch 1/10000\n",
      "568/568 - 8s - loss: 0.3022 - val_loss: 0.2611 - 8s/epoch - 13ms/step\n",
      "Epoch 2/10000\n",
      "568/568 - 4s - loss: 0.2172 - val_loss: 0.2395 - 4s/epoch - 8ms/step\n",
      "Epoch 3/10000\n",
      "568/568 - 4s - loss: 0.2042 - val_loss: 0.2320 - 4s/epoch - 8ms/step\n",
      "Epoch 4/10000\n",
      "568/568 - 4s - loss: 0.1936 - val_loss: 0.2115 - 4s/epoch - 7ms/step\n",
      "Epoch 5/10000\n",
      "568/568 - 4s - loss: 0.1851 - val_loss: 0.2076 - 4s/epoch - 7ms/step\n",
      "Epoch 6/10000\n",
      "568/568 - 4s - loss: 0.1771 - val_loss: 0.1927 - 4s/epoch - 7ms/step\n",
      "Epoch 7/10000\n",
      "568/568 - 4s - loss: 0.1680 - val_loss: 0.1851 - 4s/epoch - 8ms/step\n",
      "Epoch 8/10000\n",
      "568/568 - 4s - loss: 0.1600 - val_loss: 0.1801 - 4s/epoch - 7ms/step\n",
      "Epoch 9/10000\n",
      "568/568 - 4s - loss: 0.1539 - val_loss: 0.1695 - 4s/epoch - 7ms/step\n",
      "Epoch 10/10000\n",
      "568/568 - 4s - loss: 0.1472 - val_loss: 0.1747 - 4s/epoch - 7ms/step\n",
      "Epoch 11/10000\n",
      "568/568 - 4s - loss: 0.1404 - val_loss: 0.1604 - 4s/epoch - 7ms/step\n",
      "Epoch 12/10000\n",
      "568/568 - 4s - loss: 0.1347 - val_loss: 0.1606 - 4s/epoch - 7ms/step\n",
      "Epoch 13/10000\n",
      "568/568 - 4s - loss: 0.1309 - val_loss: 0.1454 - 4s/epoch - 7ms/step\n",
      "Epoch 14/10000\n",
      "568/568 - 4s - loss: 0.1237 - val_loss: 0.1441 - 4s/epoch - 7ms/step\n",
      "Epoch 15/10000\n",
      "568/568 - 4s - loss: 0.1206 - val_loss: 0.1486 - 4s/epoch - 7ms/step\n",
      "Epoch 16/10000\n",
      "568/568 - 4s - loss: 0.1172 - val_loss: 0.1325 - 4s/epoch - 8ms/step\n",
      "Epoch 17/10000\n",
      "568/568 - 4s - loss: 0.1118 - val_loss: 0.1299 - 4s/epoch - 7ms/step\n",
      "Epoch 18/10000\n",
      "568/568 - 4s - loss: 0.1090 - val_loss: 0.1331 - 4s/epoch - 7ms/step\n",
      "Epoch 19/10000\n",
      "568/568 - 4s - loss: 0.1050 - val_loss: 0.1246 - 4s/epoch - 7ms/step\n",
      "Epoch 20/10000\n",
      "568/568 - 4s - loss: 0.1030 - val_loss: 0.1205 - 4s/epoch - 7ms/step\n",
      "Epoch 21/10000\n",
      "568/568 - 4s - loss: 0.1010 - val_loss: 0.1227 - 4s/epoch - 7ms/step\n",
      "Epoch 22/10000\n",
      "568/568 - 4s - loss: 0.1010 - val_loss: 0.1222 - 4s/epoch - 7ms/step\n",
      "Epoch 23/10000\n",
      "568/568 - 4s - loss: 0.0960 - val_loss: 0.1178 - 4s/epoch - 7ms/step\n",
      "Epoch 24/10000\n",
      "568/568 - 4s - loss: 0.0940 - val_loss: 0.1192 - 4s/epoch - 8ms/step\n",
      "Epoch 25/10000\n",
      "568/568 - 4s - loss: 0.0940 - val_loss: 0.1097 - 4s/epoch - 7ms/step\n",
      "Epoch 26/10000\n",
      "568/568 - 4s - loss: 0.0919 - val_loss: 0.1246 - 4s/epoch - 7ms/step\n",
      "Epoch 27/10000\n",
      "568/568 - 5s - loss: 0.0910 - val_loss: 0.1086 - 5s/epoch - 8ms/step\n",
      "Epoch 28/10000\n",
      "568/568 - 5s - loss: 0.0896 - val_loss: 0.1107 - 5s/epoch - 8ms/step\n",
      "Epoch 29/10000\n",
      "568/568 - 4s - loss: 0.0870 - val_loss: 0.1104 - 4s/epoch - 8ms/step\n",
      "Epoch 30/10000\n",
      "568/568 - 4s - loss: 0.0869 - val_loss: 0.1081 - 4s/epoch - 8ms/step\n",
      "Epoch 31/10000\n",
      "568/568 - 5s - loss: 0.0850 - val_loss: 0.1070 - 5s/epoch - 9ms/step\n",
      "Epoch 32/10000\n",
      "568/568 - 5s - loss: 0.0841 - val_loss: 0.1082 - 5s/epoch - 9ms/step\n",
      "Epoch 33/10000\n",
      "568/568 - 4s - loss: 0.0826 - val_loss: 0.1029 - 4s/epoch - 8ms/step\n",
      "Epoch 34/10000\n",
      "568/568 - 4s - loss: 0.0821 - val_loss: 0.1031 - 4s/epoch - 8ms/step\n",
      "Epoch 35/10000\n",
      "568/568 - 4s - loss: 0.0791 - val_loss: 0.1007 - 4s/epoch - 7ms/step\n",
      "Epoch 36/10000\n",
      "568/568 - 4s - loss: 0.0818 - val_loss: 0.1019 - 4s/epoch - 7ms/step\n",
      "Epoch 37/10000\n",
      "568/568 - 4s - loss: 0.0792 - val_loss: 0.0991 - 4s/epoch - 7ms/step\n",
      "Epoch 38/10000\n",
      "568/568 - 4s - loss: 0.0781 - val_loss: 0.1006 - 4s/epoch - 7ms/step\n",
      "Epoch 39/10000\n",
      "568/568 - 4s - loss: 0.0761 - val_loss: 0.1033 - 4s/epoch - 7ms/step\n",
      "Epoch 40/10000\n",
      "568/568 - 4s - loss: 0.0769 - val_loss: 0.1019 - 4s/epoch - 7ms/step\n",
      "Epoch 41/10000\n",
      "568/568 - 4s - loss: 0.0776 - val_loss: 0.0986 - 4s/epoch - 8ms/step\n",
      "Epoch 42/10000\n",
      "568/568 - 4s - loss: 0.0757 - val_loss: 0.0909 - 4s/epoch - 7ms/step\n",
      "Epoch 43/10000\n",
      "568/568 - 4s - loss: 0.0729 - val_loss: 0.1020 - 4s/epoch - 7ms/step\n",
      "Epoch 44/10000\n",
      "568/568 - 4s - loss: 0.0723 - val_loss: 0.0957 - 4s/epoch - 7ms/step\n",
      "Epoch 45/10000\n",
      "568/568 - 4s - loss: 0.0729 - val_loss: 0.1030 - 4s/epoch - 7ms/step\n",
      "Epoch 46/10000\n",
      "568/568 - 4s - loss: 0.0708 - val_loss: 0.0929 - 4s/epoch - 7ms/step\n",
      "Epoch 47/10000\n",
      "568/568 - 4s - loss: 0.0701 - val_loss: 0.0939 - 4s/epoch - 8ms/step\n",
      "Epoch 48/10000\n",
      "568/568 - 4s - loss: 0.0709 - val_loss: 0.1057 - 4s/epoch - 8ms/step\n",
      "Epoch 49/10000\n",
      "568/568 - 4s - loss: 0.0718 - val_loss: 0.0885 - 4s/epoch - 7ms/step\n",
      "Epoch 50/10000\n",
      "568/568 - 4s - loss: 0.0685 - val_loss: 0.0919 - 4s/epoch - 8ms/step\n",
      "Epoch 51/10000\n",
      "568/568 - 4s - loss: 0.0720 - val_loss: 0.0918 - 4s/epoch - 7ms/step\n",
      "Epoch 52/10000\n",
      "568/568 - 4s - loss: 0.0687 - val_loss: 0.0862 - 4s/epoch - 7ms/step\n",
      "Epoch 53/10000\n",
      "568/568 - 4s - loss: 0.0664 - val_loss: 0.0902 - 4s/epoch - 7ms/step\n",
      "Epoch 54/10000\n",
      "568/568 - 4s - loss: 0.0668 - val_loss: 0.0951 - 4s/epoch - 8ms/step\n",
      "Epoch 55/10000\n",
      "568/568 - 4s - loss: 0.0658 - val_loss: 0.0870 - 4s/epoch - 7ms/step\n",
      "Epoch 56/10000\n",
      "568/568 - 4s - loss: 0.0678 - val_loss: 0.0893 - 4s/epoch - 7ms/step\n",
      "Epoch 57/10000\n",
      "568/568 - 4s - loss: 0.0639 - val_loss: 0.0898 - 4s/epoch - 7ms/step\n",
      "Epoch 58/10000\n",
      "568/568 - 4s - loss: 0.0636 - val_loss: 0.0840 - 4s/epoch - 7ms/step\n",
      "Epoch 59/10000\n",
      "568/568 - 4s - loss: 0.0640 - val_loss: 0.0828 - 4s/epoch - 7ms/step\n",
      "Epoch 60/10000\n",
      "568/568 - 4s - loss: 0.0608 - val_loss: 0.0788 - 4s/epoch - 7ms/step\n",
      "Epoch 61/10000\n",
      "568/568 - 4s - loss: 0.0645 - val_loss: 0.0883 - 4s/epoch - 7ms/step\n",
      "Epoch 62/10000\n",
      "568/568 - 4s - loss: 0.0619 - val_loss: 0.0816 - 4s/epoch - 7ms/step\n",
      "Epoch 63/10000\n",
      "568/568 - 4s - loss: 0.0607 - val_loss: 0.0797 - 4s/epoch - 7ms/step\n",
      "Epoch 64/10000\n",
      "568/568 - 4s - loss: 0.0627 - val_loss: 0.0769 - 4s/epoch - 7ms/step\n",
      "Epoch 65/10000\n",
      "568/568 - 4s - loss: 0.0577 - val_loss: 0.0767 - 4s/epoch - 7ms/step\n",
      "Epoch 66/10000\n",
      "568/568 - 4s - loss: 0.0590 - val_loss: 0.0826 - 4s/epoch - 7ms/step\n",
      "Epoch 67/10000\n",
      "568/568 - 4s - loss: 0.0599 - val_loss: 0.0763 - 4s/epoch - 7ms/step\n",
      "Epoch 68/10000\n",
      "568/568 - 4s - loss: 0.0575 - val_loss: 0.0758 - 4s/epoch - 8ms/step\n",
      "Epoch 69/10000\n",
      "568/568 - 4s - loss: 0.0663 - val_loss: 0.0770 - 4s/epoch - 8ms/step\n",
      "Epoch 70/10000\n",
      "568/568 - 4s - loss: 0.0582 - val_loss: 0.0739 - 4s/epoch - 8ms/step\n",
      "Epoch 71/10000\n",
      "568/568 - 4s - loss: 0.0544 - val_loss: 0.0717 - 4s/epoch - 7ms/step\n",
      "Epoch 72/10000\n",
      "568/568 - 4s - loss: 0.0566 - val_loss: 0.0733 - 4s/epoch - 7ms/step\n",
      "Epoch 73/10000\n",
      "568/568 - 4s - loss: 0.0569 - val_loss: 0.0825 - 4s/epoch - 7ms/step\n",
      "Epoch 74/10000\n",
      "568/568 - 4s - loss: 0.0574 - val_loss: 0.0768 - 4s/epoch - 7ms/step\n",
      "Epoch 75/10000\n",
      "568/568 - 4s - loss: 0.0619 - val_loss: 0.0754 - 4s/epoch - 8ms/step\n",
      "Epoch 76/10000\n",
      "568/568 - 4s - loss: 0.0531 - val_loss: 0.0719 - 4s/epoch - 8ms/step\n",
      "Epoch 77/10000\n",
      "568/568 - 4s - loss: 0.0599 - val_loss: 0.0790 - 4s/epoch - 7ms/step\n",
      "Epoch 78/10000\n",
      "568/568 - 4s - loss: 0.0550 - val_loss: 0.0720 - 4s/epoch - 7ms/step\n",
      "Epoch 79/10000\n",
      "568/568 - 4s - loss: 0.0529 - val_loss: 0.0730 - 4s/epoch - 7ms/step\n",
      "Epoch 80/10000\n",
      "568/568 - 4s - loss: 0.0539 - val_loss: 0.0779 - 4s/epoch - 7ms/step\n",
      "Epoch 81/10000\n",
      "568/568 - 4s - loss: 0.0517 - val_loss: 0.0712 - 4s/epoch - 8ms/step\n",
      "Epoch 82/10000\n",
      "568/568 - 4s - loss: 0.0515 - val_loss: 0.0750 - 4s/epoch - 8ms/step\n",
      "Epoch 83/10000\n",
      "568/568 - 4s - loss: 0.0538 - val_loss: 0.0720 - 4s/epoch - 7ms/step\n",
      "Epoch 84/10000\n",
      "568/568 - 4s - loss: 0.0519 - val_loss: 0.0687 - 4s/epoch - 7ms/step\n",
      "Epoch 85/10000\n",
      "568/568 - 4s - loss: 0.0610 - val_loss: 0.0776 - 4s/epoch - 7ms/step\n",
      "Epoch 86/10000\n",
      "568/568 - 4s - loss: 0.0520 - val_loss: 0.0710 - 4s/epoch - 7ms/step\n",
      "Epoch 87/10000\n",
      "568/568 - 4s - loss: 0.0531 - val_loss: 0.0692 - 4s/epoch - 7ms/step\n",
      "Epoch 88/10000\n",
      "568/568 - 4s - loss: 0.0497 - val_loss: 0.0673 - 4s/epoch - 7ms/step\n",
      "Epoch 89/10000\n",
      "568/568 - 4s - loss: 0.0499 - val_loss: 0.0690 - 4s/epoch - 7ms/step\n",
      "Epoch 90/10000\n",
      "568/568 - 4s - loss: 0.0505 - val_loss: 0.0671 - 4s/epoch - 7ms/step\n",
      "Epoch 91/10000\n",
      "568/568 - 4s - loss: 0.0495 - val_loss: 0.0726 - 4s/epoch - 7ms/step\n",
      "Epoch 92/10000\n",
      "568/568 - 4s - loss: 0.0501 - val_loss: 0.0683 - 4s/epoch - 7ms/step\n",
      "Epoch 93/10000\n",
      "568/568 - 4s - loss: 0.0498 - val_loss: 0.0740 - 4s/epoch - 7ms/step\n",
      "Epoch 94/10000\n",
      "568/568 - 4s - loss: 0.0493 - val_loss: 0.0664 - 4s/epoch - 7ms/step\n",
      "Epoch 95/10000\n",
      "568/568 - 4s - loss: 0.0482 - val_loss: 0.0690 - 4s/epoch - 7ms/step\n",
      "Epoch 96/10000\n",
      "568/568 - 4s - loss: 0.0489 - val_loss: 0.0678 - 4s/epoch - 7ms/step\n",
      "Epoch 97/10000\n",
      "568/568 - 4s - loss: 0.0481 - val_loss: 0.0688 - 4s/epoch - 7ms/step\n",
      "Epoch 98/10000\n",
      "568/568 - 4s - loss: 0.0615 - val_loss: 0.0781 - 4s/epoch - 7ms/step\n",
      "Epoch 99/10000\n",
      "568/568 - 4s - loss: 0.0518 - val_loss: 0.0651 - 4s/epoch - 8ms/step\n",
      "Epoch 100/10000\n",
      "568/568 - 4s - loss: 0.0485 - val_loss: 0.0656 - 4s/epoch - 7ms/step\n",
      "Epoch 101/10000\n",
      "568/568 - 4s - loss: 0.0466 - val_loss: 0.0675 - 4s/epoch - 7ms/step\n",
      "Epoch 102/10000\n",
      "568/568 - 4s - loss: 0.0471 - val_loss: 0.0663 - 4s/epoch - 7ms/step\n",
      "Epoch 103/10000\n",
      "568/568 - 4s - loss: 0.0474 - val_loss: 0.0644 - 4s/epoch - 7ms/step\n",
      "Epoch 104/10000\n",
      "568/568 - 4s - loss: 0.0473 - val_loss: 0.0659 - 4s/epoch - 7ms/step\n",
      "Epoch 105/10000\n",
      "568/568 - 4s - loss: 0.0464 - val_loss: 0.0629 - 4s/epoch - 8ms/step\n",
      "Epoch 106/10000\n",
      "568/568 - 4s - loss: 0.0470 - val_loss: 0.0684 - 4s/epoch - 7ms/step\n",
      "Epoch 107/10000\n",
      "568/568 - 4s - loss: 0.0468 - val_loss: 0.0669 - 4s/epoch - 8ms/step\n",
      "Epoch 108/10000\n",
      "568/568 - 4s - loss: 0.0483 - val_loss: 0.0648 - 4s/epoch - 7ms/step\n",
      "Epoch 109/10000\n",
      "568/568 - 4s - loss: 0.0465 - val_loss: 0.0638 - 4s/epoch - 7ms/step\n",
      "Epoch 110/10000\n",
      "568/568 - 4s - loss: 0.0448 - val_loss: 0.0612 - 4s/epoch - 7ms/step\n",
      "Epoch 111/10000\n",
      "568/568 - 4s - loss: 0.0449 - val_loss: 0.0644 - 4s/epoch - 7ms/step\n",
      "Epoch 112/10000\n",
      "568/568 - 4s - loss: 0.0459 - val_loss: 0.0614 - 4s/epoch - 8ms/step\n",
      "Epoch 113/10000\n",
      "568/568 - 4s - loss: 0.0507 - val_loss: 0.0657 - 4s/epoch - 7ms/step\n",
      "Epoch 114/10000\n",
      "568/568 - 4s - loss: 0.0456 - val_loss: 0.0645 - 4s/epoch - 8ms/step\n",
      "Epoch 115/10000\n",
      "568/568 - 4s - loss: 0.0442 - val_loss: 0.0596 - 4s/epoch - 7ms/step\n",
      "Epoch 116/10000\n",
      "568/568 - 4s - loss: 0.0444 - val_loss: 0.0623 - 4s/epoch - 7ms/step\n",
      "Epoch 117/10000\n",
      "568/568 - 4s - loss: 0.0472 - val_loss: 0.0629 - 4s/epoch - 7ms/step\n",
      "Epoch 118/10000\n",
      "568/568 - 4s - loss: 0.0454 - val_loss: 0.0637 - 4s/epoch - 7ms/step\n",
      "Epoch 119/10000\n",
      "568/568 - 4s - loss: 0.0438 - val_loss: 0.0631 - 4s/epoch - 7ms/step\n",
      "Epoch 120/10000\n",
      "568/568 - 4s - loss: 0.0538 - val_loss: 0.0655 - 4s/epoch - 7ms/step\n",
      "Epoch 121/10000\n",
      "568/568 - 4s - loss: 0.0430 - val_loss: 0.0581 - 4s/epoch - 7ms/step\n",
      "Epoch 122/10000\n",
      "568/568 - 4s - loss: 0.0428 - val_loss: 0.0610 - 4s/epoch - 8ms/step\n",
      "Epoch 123/10000\n",
      "568/568 - 4s - loss: 0.0449 - val_loss: 0.0615 - 4s/epoch - 7ms/step\n",
      "Epoch 124/10000\n",
      "568/568 - 4s - loss: 0.0435 - val_loss: 0.0595 - 4s/epoch - 7ms/step\n",
      "Epoch 125/10000\n",
      "568/568 - 4s - loss: 0.0425 - val_loss: 0.0626 - 4s/epoch - 8ms/step\n",
      "Epoch 126/10000\n",
      "568/568 - 4s - loss: 0.0447 - val_loss: 0.0650 - 4s/epoch - 7ms/step\n",
      "Epoch 127/10000\n",
      "568/568 - 4s - loss: 0.0424 - val_loss: 0.0618 - 4s/epoch - 7ms/step\n",
      "Epoch 128/10000\n",
      "568/568 - 4s - loss: 0.0520 - val_loss: 0.0717 - 4s/epoch - 8ms/step\n",
      "Epoch 129/10000\n",
      "568/568 - 4s - loss: 0.0476 - val_loss: 0.0910 - 4s/epoch - 7ms/step\n",
      "Epoch 130/10000\n",
      "568/568 - 4s - loss: 0.0516 - val_loss: 0.0631 - 4s/epoch - 7ms/step\n",
      "Epoch 131/10000\n",
      "568/568 - 4s - loss: 0.0420 - val_loss: 0.0632 - 4s/epoch - 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_15_layer_call_fn, gru_cell_15_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/30_20_1_50_1_50_datt_seq2seq_gru_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/30_20_1_50_1_50_datt_seq2seq_gru_test\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7A56594C0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7DBAA3880> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.867165</td>\n",
       "      <td>0.918425</td>\n",
       "      <td>0.892303</td>\n",
       "      <td>0.892631</td>\n",
       "      <td>7.189163</td>\n",
       "      <td>5.011184</td>\n",
       "      <td>5.049971</td>\n",
       "      <td>5.750106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753507</td>\n",
       "      <td>0.861905</td>\n",
       "      <td>0.861368</td>\n",
       "      <td>0.825593</td>\n",
       "      <td>9.61258</td>\n",
       "      <td>6.522024</td>\n",
       "      <td>5.729883</td>\n",
       "      <td>7.288163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.645785</td>\n",
       "      <td>0.806962</td>\n",
       "      <td>0.823615</td>\n",
       "      <td>0.758788</td>\n",
       "      <td>11.016997</td>\n",
       "      <td>7.71389</td>\n",
       "      <td>6.463863</td>\n",
       "      <td>8.39825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.529321</td>\n",
       "      <td>0.757563</td>\n",
       "      <td>0.79852</td>\n",
       "      <td>0.695135</td>\n",
       "      <td>12.273014</td>\n",
       "      <td>8.647632</td>\n",
       "      <td>6.909059</td>\n",
       "      <td>9.276568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.419132</td>\n",
       "      <td>0.711256</td>\n",
       "      <td>0.778355</td>\n",
       "      <td>0.636248</td>\n",
       "      <td>13.415207</td>\n",
       "      <td>9.441607</td>\n",
       "      <td>7.247029</td>\n",
       "      <td>10.034614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.320964</td>\n",
       "      <td>0.671924</td>\n",
       "      <td>0.756268</td>\n",
       "      <td>0.583052</td>\n",
       "      <td>14.456843</td>\n",
       "      <td>10.069</td>\n",
       "      <td>7.599405</td>\n",
       "      <td>10.708416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.239019</td>\n",
       "      <td>0.644471</td>\n",
       "      <td>0.739401</td>\n",
       "      <td>0.540964</td>\n",
       "      <td>15.006608</td>\n",
       "      <td>10.484874</td>\n",
       "      <td>7.858028</td>\n",
       "      <td>11.116503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.169734</td>\n",
       "      <td>0.628785</td>\n",
       "      <td>0.727699</td>\n",
       "      <td>0.508739</td>\n",
       "      <td>15.378396</td>\n",
       "      <td>10.716937</td>\n",
       "      <td>8.032711</td>\n",
       "      <td>11.376015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.107184</td>\n",
       "      <td>0.616728</td>\n",
       "      <td>0.706015</td>\n",
       "      <td>0.476642</td>\n",
       "      <td>15.714963</td>\n",
       "      <td>10.8929</td>\n",
       "      <td>8.346893</td>\n",
       "      <td>11.651585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.046635</td>\n",
       "      <td>0.60296</td>\n",
       "      <td>0.668142</td>\n",
       "      <td>0.439246</td>\n",
       "      <td>16.007581</td>\n",
       "      <td>11.08875</td>\n",
       "      <td>8.868788</td>\n",
       "      <td>11.988373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.012026</td>\n",
       "      <td>0.586628</td>\n",
       "      <td>0.626771</td>\n",
       "      <td>0.400458</td>\n",
       "      <td>16.325368</td>\n",
       "      <td>11.316289</td>\n",
       "      <td>9.406147</td>\n",
       "      <td>12.349268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.068301</td>\n",
       "      <td>0.56873</td>\n",
       "      <td>0.591625</td>\n",
       "      <td>0.364018</td>\n",
       "      <td>16.66976</td>\n",
       "      <td>11.559881</td>\n",
       "      <td>9.840311</td>\n",
       "      <td>12.689984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.118985</td>\n",
       "      <td>0.551353</td>\n",
       "      <td>0.563192</td>\n",
       "      <td>0.331854</td>\n",
       "      <td>16.83023</td>\n",
       "      <td>11.791483</td>\n",
       "      <td>10.178548</td>\n",
       "      <td>12.93342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.161994</td>\n",
       "      <td>0.535847</td>\n",
       "      <td>0.537515</td>\n",
       "      <td>0.30379</td>\n",
       "      <td>16.923169</td>\n",
       "      <td>11.995232</td>\n",
       "      <td>10.47474</td>\n",
       "      <td>13.131047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.199444</td>\n",
       "      <td>0.522685</td>\n",
       "      <td>0.512926</td>\n",
       "      <td>0.278722</td>\n",
       "      <td>17.023931</td>\n",
       "      <td>12.165714</td>\n",
       "      <td>10.750319</td>\n",
       "      <td>13.313321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.229417</td>\n",
       "      <td>0.510559</td>\n",
       "      <td>0.490897</td>\n",
       "      <td>0.257346</td>\n",
       "      <td>17.067057</td>\n",
       "      <td>12.320532</td>\n",
       "      <td>10.991927</td>\n",
       "      <td>13.459839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.25212</td>\n",
       "      <td>0.497031</td>\n",
       "      <td>0.471377</td>\n",
       "      <td>0.238763</td>\n",
       "      <td>17.058056</td>\n",
       "      <td>12.489508</td>\n",
       "      <td>11.202649</td>\n",
       "      <td>13.583405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.270475</td>\n",
       "      <td>0.480755</td>\n",
       "      <td>0.452462</td>\n",
       "      <td>0.220914</td>\n",
       "      <td>17.141022</td>\n",
       "      <td>12.689028</td>\n",
       "      <td>11.404603</td>\n",
       "      <td>13.744884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.287401</td>\n",
       "      <td>0.462635</td>\n",
       "      <td>0.439159</td>\n",
       "      <td>0.204798</td>\n",
       "      <td>17.275002</td>\n",
       "      <td>12.907068</td>\n",
       "      <td>11.545982</td>\n",
       "      <td>13.909351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.301671</td>\n",
       "      <td>0.445355</td>\n",
       "      <td>0.429339</td>\n",
       "      <td>0.191008</td>\n",
       "      <td>17.39046</td>\n",
       "      <td>13.110744</td>\n",
       "      <td>11.650677</td>\n",
       "      <td>14.050627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.109831</td>\n",
       "      <td>0.619128</td>\n",
       "      <td>0.643348</td>\n",
       "      <td>0.457435</td>\n",
       "      <td>14.98877</td>\n",
       "      <td>10.646714</td>\n",
       "      <td>8.977577</td>\n",
       "      <td>11.537687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TT-3061-3 TT-3061-5 LT-3061-2      mean  TT-3061-3  TT-3061-5  \\\n",
       "index        R2        R2        R2        R2      nRMSE      nRMSE   \n",
       "0      0.867165  0.918425  0.892303  0.892631   7.189163   5.011184   \n",
       "1      0.753507  0.861905  0.861368  0.825593    9.61258   6.522024   \n",
       "2      0.645785  0.806962  0.823615  0.758788  11.016997    7.71389   \n",
       "3      0.529321  0.757563   0.79852  0.695135  12.273014   8.647632   \n",
       "4      0.419132  0.711256  0.778355  0.636248  13.415207   9.441607   \n",
       "5      0.320964  0.671924  0.756268  0.583052  14.456843     10.069   \n",
       "6      0.239019  0.644471  0.739401  0.540964  15.006608  10.484874   \n",
       "7      0.169734  0.628785  0.727699  0.508739  15.378396  10.716937   \n",
       "8      0.107184  0.616728  0.706015  0.476642  15.714963    10.8929   \n",
       "9      0.046635   0.60296  0.668142  0.439246  16.007581   11.08875   \n",
       "10    -0.012026  0.586628  0.626771  0.400458  16.325368  11.316289   \n",
       "11    -0.068301   0.56873  0.591625  0.364018   16.66976  11.559881   \n",
       "12    -0.118985  0.551353  0.563192  0.331854   16.83023  11.791483   \n",
       "13    -0.161994  0.535847  0.537515   0.30379  16.923169  11.995232   \n",
       "14    -0.199444  0.522685  0.512926  0.278722  17.023931  12.165714   \n",
       "15    -0.229417  0.510559  0.490897  0.257346  17.067057  12.320532   \n",
       "16     -0.25212  0.497031  0.471377  0.238763  17.058056  12.489508   \n",
       "17    -0.270475  0.480755  0.452462  0.220914  17.141022  12.689028   \n",
       "18    -0.287401  0.462635  0.439159  0.204798  17.275002  12.907068   \n",
       "19    -0.301671  0.445355  0.429339  0.191008   17.39046  13.110744   \n",
       "mean   0.109831  0.619128  0.643348  0.457435   14.98877  10.646714   \n",
       "\n",
       "       LT-3061-2       mean  \n",
       "index      nRMSE      nRMSE  \n",
       "0       5.049971   5.750106  \n",
       "1       5.729883   7.288163  \n",
       "2       6.463863    8.39825  \n",
       "3       6.909059   9.276568  \n",
       "4       7.247029  10.034614  \n",
       "5       7.599405  10.708416  \n",
       "6       7.858028  11.116503  \n",
       "7       8.032711  11.376015  \n",
       "8       8.346893  11.651585  \n",
       "9       8.868788  11.988373  \n",
       "10      9.406147  12.349268  \n",
       "11      9.840311  12.689984  \n",
       "12     10.178548   12.93342  \n",
       "13      10.47474  13.131047  \n",
       "14     10.750319  13.313321  \n",
       "15     10.991927  13.459839  \n",
       "16     11.202649  13.583405  \n",
       "17     11.404603  13.744884  \n",
       "18     11.545982  13.909351  \n",
       "19     11.650677  14.050627  \n",
       "mean    8.977577  11.537687  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history size: 30\n",
      "future size: 30\n",
      "Epoch 1/10000\n",
      "563/563 - 8s - loss: 0.3774 - val_loss: 0.3121 - 8s/epoch - 14ms/step\n",
      "Epoch 2/10000\n",
      "563/563 - 5s - loss: 0.2884 - val_loss: 0.2864 - 5s/epoch - 8ms/step\n",
      "Epoch 3/10000\n",
      "563/563 - 4s - loss: 0.2669 - val_loss: 0.2692 - 4s/epoch - 8ms/step\n",
      "Epoch 4/10000\n",
      "563/563 - 4s - loss: 0.2477 - val_loss: 0.2516 - 4s/epoch - 8ms/step\n",
      "Epoch 5/10000\n",
      "563/563 - 4s - loss: 0.2311 - val_loss: 0.2370 - 4s/epoch - 8ms/step\n",
      "Epoch 6/10000\n",
      "563/563 - 4s - loss: 0.2172 - val_loss: 0.2289 - 4s/epoch - 8ms/step\n",
      "Epoch 7/10000\n",
      "563/563 - 4s - loss: 0.2058 - val_loss: 0.2176 - 4s/epoch - 8ms/step\n",
      "Epoch 8/10000\n",
      "563/563 - 4s - loss: 0.1922 - val_loss: 0.2188 - 4s/epoch - 8ms/step\n",
      "Epoch 9/10000\n",
      "563/563 - 4s - loss: 0.1837 - val_loss: 0.2005 - 4s/epoch - 8ms/step\n",
      "Epoch 10/10000\n",
      "563/563 - 5s - loss: 0.1759 - val_loss: 0.1926 - 5s/epoch - 8ms/step\n",
      "Epoch 11/10000\n",
      "563/563 - 4s - loss: 0.1696 - val_loss: 0.1881 - 4s/epoch - 8ms/step\n",
      "Epoch 12/10000\n",
      "563/563 - 4s - loss: 0.1615 - val_loss: 0.1805 - 4s/epoch - 8ms/step\n",
      "Epoch 13/10000\n",
      "563/563 - 4s - loss: 0.1576 - val_loss: 0.1714 - 4s/epoch - 8ms/step\n",
      "Epoch 14/10000\n",
      "563/563 - 4s - loss: 0.1491 - val_loss: 0.1648 - 4s/epoch - 8ms/step\n",
      "Epoch 15/10000\n",
      "563/563 - 4s - loss: 0.1478 - val_loss: 0.1654 - 4s/epoch - 8ms/step\n",
      "Epoch 16/10000\n",
      "563/563 - 4s - loss: 0.1457 - val_loss: 0.1650 - 4s/epoch - 8ms/step\n",
      "Epoch 17/10000\n",
      "563/563 - 4s - loss: 0.1412 - val_loss: 0.1592 - 4s/epoch - 8ms/step\n",
      "Epoch 18/10000\n",
      "563/563 - 5s - loss: 0.1340 - val_loss: 0.1589 - 5s/epoch - 8ms/step\n",
      "Epoch 19/10000\n",
      "563/563 - 4s - loss: 0.1320 - val_loss: 0.1362 - 4s/epoch - 8ms/step\n",
      "Epoch 20/10000\n",
      "563/563 - 4s - loss: 0.1291 - val_loss: 0.1391 - 4s/epoch - 8ms/step\n",
      "Epoch 21/10000\n",
      "563/563 - 4s - loss: 0.1265 - val_loss: 0.1400 - 4s/epoch - 8ms/step\n",
      "Epoch 22/10000\n",
      "563/563 - 4s - loss: 0.1246 - val_loss: 0.1420 - 4s/epoch - 8ms/step\n",
      "Epoch 23/10000\n",
      "563/563 - 4s - loss: 0.1221 - val_loss: 0.1375 - 4s/epoch - 8ms/step\n",
      "Epoch 24/10000\n",
      "563/563 - 4s - loss: 0.1195 - val_loss: 0.1258 - 4s/epoch - 8ms/step\n",
      "Epoch 25/10000\n",
      "563/563 - 4s - loss: 0.1157 - val_loss: 0.1289 - 4s/epoch - 8ms/step\n",
      "Epoch 26/10000\n",
      "563/563 - 5s - loss: 0.1168 - val_loss: 0.1275 - 5s/epoch - 8ms/step\n",
      "Epoch 27/10000\n",
      "563/563 - 4s - loss: 0.1116 - val_loss: 0.1355 - 4s/epoch - 8ms/step\n",
      "Epoch 28/10000\n",
      "563/563 - 4s - loss: 0.1184 - val_loss: 0.1336 - 4s/epoch - 8ms/step\n",
      "Epoch 29/10000\n",
      "563/563 - 4s - loss: 0.1078 - val_loss: 0.1270 - 4s/epoch - 8ms/step\n",
      "Epoch 30/10000\n",
      "563/563 - 4s - loss: 0.1069 - val_loss: 0.1210 - 4s/epoch - 8ms/step\n",
      "Epoch 31/10000\n",
      "563/563 - 4s - loss: 0.1076 - val_loss: 0.1150 - 4s/epoch - 8ms/step\n",
      "Epoch 32/10000\n",
      "563/563 - 4s - loss: 0.1073 - val_loss: 0.1391 - 4s/epoch - 8ms/step\n",
      "Epoch 33/10000\n",
      "563/563 - 4s - loss: 0.1081 - val_loss: 0.1171 - 4s/epoch - 8ms/step\n",
      "Epoch 34/10000\n",
      "563/563 - 4s - loss: 0.1042 - val_loss: 0.1124 - 4s/epoch - 8ms/step\n",
      "Epoch 35/10000\n",
      "563/563 - 4s - loss: 0.1058 - val_loss: 0.1335 - 4s/epoch - 8ms/step\n",
      "Epoch 36/10000\n",
      "563/563 - 4s - loss: 0.1047 - val_loss: 0.1186 - 4s/epoch - 8ms/step\n",
      "Epoch 37/10000\n",
      "563/563 - 4s - loss: 0.0995 - val_loss: 0.1227 - 4s/epoch - 8ms/step\n",
      "Epoch 38/10000\n",
      "563/563 - 4s - loss: 0.0983 - val_loss: 0.1236 - 4s/epoch - 8ms/step\n",
      "Epoch 39/10000\n",
      "563/563 - 5s - loss: 0.0986 - val_loss: 0.1047 - 5s/epoch - 8ms/step\n",
      "Epoch 40/10000\n",
      "563/563 - 4s - loss: 0.0950 - val_loss: 0.1061 - 4s/epoch - 8ms/step\n",
      "Epoch 41/10000\n",
      "563/563 - 4s - loss: 0.0930 - val_loss: 0.1082 - 4s/epoch - 8ms/step\n",
      "Epoch 42/10000\n",
      "563/563 - 4s - loss: 0.0945 - val_loss: 0.1072 - 4s/epoch - 8ms/step\n",
      "Epoch 43/10000\n",
      "563/563 - 4s - loss: 0.0908 - val_loss: 0.1019 - 4s/epoch - 8ms/step\n",
      "Epoch 44/10000\n",
      "563/563 - 4s - loss: 0.0917 - val_loss: 0.0992 - 4s/epoch - 8ms/step\n",
      "Epoch 45/10000\n",
      "563/563 - 4s - loss: 0.0903 - val_loss: 0.1045 - 4s/epoch - 8ms/step\n",
      "Epoch 46/10000\n",
      "563/563 - 5s - loss: 0.0890 - val_loss: 0.0955 - 5s/epoch - 8ms/step\n",
      "Epoch 47/10000\n",
      "563/563 - 5s - loss: 0.0873 - val_loss: 0.0942 - 5s/epoch - 8ms/step\n",
      "Epoch 48/10000\n",
      "563/563 - 4s - loss: 0.0891 - val_loss: 0.0974 - 4s/epoch - 8ms/step\n",
      "Epoch 49/10000\n",
      "563/563 - 4s - loss: 0.0863 - val_loss: 0.0979 - 4s/epoch - 8ms/step\n",
      "Epoch 50/10000\n",
      "563/563 - 4s - loss: 0.0850 - val_loss: 0.0981 - 4s/epoch - 8ms/step\n",
      "Epoch 51/10000\n",
      "563/563 - 4s - loss: 0.0846 - val_loss: 0.1005 - 4s/epoch - 8ms/step\n",
      "Epoch 52/10000\n",
      "563/563 - 4s - loss: 0.0835 - val_loss: 0.0985 - 4s/epoch - 8ms/step\n",
      "Epoch 53/10000\n",
      "563/563 - 5s - loss: 0.0837 - val_loss: 0.1024 - 5s/epoch - 8ms/step\n",
      "Epoch 54/10000\n",
      "563/563 - 4s - loss: 0.0813 - val_loss: 0.1066 - 4s/epoch - 8ms/step\n",
      "Epoch 55/10000\n",
      "563/563 - 4s - loss: 0.0823 - val_loss: 0.0935 - 4s/epoch - 8ms/step\n",
      "Epoch 56/10000\n",
      "563/563 - 4s - loss: 0.0804 - val_loss: 0.0922 - 4s/epoch - 8ms/step\n",
      "Epoch 57/10000\n",
      "563/563 - 4s - loss: 0.0791 - val_loss: 0.0966 - 4s/epoch - 8ms/step\n",
      "Epoch 58/10000\n",
      "563/563 - 4s - loss: 0.0810 - val_loss: 0.0927 - 4s/epoch - 8ms/step\n",
      "Epoch 59/10000\n",
      "563/563 - 4s - loss: 0.0801 - val_loss: 0.0893 - 4s/epoch - 8ms/step\n",
      "Epoch 60/10000\n",
      "563/563 - 4s - loss: 0.0790 - val_loss: 0.0926 - 4s/epoch - 8ms/step\n",
      "Epoch 61/10000\n",
      "563/563 - 5s - loss: 0.0769 - val_loss: 0.0849 - 5s/epoch - 8ms/step\n",
      "Epoch 62/10000\n",
      "563/563 - 4s - loss: 0.0753 - val_loss: 0.0995 - 4s/epoch - 8ms/step\n",
      "Epoch 63/10000\n",
      "563/563 - 4s - loss: 0.0765 - val_loss: 0.0825 - 4s/epoch - 8ms/step\n",
      "Epoch 64/10000\n",
      "563/563 - 4s - loss: 0.0751 - val_loss: 0.0880 - 4s/epoch - 8ms/step\n",
      "Epoch 65/10000\n",
      "563/563 - 4s - loss: 0.0768 - val_loss: 0.0916 - 4s/epoch - 8ms/step\n",
      "Epoch 66/10000\n",
      "563/563 - 5s - loss: 0.0725 - val_loss: 0.0817 - 5s/epoch - 8ms/step\n",
      "Epoch 67/10000\n",
      "563/563 - 4s - loss: 0.0721 - val_loss: 0.0888 - 4s/epoch - 8ms/step\n",
      "Epoch 68/10000\n",
      "563/563 - 4s - loss: 0.0741 - val_loss: 0.0816 - 4s/epoch - 8ms/step\n",
      "Epoch 69/10000\n",
      "563/563 - 4s - loss: 0.0711 - val_loss: 0.0923 - 4s/epoch - 8ms/step\n",
      "Epoch 70/10000\n",
      "563/563 - 4s - loss: 0.0732 - val_loss: 0.0843 - 4s/epoch - 8ms/step\n",
      "Epoch 71/10000\n",
      "563/563 - 4s - loss: 0.0712 - val_loss: 0.0804 - 4s/epoch - 8ms/step\n",
      "Epoch 72/10000\n",
      "563/563 - 4s - loss: 0.0723 - val_loss: 0.0840 - 4s/epoch - 8ms/step\n",
      "Epoch 73/10000\n",
      "563/563 - 4s - loss: 0.0694 - val_loss: 0.0830 - 4s/epoch - 8ms/step\n",
      "Epoch 74/10000\n",
      "563/563 - 4s - loss: 0.0685 - val_loss: 0.0859 - 4s/epoch - 8ms/step\n",
      "Epoch 75/10000\n",
      "563/563 - 4s - loss: 0.0692 - val_loss: 0.0809 - 4s/epoch - 8ms/step\n",
      "Epoch 76/10000\n",
      "563/563 - 4s - loss: 0.0701 - val_loss: 0.0766 - 4s/epoch - 8ms/step\n",
      "Epoch 77/10000\n",
      "563/563 - 4s - loss: 0.0669 - val_loss: 0.0796 - 4s/epoch - 8ms/step\n",
      "Epoch 78/10000\n",
      "563/563 - 5s - loss: 0.0697 - val_loss: 0.0814 - 5s/epoch - 8ms/step\n",
      "Epoch 79/10000\n",
      "563/563 - 4s - loss: 0.0670 - val_loss: 0.0787 - 4s/epoch - 8ms/step\n",
      "Epoch 80/10000\n",
      "563/563 - 4s - loss: 0.0694 - val_loss: 0.0792 - 4s/epoch - 8ms/step\n",
      "Epoch 81/10000\n",
      "563/563 - 5s - loss: 0.0670 - val_loss: 0.0776 - 5s/epoch - 8ms/step\n",
      "Epoch 82/10000\n",
      "563/563 - 4s - loss: 0.0673 - val_loss: 0.0816 - 4s/epoch - 8ms/step\n",
      "Epoch 83/10000\n",
      "563/563 - 4s - loss: 0.0657 - val_loss: 0.0765 - 4s/epoch - 8ms/step\n",
      "Epoch 84/10000\n",
      "563/563 - 4s - loss: 0.0671 - val_loss: 0.0979 - 4s/epoch - 8ms/step\n",
      "Epoch 85/10000\n",
      "563/563 - 4s - loss: 0.0665 - val_loss: 0.0739 - 4s/epoch - 8ms/step\n",
      "Epoch 86/10000\n",
      "563/563 - 4s - loss: 0.0645 - val_loss: 0.0785 - 4s/epoch - 8ms/step\n",
      "Epoch 87/10000\n",
      "563/563 - 4s - loss: 0.0656 - val_loss: 0.0743 - 4s/epoch - 8ms/step\n",
      "Epoch 88/10000\n",
      "563/563 - 4s - loss: 0.0639 - val_loss: 0.0736 - 4s/epoch - 8ms/step\n",
      "Epoch 89/10000\n",
      "563/563 - 5s - loss: 0.0662 - val_loss: 0.0729 - 5s/epoch - 8ms/step\n",
      "Epoch 90/10000\n",
      "563/563 - 4s - loss: 0.0627 - val_loss: 0.1058 - 4s/epoch - 8ms/step\n",
      "Epoch 91/10000\n",
      "563/563 - 4s - loss: 0.0813 - val_loss: 0.0782 - 4s/epoch - 8ms/step\n",
      "Epoch 92/10000\n",
      "563/563 - 4s - loss: 0.0613 - val_loss: 0.0772 - 4s/epoch - 8ms/step\n",
      "Epoch 93/10000\n",
      "563/563 - 4s - loss: 0.0620 - val_loss: 0.0726 - 4s/epoch - 8ms/step\n",
      "Epoch 94/10000\n",
      "563/563 - 5s - loss: 0.0605 - val_loss: 0.0715 - 5s/epoch - 8ms/step\n",
      "Epoch 95/10000\n",
      "563/563 - 4s - loss: 0.0604 - val_loss: 0.0720 - 4s/epoch - 8ms/step\n",
      "Epoch 96/10000\n",
      "563/563 - 4s - loss: 0.0612 - val_loss: 0.0694 - 4s/epoch - 8ms/step\n",
      "Epoch 97/10000\n",
      "563/563 - 4s - loss: 0.0624 - val_loss: 0.0801 - 4s/epoch - 8ms/step\n",
      "Epoch 98/10000\n",
      "563/563 - 4s - loss: 0.0686 - val_loss: 0.0743 - 4s/epoch - 8ms/step\n",
      "Epoch 99/10000\n",
      "563/563 - 4s - loss: 0.0614 - val_loss: 0.0730 - 4s/epoch - 8ms/step\n",
      "Epoch 100/10000\n",
      "563/563 - 5s - loss: 0.0599 - val_loss: 0.0682 - 5s/epoch - 8ms/step\n",
      "Epoch 101/10000\n",
      "563/563 - 4s - loss: 0.0586 - val_loss: 0.0713 - 4s/epoch - 8ms/step\n",
      "Epoch 102/10000\n",
      "563/563 - 4s - loss: 0.0591 - val_loss: 0.0694 - 4s/epoch - 8ms/step\n",
      "Epoch 103/10000\n",
      "563/563 - 4s - loss: 0.0597 - val_loss: 0.0712 - 4s/epoch - 8ms/step\n",
      "Epoch 104/10000\n",
      "563/563 - 4s - loss: 0.0597 - val_loss: 0.0738 - 4s/epoch - 8ms/step\n",
      "Epoch 105/10000\n",
      "563/563 - 5s - loss: 0.0608 - val_loss: 0.0715 - 5s/epoch - 9ms/step\n",
      "Epoch 106/10000\n",
      "563/563 - 5s - loss: 0.0599 - val_loss: 0.0731 - 5s/epoch - 9ms/step\n",
      "Epoch 107/10000\n",
      "563/563 - 5s - loss: 0.0585 - val_loss: 0.0726 - 5s/epoch - 8ms/step\n",
      "Epoch 108/10000\n",
      "563/563 - 4s - loss: 0.0623 - val_loss: 0.0792 - 4s/epoch - 8ms/step\n",
      "Epoch 109/10000\n",
      "563/563 - 4s - loss: 0.0605 - val_loss: 0.0662 - 4s/epoch - 8ms/step\n",
      "Epoch 110/10000\n",
      "563/563 - 4s - loss: 0.0575 - val_loss: 0.0666 - 4s/epoch - 8ms/step\n",
      "Epoch 111/10000\n",
      "563/563 - 4s - loss: 0.0589 - val_loss: 0.0684 - 4s/epoch - 8ms/step\n",
      "Epoch 112/10000\n",
      "563/563 - 4s - loss: 0.0586 - val_loss: 0.0700 - 4s/epoch - 8ms/step\n",
      "Epoch 113/10000\n",
      "563/563 - 5s - loss: 0.0562 - val_loss: 0.0671 - 5s/epoch - 8ms/step\n",
      "Epoch 114/10000\n",
      "563/563 - 4s - loss: 0.0569 - val_loss: 0.0671 - 4s/epoch - 8ms/step\n",
      "Epoch 115/10000\n",
      "563/563 - 4s - loss: 0.0582 - val_loss: 0.0703 - 4s/epoch - 8ms/step\n",
      "Epoch 116/10000\n",
      "563/563 - 4s - loss: 0.0571 - val_loss: 0.0707 - 4s/epoch - 8ms/step\n",
      "Epoch 117/10000\n",
      "563/563 - 4s - loss: 0.0584 - val_loss: 0.0666 - 4s/epoch - 8ms/step\n",
      "Epoch 118/10000\n",
      "563/563 - 4s - loss: 0.0569 - val_loss: 0.0684 - 4s/epoch - 8ms/step\n",
      "Epoch 119/10000\n",
      "563/563 - 5s - loss: 0.0564 - val_loss: 0.0701 - 5s/epoch - 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_16_layer_call_fn, gru_cell_16_layer_call_and_return_conditional_losses, gru_cell_17_layer_call_fn, gru_cell_17_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/30_30_1_50_1_50_datt_seq2seq_gru_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/30_30_1_50_1_50_datt_seq2seq_gru_test\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7A5FB9040> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7A572B340> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.849234</td>\n",
       "      <td>0.883302</td>\n",
       "      <td>0.919487</td>\n",
       "      <td>0.884008</td>\n",
       "      <td>7.653667</td>\n",
       "      <td>5.991931</td>\n",
       "      <td>4.350405</td>\n",
       "      <td>5.998668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.764664</td>\n",
       "      <td>0.811559</td>\n",
       "      <td>0.874794</td>\n",
       "      <td>0.817006</td>\n",
       "      <td>9.560184</td>\n",
       "      <td>7.614727</td>\n",
       "      <td>5.426794</td>\n",
       "      <td>7.533902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.650303</td>\n",
       "      <td>0.737239</td>\n",
       "      <td>0.798962</td>\n",
       "      <td>0.728835</td>\n",
       "      <td>11.652269</td>\n",
       "      <td>8.99263</td>\n",
       "      <td>6.878473</td>\n",
       "      <td>9.174458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.529713</td>\n",
       "      <td>0.677445</td>\n",
       "      <td>0.719247</td>\n",
       "      <td>0.642135</td>\n",
       "      <td>13.512491</td>\n",
       "      <td>9.964815</td>\n",
       "      <td>8.130364</td>\n",
       "      <td>10.53589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.417581</td>\n",
       "      <td>0.621813</td>\n",
       "      <td>0.661086</td>\n",
       "      <td>0.566827</td>\n",
       "      <td>15.037259</td>\n",
       "      <td>10.79214</td>\n",
       "      <td>8.934091</td>\n",
       "      <td>11.58783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.31836</td>\n",
       "      <td>0.570285</td>\n",
       "      <td>0.629241</td>\n",
       "      <td>0.505962</td>\n",
       "      <td>16.268642</td>\n",
       "      <td>11.507288</td>\n",
       "      <td>9.344888</td>\n",
       "      <td>12.373606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.231961</td>\n",
       "      <td>0.523336</td>\n",
       "      <td>0.611814</td>\n",
       "      <td>0.455703</td>\n",
       "      <td>17.270833</td>\n",
       "      <td>12.123439</td>\n",
       "      <td>9.56284</td>\n",
       "      <td>12.985704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.156629</td>\n",
       "      <td>0.486403</td>\n",
       "      <td>0.592897</td>\n",
       "      <td>0.411976</td>\n",
       "      <td>18.101369</td>\n",
       "      <td>12.58841</td>\n",
       "      <td>9.794577</td>\n",
       "      <td>13.494785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.097321</td>\n",
       "      <td>0.456225</td>\n",
       "      <td>0.563569</td>\n",
       "      <td>0.372372</td>\n",
       "      <td>18.731381</td>\n",
       "      <td>12.958312</td>\n",
       "      <td>10.14288</td>\n",
       "      <td>13.944191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.05293</td>\n",
       "      <td>0.428722</td>\n",
       "      <td>0.522525</td>\n",
       "      <td>0.334726</td>\n",
       "      <td>19.193203</td>\n",
       "      <td>13.286366</td>\n",
       "      <td>10.611442</td>\n",
       "      <td>14.36367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.012842</td>\n",
       "      <td>0.404137</td>\n",
       "      <td>0.469327</td>\n",
       "      <td>0.295435</td>\n",
       "      <td>19.604158</td>\n",
       "      <td>13.572974</td>\n",
       "      <td>11.189711</td>\n",
       "      <td>14.788947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.026825</td>\n",
       "      <td>0.379931</td>\n",
       "      <td>0.406118</td>\n",
       "      <td>0.253075</td>\n",
       "      <td>19.634995</td>\n",
       "      <td>13.850357</td>\n",
       "      <td>11.840862</td>\n",
       "      <td>15.108738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.060598</td>\n",
       "      <td>0.355436</td>\n",
       "      <td>0.345375</td>\n",
       "      <td>0.213404</td>\n",
       "      <td>19.086058</td>\n",
       "      <td>14.126718</td>\n",
       "      <td>12.435311</td>\n",
       "      <td>15.216029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.084489</td>\n",
       "      <td>0.329818</td>\n",
       "      <td>0.293459</td>\n",
       "      <td>0.179596</td>\n",
       "      <td>18.655233</td>\n",
       "      <td>14.409795</td>\n",
       "      <td>12.921848</td>\n",
       "      <td>15.328959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.099921</td>\n",
       "      <td>0.299324</td>\n",
       "      <td>0.253801</td>\n",
       "      <td>0.151068</td>\n",
       "      <td>18.48673</td>\n",
       "      <td>14.740551</td>\n",
       "      <td>13.282552</td>\n",
       "      <td>15.503278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.112146</td>\n",
       "      <td>0.269815</td>\n",
       "      <td>0.226839</td>\n",
       "      <td>0.128169</td>\n",
       "      <td>18.526458</td>\n",
       "      <td>15.054542</td>\n",
       "      <td>13.522742</td>\n",
       "      <td>15.701247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.121613</td>\n",
       "      <td>0.246806</td>\n",
       "      <td>0.210358</td>\n",
       "      <td>0.11185</td>\n",
       "      <td>18.240285</td>\n",
       "      <td>15.293374</td>\n",
       "      <td>13.668892</td>\n",
       "      <td>15.734183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.130198</td>\n",
       "      <td>0.229852</td>\n",
       "      <td>0.200677</td>\n",
       "      <td>0.10011</td>\n",
       "      <td>17.959917</td>\n",
       "      <td>15.467994</td>\n",
       "      <td>13.755103</td>\n",
       "      <td>15.727671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.139912</td>\n",
       "      <td>0.216131</td>\n",
       "      <td>0.193235</td>\n",
       "      <td>0.089818</td>\n",
       "      <td>17.770425</td>\n",
       "      <td>15.607891</td>\n",
       "      <td>13.821449</td>\n",
       "      <td>15.733255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.151461</td>\n",
       "      <td>0.202395</td>\n",
       "      <td>0.185941</td>\n",
       "      <td>0.078958</td>\n",
       "      <td>17.600528</td>\n",
       "      <td>15.744263</td>\n",
       "      <td>13.88591</td>\n",
       "      <td>15.743567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.161877</td>\n",
       "      <td>0.189504</td>\n",
       "      <td>0.178535</td>\n",
       "      <td>0.068721</td>\n",
       "      <td>17.494393</td>\n",
       "      <td>15.871871</td>\n",
       "      <td>13.950989</td>\n",
       "      <td>15.772418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.170688</td>\n",
       "      <td>0.178656</td>\n",
       "      <td>0.170558</td>\n",
       "      <td>0.059509</td>\n",
       "      <td>17.445807</td>\n",
       "      <td>15.976791</td>\n",
       "      <td>14.020898</td>\n",
       "      <td>15.814499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.180329</td>\n",
       "      <td>0.17114</td>\n",
       "      <td>0.160524</td>\n",
       "      <td>0.050445</td>\n",
       "      <td>17.2745</td>\n",
       "      <td>16.048561</td>\n",
       "      <td>14.108765</td>\n",
       "      <td>15.810608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.193518</td>\n",
       "      <td>0.165971</td>\n",
       "      <td>0.148011</td>\n",
       "      <td>0.040154</td>\n",
       "      <td>17.134306</td>\n",
       "      <td>16.099806</td>\n",
       "      <td>14.217879</td>\n",
       "      <td>15.817331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.211157</td>\n",
       "      <td>0.161396</td>\n",
       "      <td>0.136025</td>\n",
       "      <td>0.028755</td>\n",
       "      <td>17.084286</td>\n",
       "      <td>16.144523</td>\n",
       "      <td>14.321827</td>\n",
       "      <td>15.850212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.229173</td>\n",
       "      <td>0.15761</td>\n",
       "      <td>0.127324</td>\n",
       "      <td>0.018587</td>\n",
       "      <td>17.038795</td>\n",
       "      <td>16.1801</td>\n",
       "      <td>14.398767</td>\n",
       "      <td>15.872554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.244127</td>\n",
       "      <td>0.153282</td>\n",
       "      <td>0.12188</td>\n",
       "      <td>0.010345</td>\n",
       "      <td>16.975256</td>\n",
       "      <td>16.219188</td>\n",
       "      <td>14.449079</td>\n",
       "      <td>15.881174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.253303</td>\n",
       "      <td>0.151011</td>\n",
       "      <td>0.11599</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>16.996077</td>\n",
       "      <td>16.237657</td>\n",
       "      <td>14.503521</td>\n",
       "      <td>15.912418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.257323</td>\n",
       "      <td>0.146785</td>\n",
       "      <td>0.108302</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>17.043926</td>\n",
       "      <td>16.275828</td>\n",
       "      <td>14.572544</td>\n",
       "      <td>15.964099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.258653</td>\n",
       "      <td>0.139436</td>\n",
       "      <td>0.097875</td>\n",
       "      <td>-0.007114</td>\n",
       "      <td>17.076851</td>\n",
       "      <td>16.344114</td>\n",
       "      <td>14.663286</td>\n",
       "      <td>16.028084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.033141</td>\n",
       "      <td>0.358159</td>\n",
       "      <td>0.368126</td>\n",
       "      <td>0.253142</td>\n",
       "      <td>16.803676</td>\n",
       "      <td>13.836232</td>\n",
       "      <td>11.89029</td>\n",
       "      <td>14.176733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TT-3061-3 TT-3061-5 LT-3061-2      mean  TT-3061-3  TT-3061-5  \\\n",
       "index        R2        R2        R2        R2      nRMSE      nRMSE   \n",
       "0      0.849234  0.883302  0.919487  0.884008   7.653667   5.991931   \n",
       "1      0.764664  0.811559  0.874794  0.817006   9.560184   7.614727   \n",
       "2      0.650303  0.737239  0.798962  0.728835  11.652269    8.99263   \n",
       "3      0.529713  0.677445  0.719247  0.642135  13.512491   9.964815   \n",
       "4      0.417581  0.621813  0.661086  0.566827  15.037259   10.79214   \n",
       "5       0.31836  0.570285  0.629241  0.505962  16.268642  11.507288   \n",
       "6      0.231961  0.523336  0.611814  0.455703  17.270833  12.123439   \n",
       "7      0.156629  0.486403  0.592897  0.411976  18.101369   12.58841   \n",
       "8      0.097321  0.456225  0.563569  0.372372  18.731381  12.958312   \n",
       "9       0.05293  0.428722  0.522525  0.334726  19.193203  13.286366   \n",
       "10     0.012842  0.404137  0.469327  0.295435  19.604158  13.572974   \n",
       "11    -0.026825  0.379931  0.406118  0.253075  19.634995  13.850357   \n",
       "12    -0.060598  0.355436  0.345375  0.213404  19.086058  14.126718   \n",
       "13    -0.084489  0.329818  0.293459  0.179596  18.655233  14.409795   \n",
       "14    -0.099921  0.299324  0.253801  0.151068   18.48673  14.740551   \n",
       "15    -0.112146  0.269815  0.226839  0.128169  18.526458  15.054542   \n",
       "16    -0.121613  0.246806  0.210358   0.11185  18.240285  15.293374   \n",
       "17    -0.130198  0.229852  0.200677   0.10011  17.959917  15.467994   \n",
       "18    -0.139912  0.216131  0.193235  0.089818  17.770425  15.607891   \n",
       "19    -0.151461  0.202395  0.185941  0.078958  17.600528  15.744263   \n",
       "20    -0.161877  0.189504  0.178535  0.068721  17.494393  15.871871   \n",
       "21    -0.170688  0.178656  0.170558  0.059509  17.445807  15.976791   \n",
       "22    -0.180329   0.17114  0.160524  0.050445    17.2745  16.048561   \n",
       "23    -0.193518  0.165971  0.148011  0.040154  17.134306  16.099806   \n",
       "24    -0.211157  0.161396  0.136025  0.028755  17.084286  16.144523   \n",
       "25    -0.229173   0.15761  0.127324  0.018587  17.038795    16.1801   \n",
       "26    -0.244127  0.153282   0.12188  0.010345  16.975256  16.219188   \n",
       "27    -0.253303  0.151011   0.11599  0.004566  16.996077  16.237657   \n",
       "28    -0.257323  0.146785  0.108302 -0.000745  17.043926  16.275828   \n",
       "29    -0.258653  0.139436  0.097875 -0.007114  17.076851  16.344114   \n",
       "mean   0.033141  0.358159  0.368126  0.253142  16.803676  13.836232   \n",
       "\n",
       "       LT-3061-2       mean  \n",
       "index      nRMSE      nRMSE  \n",
       "0       4.350405   5.998668  \n",
       "1       5.426794   7.533902  \n",
       "2       6.878473   9.174458  \n",
       "3       8.130364   10.53589  \n",
       "4       8.934091   11.58783  \n",
       "5       9.344888  12.373606  \n",
       "6        9.56284  12.985704  \n",
       "7       9.794577  13.494785  \n",
       "8       10.14288  13.944191  \n",
       "9      10.611442   14.36367  \n",
       "10     11.189711  14.788947  \n",
       "11     11.840862  15.108738  \n",
       "12     12.435311  15.216029  \n",
       "13     12.921848  15.328959  \n",
       "14     13.282552  15.503278  \n",
       "15     13.522742  15.701247  \n",
       "16     13.668892  15.734183  \n",
       "17     13.755103  15.727671  \n",
       "18     13.821449  15.733255  \n",
       "19      13.88591  15.743567  \n",
       "20     13.950989  15.772418  \n",
       "21     14.020898  15.814499  \n",
       "22     14.108765  15.810608  \n",
       "23     14.217879  15.817331  \n",
       "24     14.321827  15.850212  \n",
       "25     14.398767  15.872554  \n",
       "26     14.449079  15.881174  \n",
       "27     14.503521  15.912418  \n",
       "28     14.572544  15.964099  \n",
       "29     14.663286  16.028084  \n",
       "mean    11.89029  14.176733  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history size: 40\n",
      "future size: 10\n",
      "Epoch 1/10000\n",
      "568/568 - 8s - loss: 0.2338 - val_loss: 0.1700 - 8s/epoch - 14ms/step\n",
      "Epoch 2/10000\n",
      "568/568 - 4s - loss: 0.1481 - val_loss: 0.1532 - 4s/epoch - 8ms/step\n",
      "Epoch 3/10000\n",
      "568/568 - 4s - loss: 0.1353 - val_loss: 0.1453 - 4s/epoch - 8ms/step\n",
      "Epoch 4/10000\n",
      "568/568 - 4s - loss: 0.1264 - val_loss: 0.1318 - 4s/epoch - 8ms/step\n",
      "Epoch 5/10000\n",
      "568/568 - 4s - loss: 0.1171 - val_loss: 0.1201 - 4s/epoch - 8ms/step\n",
      "Epoch 6/10000\n",
      "568/568 - 4s - loss: 0.1072 - val_loss: 0.1110 - 4s/epoch - 8ms/step\n",
      "Epoch 7/10000\n",
      "568/568 - 4s - loss: 0.1021 - val_loss: 0.1110 - 4s/epoch - 7ms/step\n",
      "Epoch 8/10000\n",
      "568/568 - 4s - loss: 0.0978 - val_loss: 0.1046 - 4s/epoch - 7ms/step\n",
      "Epoch 9/10000\n",
      "568/568 - 4s - loss: 0.0938 - val_loss: 0.0978 - 4s/epoch - 8ms/step\n",
      "Epoch 10/10000\n",
      "568/568 - 4s - loss: 0.0900 - val_loss: 0.0984 - 4s/epoch - 7ms/step\n",
      "Epoch 11/10000\n",
      "568/568 - 4s - loss: 0.0883 - val_loss: 0.0977 - 4s/epoch - 8ms/step\n",
      "Epoch 12/10000\n",
      "568/568 - 4s - loss: 0.0854 - val_loss: 0.0933 - 4s/epoch - 8ms/step\n",
      "Epoch 13/10000\n",
      "568/568 - 4s - loss: 0.0812 - val_loss: 0.0897 - 4s/epoch - 8ms/step\n",
      "Epoch 14/10000\n",
      "568/568 - 4s - loss: 0.0791 - val_loss: 0.0920 - 4s/epoch - 8ms/step\n",
      "Epoch 15/10000\n",
      "568/568 - 4s - loss: 0.0765 - val_loss: 0.0881 - 4s/epoch - 8ms/step\n",
      "Epoch 16/10000\n",
      "568/568 - 4s - loss: 0.0753 - val_loss: 0.0841 - 4s/epoch - 8ms/step\n",
      "Epoch 17/10000\n",
      "568/568 - 4s - loss: 0.0768 - val_loss: 0.0874 - 4s/epoch - 8ms/step\n",
      "Epoch 18/10000\n",
      "568/568 - 4s - loss: 0.0705 - val_loss: 0.0832 - 4s/epoch - 8ms/step\n",
      "Epoch 19/10000\n",
      "568/568 - 4s - loss: 0.0687 - val_loss: 0.0821 - 4s/epoch - 8ms/step\n",
      "Epoch 20/10000\n",
      "568/568 - 4s - loss: 0.0689 - val_loss: 0.0877 - 4s/epoch - 7ms/step\n",
      "Epoch 21/10000\n",
      "568/568 - 4s - loss: 0.0702 - val_loss: 0.0808 - 4s/epoch - 7ms/step\n",
      "Epoch 22/10000\n",
      "568/568 - 4s - loss: 0.0643 - val_loss: 0.0783 - 4s/epoch - 8ms/step\n",
      "Epoch 23/10000\n",
      "568/568 - 4s - loss: 0.0637 - val_loss: 0.0814 - 4s/epoch - 8ms/step\n",
      "Epoch 24/10000\n",
      "568/568 - 4s - loss: 0.0631 - val_loss: 0.0789 - 4s/epoch - 8ms/step\n",
      "Epoch 25/10000\n",
      "568/568 - 4s - loss: 0.0612 - val_loss: 0.0729 - 4s/epoch - 8ms/step\n",
      "Epoch 26/10000\n",
      "568/568 - 4s - loss: 0.0637 - val_loss: 0.0806 - 4s/epoch - 8ms/step\n",
      "Epoch 27/10000\n",
      "568/568 - 4s - loss: 0.0613 - val_loss: 0.0750 - 4s/epoch - 8ms/step\n",
      "Epoch 28/10000\n",
      "568/568 - 4s - loss: 0.0595 - val_loss: 0.0744 - 4s/epoch - 7ms/step\n",
      "Epoch 29/10000\n",
      "568/568 - 4s - loss: 0.0583 - val_loss: 0.0726 - 4s/epoch - 8ms/step\n",
      "Epoch 30/10000\n",
      "568/568 - 4s - loss: 0.0572 - val_loss: 0.0717 - 4s/epoch - 8ms/step\n",
      "Epoch 31/10000\n",
      "568/568 - 4s - loss: 0.0577 - val_loss: 0.0697 - 4s/epoch - 7ms/step\n",
      "Epoch 32/10000\n",
      "568/568 - 4s - loss: 0.0580 - val_loss: 0.0699 - 4s/epoch - 8ms/step\n",
      "Epoch 33/10000\n",
      "568/568 - 4s - loss: 0.0581 - val_loss: 0.0721 - 4s/epoch - 8ms/step\n",
      "Epoch 34/10000\n",
      "568/568 - 4s - loss: 0.0537 - val_loss: 0.0734 - 4s/epoch - 8ms/step\n",
      "Epoch 35/10000\n",
      "568/568 - 4s - loss: 0.0549 - val_loss: 0.0688 - 4s/epoch - 7ms/step\n",
      "Epoch 36/10000\n",
      "568/568 - 4s - loss: 0.0530 - val_loss: 0.0663 - 4s/epoch - 8ms/step\n",
      "Epoch 37/10000\n",
      "568/568 - 4s - loss: 0.0517 - val_loss: 0.0674 - 4s/epoch - 7ms/step\n",
      "Epoch 38/10000\n",
      "568/568 - 4s - loss: 0.0504 - val_loss: 0.0636 - 4s/epoch - 8ms/step\n",
      "Epoch 39/10000\n",
      "568/568 - 4s - loss: 0.0506 - val_loss: 0.0696 - 4s/epoch - 8ms/step\n",
      "Epoch 40/10000\n",
      "568/568 - 4s - loss: 0.0526 - val_loss: 0.0651 - 4s/epoch - 7ms/step\n",
      "Epoch 41/10000\n",
      "568/568 - 4s - loss: 0.0497 - val_loss: 0.0627 - 4s/epoch - 8ms/step\n",
      "Epoch 42/10000\n",
      "568/568 - 4s - loss: 0.0495 - val_loss: 0.0695 - 4s/epoch - 7ms/step\n",
      "Epoch 43/10000\n",
      "568/568 - 4s - loss: 0.0495 - val_loss: 0.0624 - 4s/epoch - 7ms/step\n",
      "Epoch 44/10000\n",
      "568/568 - 4s - loss: 0.0479 - val_loss: 0.0614 - 4s/epoch - 8ms/step\n",
      "Epoch 45/10000\n",
      "568/568 - 4s - loss: 0.0490 - val_loss: 0.0679 - 4s/epoch - 8ms/step\n",
      "Epoch 46/10000\n",
      "568/568 - 4s - loss: 0.0473 - val_loss: 0.0628 - 4s/epoch - 7ms/step\n",
      "Epoch 47/10000\n",
      "568/568 - 4s - loss: 0.0463 - val_loss: 0.0597 - 4s/epoch - 8ms/step\n",
      "Epoch 48/10000\n",
      "568/568 - 4s - loss: 0.0453 - val_loss: 0.0629 - 4s/epoch - 8ms/step\n",
      "Epoch 49/10000\n",
      "568/568 - 4s - loss: 0.0493 - val_loss: 0.0632 - 4s/epoch - 7ms/step\n",
      "Epoch 50/10000\n",
      "568/568 - 4s - loss: 0.0449 - val_loss: 0.0579 - 4s/epoch - 8ms/step\n",
      "Epoch 51/10000\n",
      "568/568 - 4s - loss: 0.0448 - val_loss: 0.0590 - 4s/epoch - 8ms/step\n",
      "Epoch 52/10000\n",
      "568/568 - 4s - loss: 0.0438 - val_loss: 0.0648 - 4s/epoch - 8ms/step\n",
      "Epoch 53/10000\n",
      "568/568 - 4s - loss: 0.0458 - val_loss: 0.0665 - 4s/epoch - 8ms/step\n",
      "Epoch 54/10000\n",
      "568/568 - 4s - loss: 0.0430 - val_loss: 0.0540 - 4s/epoch - 7ms/step\n",
      "Epoch 55/10000\n",
      "568/568 - 4s - loss: 0.0452 - val_loss: 0.0586 - 4s/epoch - 7ms/step\n",
      "Epoch 56/10000\n",
      "568/568 - 4s - loss: 0.0439 - val_loss: 0.0558 - 4s/epoch - 8ms/step\n",
      "Epoch 57/10000\n",
      "568/568 - 4s - loss: 0.0444 - val_loss: 0.0554 - 4s/epoch - 7ms/step\n",
      "Epoch 58/10000\n",
      "568/568 - 4s - loss: 0.0423 - val_loss: 0.0609 - 4s/epoch - 7ms/step\n",
      "Epoch 59/10000\n",
      "568/568 - 4s - loss: 0.0419 - val_loss: 0.0527 - 4s/epoch - 8ms/step\n",
      "Epoch 60/10000\n",
      "568/568 - 4s - loss: 0.0415 - val_loss: 0.0540 - 4s/epoch - 7ms/step\n",
      "Epoch 61/10000\n",
      "568/568 - 4s - loss: 0.0411 - val_loss: 0.0557 - 4s/epoch - 7ms/step\n",
      "Epoch 62/10000\n",
      "568/568 - 4s - loss: 0.0401 - val_loss: 0.0556 - 4s/epoch - 7ms/step\n",
      "Epoch 63/10000\n",
      "568/568 - 4s - loss: 0.0407 - val_loss: 0.0594 - 4s/epoch - 7ms/step\n",
      "Epoch 64/10000\n",
      "568/568 - 4s - loss: 0.0405 - val_loss: 0.0541 - 4s/epoch - 8ms/step\n",
      "Epoch 65/10000\n",
      "568/568 - 4s - loss: 0.0431 - val_loss: 0.0545 - 4s/epoch - 8ms/step\n",
      "Epoch 66/10000\n",
      "568/568 - 4s - loss: 0.0432 - val_loss: 0.0603 - 4s/epoch - 8ms/step\n",
      "Epoch 67/10000\n",
      "568/568 - 4s - loss: 0.0395 - val_loss: 0.0520 - 4s/epoch - 8ms/step\n",
      "Epoch 68/10000\n",
      "568/568 - 4s - loss: 0.0391 - val_loss: 0.0511 - 4s/epoch - 7ms/step\n",
      "Epoch 69/10000\n",
      "568/568 - 4s - loss: 0.0378 - val_loss: 0.0503 - 4s/epoch - 7ms/step\n",
      "Epoch 70/10000\n",
      "568/568 - 4s - loss: 0.0374 - val_loss: 0.0518 - 4s/epoch - 8ms/step\n",
      "Epoch 71/10000\n",
      "568/568 - 4s - loss: 0.0399 - val_loss: 0.0523 - 4s/epoch - 7ms/step\n",
      "Epoch 72/10000\n",
      "568/568 - 4s - loss: 0.0369 - val_loss: 0.0502 - 4s/epoch - 8ms/step\n",
      "Epoch 73/10000\n",
      "568/568 - 4s - loss: 0.0363 - val_loss: 0.0510 - 4s/epoch - 7ms/step\n",
      "Epoch 74/10000\n",
      "568/568 - 4s - loss: 0.0409 - val_loss: 0.0543 - 4s/epoch - 7ms/step\n",
      "Epoch 75/10000\n",
      "568/568 - 4s - loss: 0.0367 - val_loss: 0.0578 - 4s/epoch - 7ms/step\n",
      "Epoch 76/10000\n",
      "568/568 - 4s - loss: 0.0384 - val_loss: 0.0521 - 4s/epoch - 7ms/step\n",
      "Epoch 77/10000\n",
      "568/568 - 4s - loss: 0.0378 - val_loss: 0.0528 - 4s/epoch - 8ms/step\n",
      "Epoch 78/10000\n",
      "568/568 - 4s - loss: 0.0371 - val_loss: 0.0559 - 4s/epoch - 8ms/step\n",
      "Epoch 79/10000\n",
      "568/568 - 4s - loss: 0.0357 - val_loss: 0.0491 - 4s/epoch - 8ms/step\n",
      "Epoch 80/10000\n",
      "568/568 - 4s - loss: 0.0352 - val_loss: 0.0544 - 4s/epoch - 8ms/step\n",
      "Epoch 81/10000\n",
      "568/568 - 4s - loss: 0.0358 - val_loss: 0.0513 - 4s/epoch - 7ms/step\n",
      "Epoch 82/10000\n",
      "568/568 - 4s - loss: 0.0350 - val_loss: 0.0553 - 4s/epoch - 7ms/step\n",
      "Epoch 83/10000\n",
      "568/568 - 4s - loss: 0.0358 - val_loss: 0.0519 - 4s/epoch - 7ms/step\n",
      "Epoch 84/10000\n",
      "568/568 - 4s - loss: 0.0354 - val_loss: 0.0491 - 4s/epoch - 7ms/step\n",
      "Epoch 85/10000\n",
      "568/568 - 4s - loss: 0.0343 - val_loss: 0.0490 - 4s/epoch - 8ms/step\n",
      "Epoch 86/10000\n",
      "568/568 - 4s - loss: 0.0344 - val_loss: 0.0521 - 4s/epoch - 8ms/step\n",
      "Epoch 87/10000\n",
      "568/568 - 4s - loss: 0.0377 - val_loss: 0.0529 - 4s/epoch - 7ms/step\n",
      "Epoch 88/10000\n",
      "568/568 - 4s - loss: 0.0335 - val_loss: 0.0490 - 4s/epoch - 8ms/step\n",
      "Epoch 89/10000\n",
      "568/568 - 4s - loss: 0.0331 - val_loss: 0.0504 - 4s/epoch - 8ms/step\n",
      "Epoch 90/10000\n",
      "568/568 - 4s - loss: 0.0334 - val_loss: 0.0491 - 4s/epoch - 8ms/step\n",
      "Epoch 91/10000\n",
      "568/568 - 4s - loss: 0.0335 - val_loss: 0.0508 - 4s/epoch - 8ms/step\n",
      "Epoch 92/10000\n",
      "568/568 - 4s - loss: 0.0342 - val_loss: 0.0644 - 4s/epoch - 8ms/step\n",
      "Epoch 93/10000\n",
      "568/568 - 4s - loss: 0.0367 - val_loss: 0.0517 - 4s/epoch - 7ms/step\n",
      "Epoch 94/10000\n",
      "568/568 - 4s - loss: 0.0334 - val_loss: 0.0469 - 4s/epoch - 7ms/step\n",
      "Epoch 95/10000\n",
      "568/568 - 4s - loss: 0.0310 - val_loss: 0.0466 - 4s/epoch - 7ms/step\n",
      "Epoch 96/10000\n",
      "568/568 - 4s - loss: 0.0346 - val_loss: 0.0467 - 4s/epoch - 7ms/step\n",
      "Epoch 97/10000\n",
      "568/568 - 4s - loss: 0.0313 - val_loss: 0.0474 - 4s/epoch - 7ms/step\n",
      "Epoch 98/10000\n",
      "568/568 - 4s - loss: 0.0329 - val_loss: 0.0467 - 4s/epoch - 7ms/step\n",
      "Epoch 99/10000\n",
      "568/568 - 4s - loss: 0.0318 - val_loss: 0.0579 - 4s/epoch - 8ms/step\n",
      "Epoch 100/10000\n",
      "568/568 - 4s - loss: 0.0328 - val_loss: 0.0597 - 4s/epoch - 8ms/step\n",
      "Epoch 101/10000\n",
      "568/568 - 4s - loss: 0.0339 - val_loss: 0.0497 - 4s/epoch - 7ms/step\n",
      "Epoch 102/10000\n",
      "568/568 - 4s - loss: 0.0434 - val_loss: 0.0513 - 4s/epoch - 7ms/step\n",
      "Epoch 103/10000\n",
      "568/568 - 4s - loss: 0.0332 - val_loss: 0.0440 - 4s/epoch - 7ms/step\n",
      "Epoch 104/10000\n",
      "568/568 - 4s - loss: 0.0316 - val_loss: 0.0486 - 4s/epoch - 8ms/step\n",
      "Epoch 105/10000\n",
      "568/568 - 4s - loss: 0.0315 - val_loss: 0.0469 - 4s/epoch - 8ms/step\n",
      "Epoch 106/10000\n",
      "568/568 - 4s - loss: 0.0305 - val_loss: 0.0436 - 4s/epoch - 7ms/step\n",
      "Epoch 107/10000\n",
      "568/568 - 4s - loss: 0.0298 - val_loss: 0.0435 - 4s/epoch - 8ms/step\n",
      "Epoch 108/10000\n",
      "568/568 - 4s - loss: 0.0304 - val_loss: 0.0476 - 4s/epoch - 8ms/step\n",
      "Epoch 109/10000\n",
      "568/568 - 4s - loss: 0.0322 - val_loss: 0.0507 - 4s/epoch - 7ms/step\n",
      "Epoch 110/10000\n",
      "568/568 - 4s - loss: 0.0305 - val_loss: 0.0471 - 4s/epoch - 7ms/step\n",
      "Epoch 111/10000\n",
      "568/568 - 4s - loss: 0.0331 - val_loss: 0.0488 - 4s/epoch - 8ms/step\n",
      "Epoch 112/10000\n",
      "568/568 - 4s - loss: 0.0306 - val_loss: 0.0455 - 4s/epoch - 8ms/step\n",
      "Epoch 113/10000\n",
      "568/568 - 4s - loss: 0.0306 - val_loss: 0.0542 - 4s/epoch - 8ms/step\n",
      "Epoch 114/10000\n",
      "568/568 - 4s - loss: 0.0300 - val_loss: 0.0443 - 4s/epoch - 8ms/step\n",
      "Epoch 115/10000\n",
      "568/568 - 4s - loss: 0.0292 - val_loss: 0.0454 - 4s/epoch - 8ms/step\n",
      "Epoch 116/10000\n",
      "568/568 - 4s - loss: 0.0296 - val_loss: 0.0466 - 4s/epoch - 8ms/step\n",
      "Epoch 117/10000\n",
      "568/568 - 4s - loss: 0.0297 - val_loss: 0.0435 - 4s/epoch - 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_18_layer_call_fn, gru_cell_18_layer_call_and_return_conditional_losses, gru_cell_19_layer_call_fn, gru_cell_19_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/40_10_1_50_1_50_datt_seq2seq_gru_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/40_10_1_50_1_50_datt_seq2seq_gru_test\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7D6F6C9A0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7D770D430> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.914005</td>\n",
       "      <td>0.938262</td>\n",
       "      <td>0.953439</td>\n",
       "      <td>0.935235</td>\n",
       "      <td>4.758877</td>\n",
       "      <td>4.373315</td>\n",
       "      <td>3.322255</td>\n",
       "      <td>4.151482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.825138</td>\n",
       "      <td>0.862425</td>\n",
       "      <td>0.922229</td>\n",
       "      <td>0.869931</td>\n",
       "      <td>6.74419</td>\n",
       "      <td>6.52904</td>\n",
       "      <td>4.294247</td>\n",
       "      <td>5.855826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.705009</td>\n",
       "      <td>0.79686</td>\n",
       "      <td>0.884377</td>\n",
       "      <td>0.795415</td>\n",
       "      <td>8.641359</td>\n",
       "      <td>7.934391</td>\n",
       "      <td>5.236773</td>\n",
       "      <td>7.270841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.583736</td>\n",
       "      <td>0.757529</td>\n",
       "      <td>0.851976</td>\n",
       "      <td>0.731081</td>\n",
       "      <td>10.128946</td>\n",
       "      <td>8.669768</td>\n",
       "      <td>5.925982</td>\n",
       "      <td>8.241565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.470934</td>\n",
       "      <td>0.740693</td>\n",
       "      <td>0.831137</td>\n",
       "      <td>0.680922</td>\n",
       "      <td>11.306407</td>\n",
       "      <td>8.966887</td>\n",
       "      <td>6.329813</td>\n",
       "      <td>8.867703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.369049</td>\n",
       "      <td>0.732699</td>\n",
       "      <td>0.822046</td>\n",
       "      <td>0.641265</td>\n",
       "      <td>12.226627</td>\n",
       "      <td>9.104996</td>\n",
       "      <td>6.498674</td>\n",
       "      <td>9.276765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.27969</td>\n",
       "      <td>0.728522</td>\n",
       "      <td>0.820039</td>\n",
       "      <td>0.609417</td>\n",
       "      <td>12.937975</td>\n",
       "      <td>9.17576</td>\n",
       "      <td>6.536367</td>\n",
       "      <td>9.550034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.203551</td>\n",
       "      <td>0.722403</td>\n",
       "      <td>0.818835</td>\n",
       "      <td>0.581596</td>\n",
       "      <td>13.571647</td>\n",
       "      <td>9.277903</td>\n",
       "      <td>6.560104</td>\n",
       "      <td>9.803218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.140508</td>\n",
       "      <td>0.713105</td>\n",
       "      <td>0.813252</td>\n",
       "      <td>0.555621</td>\n",
       "      <td>14.115045</td>\n",
       "      <td>9.43093</td>\n",
       "      <td>6.662535</td>\n",
       "      <td>10.069503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.087098</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.797582</td>\n",
       "      <td>0.527626</td>\n",
       "      <td>14.563731</td>\n",
       "      <td>9.671184</td>\n",
       "      <td>6.93884</td>\n",
       "      <td>10.391252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.457872</td>\n",
       "      <td>0.76907</td>\n",
       "      <td>0.851491</td>\n",
       "      <td>0.692811</td>\n",
       "      <td>10.89948</td>\n",
       "      <td>8.313417</td>\n",
       "      <td>5.830559</td>\n",
       "      <td>8.347819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TT-3061-3 TT-3061-5 LT-3061-2      mean  TT-3061-3 TT-3061-5 LT-3061-2  \\\n",
       "index        R2        R2        R2        R2      nRMSE     nRMSE     nRMSE   \n",
       "0      0.914005  0.938262  0.953439  0.935235   4.758877  4.373315  3.322255   \n",
       "1      0.825138  0.862425  0.922229  0.869931    6.74419   6.52904  4.294247   \n",
       "2      0.705009   0.79686  0.884377  0.795415   8.641359  7.934391  5.236773   \n",
       "3      0.583736  0.757529  0.851976  0.731081  10.128946  8.669768  5.925982   \n",
       "4      0.470934  0.740693  0.831137  0.680922  11.306407  8.966887  6.329813   \n",
       "5      0.369049  0.732699  0.822046  0.641265  12.226627  9.104996  6.498674   \n",
       "6       0.27969  0.728522  0.820039  0.609417  12.937975   9.17576  6.536367   \n",
       "7      0.203551  0.722403  0.818835  0.581596  13.571647  9.277903  6.560104   \n",
       "8      0.140508  0.713105  0.813252  0.555621  14.115045   9.43093  6.662535   \n",
       "9      0.087098    0.6982  0.797582  0.527626  14.563731  9.671184   6.93884   \n",
       "mean   0.457872   0.76907  0.851491  0.692811   10.89948  8.313417  5.830559   \n",
       "\n",
       "            mean  \n",
       "index      nRMSE  \n",
       "0       4.151482  \n",
       "1       5.855826  \n",
       "2       7.270841  \n",
       "3       8.241565  \n",
       "4       8.867703  \n",
       "5       9.276765  \n",
       "6       9.550034  \n",
       "7       9.803218  \n",
       "8      10.069503  \n",
       "9      10.391252  \n",
       "mean    8.347819  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history size: 40\n",
      "future size: 20\n",
      "Epoch 1/10000\n",
      "563/563 - 8s - loss: 0.3196 - val_loss: 0.2587 - 8s/epoch - 14ms/step\n",
      "Epoch 2/10000\n",
      "563/563 - 5s - loss: 0.2228 - val_loss: 0.2341 - 5s/epoch - 8ms/step\n",
      "Epoch 3/10000\n",
      "563/563 - 5s - loss: 0.2067 - val_loss: 0.2172 - 5s/epoch - 8ms/step\n",
      "Epoch 4/10000\n",
      "563/563 - 5s - loss: 0.1949 - val_loss: 0.2107 - 5s/epoch - 8ms/step\n",
      "Epoch 5/10000\n",
      "563/563 - 5s - loss: 0.1851 - val_loss: 0.2071 - 5s/epoch - 8ms/step\n",
      "Epoch 6/10000\n",
      "563/563 - 4s - loss: 0.1753 - val_loss: 0.1874 - 4s/epoch - 8ms/step\n",
      "Epoch 7/10000\n",
      "563/563 - 4s - loss: 0.1648 - val_loss: 0.1856 - 4s/epoch - 8ms/step\n",
      "Epoch 8/10000\n",
      "563/563 - 4s - loss: 0.1577 - val_loss: 0.1714 - 4s/epoch - 8ms/step\n",
      "Epoch 9/10000\n",
      "563/563 - 4s - loss: 0.1509 - val_loss: 0.1756 - 4s/epoch - 8ms/step\n",
      "Epoch 10/10000\n",
      "563/563 - 5s - loss: 0.1436 - val_loss: 0.1599 - 5s/epoch - 8ms/step\n",
      "Epoch 11/10000\n",
      "563/563 - 5s - loss: 0.1426 - val_loss: 0.1512 - 5s/epoch - 8ms/step\n",
      "Epoch 12/10000\n",
      "563/563 - 5s - loss: 0.1337 - val_loss: 0.1576 - 5s/epoch - 8ms/step\n",
      "Epoch 13/10000\n",
      "563/563 - 5s - loss: 0.1297 - val_loss: 0.1444 - 5s/epoch - 8ms/step\n",
      "Epoch 14/10000\n",
      "563/563 - 5s - loss: 0.1246 - val_loss: 0.1413 - 5s/epoch - 8ms/step\n",
      "Epoch 15/10000\n",
      "563/563 - 5s - loss: 0.1200 - val_loss: 0.1348 - 5s/epoch - 8ms/step\n",
      "Epoch 16/10000\n",
      "563/563 - 4s - loss: 0.1185 - val_loss: 0.1327 - 4s/epoch - 8ms/step\n",
      "Epoch 17/10000\n",
      "563/563 - 4s - loss: 0.1121 - val_loss: 0.1265 - 4s/epoch - 8ms/step\n",
      "Epoch 18/10000\n",
      "563/563 - 4s - loss: 0.1081 - val_loss: 0.1235 - 4s/epoch - 8ms/step\n",
      "Epoch 19/10000\n",
      "563/563 - 5s - loss: 0.1090 - val_loss: 0.1247 - 5s/epoch - 8ms/step\n",
      "Epoch 20/10000\n",
      "563/563 - 5s - loss: 0.1041 - val_loss: 0.1283 - 5s/epoch - 8ms/step\n",
      "Epoch 21/10000\n",
      "563/563 - 5s - loss: 0.1004 - val_loss: 0.1191 - 5s/epoch - 8ms/step\n",
      "Epoch 22/10000\n",
      "563/563 - 5s - loss: 0.0964 - val_loss: 0.1227 - 5s/epoch - 8ms/step\n",
      "Epoch 23/10000\n",
      "563/563 - 4s - loss: 0.0975 - val_loss: 0.1145 - 4s/epoch - 8ms/step\n",
      "Epoch 24/10000\n",
      "563/563 - 4s - loss: 0.0937 - val_loss: 0.1107 - 4s/epoch - 8ms/step\n",
      "Epoch 25/10000\n",
      "563/563 - 5s - loss: 0.0925 - val_loss: 0.1104 - 5s/epoch - 8ms/step\n",
      "Epoch 26/10000\n",
      "563/563 - 5s - loss: 0.0908 - val_loss: 0.1067 - 5s/epoch - 8ms/step\n",
      "Epoch 27/10000\n",
      "563/563 - 5s - loss: 0.0892 - val_loss: 0.1071 - 5s/epoch - 8ms/step\n",
      "Epoch 28/10000\n",
      "563/563 - 5s - loss: 0.0876 - val_loss: 0.1075 - 5s/epoch - 8ms/step\n",
      "Epoch 29/10000\n",
      "563/563 - 5s - loss: 0.0878 - val_loss: 0.1145 - 5s/epoch - 8ms/step\n",
      "Epoch 30/10000\n",
      "563/563 - 4s - loss: 0.0852 - val_loss: 0.1041 - 4s/epoch - 8ms/step\n",
      "Epoch 31/10000\n",
      "563/563 - 5s - loss: 0.0822 - val_loss: 0.1074 - 5s/epoch - 8ms/step\n",
      "Epoch 32/10000\n",
      "563/563 - 5s - loss: 0.0832 - val_loss: 0.1010 - 5s/epoch - 8ms/step\n",
      "Epoch 33/10000\n",
      "563/563 - 4s - loss: 0.0825 - val_loss: 0.1002 - 4s/epoch - 8ms/step\n",
      "Epoch 34/10000\n",
      "563/563 - 5s - loss: 0.0806 - val_loss: 0.1092 - 5s/epoch - 8ms/step\n",
      "Epoch 35/10000\n",
      "563/563 - 5s - loss: 0.0794 - val_loss: 0.1056 - 5s/epoch - 8ms/step\n",
      "Epoch 36/10000\n",
      "563/563 - 4s - loss: 0.0806 - val_loss: 0.1001 - 4s/epoch - 8ms/step\n",
      "Epoch 37/10000\n",
      "563/563 - 5s - loss: 0.0765 - val_loss: 0.0970 - 5s/epoch - 8ms/step\n",
      "Epoch 38/10000\n",
      "563/563 - 4s - loss: 0.0761 - val_loss: 0.1024 - 4s/epoch - 8ms/step\n",
      "Epoch 39/10000\n",
      "563/563 - 4s - loss: 0.0754 - val_loss: 0.0945 - 4s/epoch - 8ms/step\n",
      "Epoch 40/10000\n",
      "563/563 - 4s - loss: 0.0755 - val_loss: 0.0900 - 4s/epoch - 8ms/step\n",
      "Epoch 41/10000\n",
      "563/563 - 4s - loss: 0.0755 - val_loss: 0.0967 - 4s/epoch - 8ms/step\n",
      "Epoch 42/10000\n",
      "563/563 - 4s - loss: 0.0729 - val_loss: 0.0857 - 4s/epoch - 8ms/step\n",
      "Epoch 43/10000\n",
      "563/563 - 4s - loss: 0.0703 - val_loss: 0.0953 - 4s/epoch - 8ms/step\n",
      "Epoch 44/10000\n",
      "563/563 - 5s - loss: 0.0688 - val_loss: 0.1162 - 5s/epoch - 8ms/step\n",
      "Epoch 45/10000\n",
      "563/563 - 5s - loss: 0.0908 - val_loss: 0.1008 - 5s/epoch - 8ms/step\n",
      "Epoch 46/10000\n",
      "563/563 - 5s - loss: 0.0752 - val_loss: 0.0963 - 5s/epoch - 8ms/step\n",
      "Epoch 47/10000\n",
      "563/563 - 5s - loss: 0.0728 - val_loss: 0.0949 - 5s/epoch - 8ms/step\n",
      "Epoch 48/10000\n",
      "563/563 - 5s - loss: 0.0713 - val_loss: 0.0931 - 5s/epoch - 8ms/step\n",
      "Epoch 49/10000\n",
      "563/563 - 5s - loss: 0.0706 - val_loss: 0.0900 - 5s/epoch - 8ms/step\n",
      "Epoch 50/10000\n",
      "563/563 - 5s - loss: 0.0692 - val_loss: 0.0925 - 5s/epoch - 8ms/step\n",
      "Epoch 51/10000\n",
      "563/563 - 5s - loss: 0.0687 - val_loss: 0.0877 - 5s/epoch - 8ms/step\n",
      "Epoch 52/10000\n",
      "563/563 - 5s - loss: 0.0674 - val_loss: 0.0936 - 5s/epoch - 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_20_layer_call_fn, gru_cell_20_layer_call_and_return_conditional_losses, gru_cell_21_layer_call_fn, gru_cell_21_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/40_20_1_50_1_50_datt_seq2seq_gru_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/40_20_1_50_1_50_datt_seq2seq_gru_test\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7ED920130> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7D7836610> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.913993</td>\n",
       "      <td>0.951672</td>\n",
       "      <td>0.924921</td>\n",
       "      <td>5.948916</td>\n",
       "      <td>5.156673</td>\n",
       "      <td>3.376807</td>\n",
       "      <td>4.827465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.815344</td>\n",
       "      <td>0.865295</td>\n",
       "      <td>0.921333</td>\n",
       "      <td>0.867324</td>\n",
       "      <td>8.326526</td>\n",
       "      <td>6.455542</td>\n",
       "      <td>4.309538</td>\n",
       "      <td>6.363869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.701051</td>\n",
       "      <td>0.824692</td>\n",
       "      <td>0.885894</td>\n",
       "      <td>0.803879</td>\n",
       "      <td>10.133035</td>\n",
       "      <td>7.367321</td>\n",
       "      <td>5.191751</td>\n",
       "      <td>7.564036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.585628</td>\n",
       "      <td>0.793889</td>\n",
       "      <td>0.859187</td>\n",
       "      <td>0.746235</td>\n",
       "      <td>11.531438</td>\n",
       "      <td>7.991198</td>\n",
       "      <td>5.768685</td>\n",
       "      <td>8.43044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.47862</td>\n",
       "      <td>0.767537</td>\n",
       "      <td>0.843643</td>\n",
       "      <td>0.6966</td>\n",
       "      <td>12.727887</td>\n",
       "      <td>8.49047</td>\n",
       "      <td>6.080141</td>\n",
       "      <td>9.099499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.381571</td>\n",
       "      <td>0.744129</td>\n",
       "      <td>0.834163</td>\n",
       "      <td>0.653287</td>\n",
       "      <td>13.815178</td>\n",
       "      <td>8.911728</td>\n",
       "      <td>6.262828</td>\n",
       "      <td>9.663245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.294258</td>\n",
       "      <td>0.722368</td>\n",
       "      <td>0.825022</td>\n",
       "      <td>0.613883</td>\n",
       "      <td>14.46882</td>\n",
       "      <td>9.28506</td>\n",
       "      <td>6.434417</td>\n",
       "      <td>10.062766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.215872</td>\n",
       "      <td>0.701731</td>\n",
       "      <td>0.814784</td>\n",
       "      <td>0.577462</td>\n",
       "      <td>14.959615</td>\n",
       "      <td>9.62612</td>\n",
       "      <td>6.621284</td>\n",
       "      <td>10.40234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.148178</td>\n",
       "      <td>0.682803</td>\n",
       "      <td>0.802885</td>\n",
       "      <td>0.544622</td>\n",
       "      <td>15.361607</td>\n",
       "      <td>9.928587</td>\n",
       "      <td>6.831881</td>\n",
       "      <td>10.707358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.091456</td>\n",
       "      <td>0.66307</td>\n",
       "      <td>0.785137</td>\n",
       "      <td>0.513221</td>\n",
       "      <td>15.634142</td>\n",
       "      <td>10.232886</td>\n",
       "      <td>7.133905</td>\n",
       "      <td>11.000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.043925</td>\n",
       "      <td>0.642631</td>\n",
       "      <td>0.758933</td>\n",
       "      <td>0.48183</td>\n",
       "      <td>15.869563</td>\n",
       "      <td>10.539284</td>\n",
       "      <td>7.557516</td>\n",
       "      <td>11.322121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.622383</td>\n",
       "      <td>0.730449</td>\n",
       "      <td>0.452158</td>\n",
       "      <td>16.094531</td>\n",
       "      <td>10.833102</td>\n",
       "      <td>7.992873</td>\n",
       "      <td>11.640169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.029604</td>\n",
       "      <td>0.601217</td>\n",
       "      <td>0.708122</td>\n",
       "      <td>0.426579</td>\n",
       "      <td>16.133882</td>\n",
       "      <td>11.131758</td>\n",
       "      <td>8.319272</td>\n",
       "      <td>11.861637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.056932</td>\n",
       "      <td>0.580611</td>\n",
       "      <td>0.692612</td>\n",
       "      <td>0.40543</td>\n",
       "      <td>16.124101</td>\n",
       "      <td>11.416642</td>\n",
       "      <td>8.540074</td>\n",
       "      <td>12.026939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.080154</td>\n",
       "      <td>0.561639</td>\n",
       "      <td>0.678246</td>\n",
       "      <td>0.386577</td>\n",
       "      <td>16.133898</td>\n",
       "      <td>11.672472</td>\n",
       "      <td>8.739964</td>\n",
       "      <td>12.182111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.098176</td>\n",
       "      <td>0.544373</td>\n",
       "      <td>0.662092</td>\n",
       "      <td>0.36943</td>\n",
       "      <td>16.105283</td>\n",
       "      <td>11.899507</td>\n",
       "      <td>8.959796</td>\n",
       "      <td>12.321529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.111644</td>\n",
       "      <td>0.527489</td>\n",
       "      <td>0.645446</td>\n",
       "      <td>0.353764</td>\n",
       "      <td>16.046003</td>\n",
       "      <td>12.116178</td>\n",
       "      <td>9.181306</td>\n",
       "      <td>12.447829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.120461</td>\n",
       "      <td>0.509668</td>\n",
       "      <td>0.630099</td>\n",
       "      <td>0.339769</td>\n",
       "      <td>16.070121</td>\n",
       "      <td>12.340056</td>\n",
       "      <td>9.381829</td>\n",
       "      <td>12.597336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.125214</td>\n",
       "      <td>0.490847</td>\n",
       "      <td>0.615639</td>\n",
       "      <td>0.327091</td>\n",
       "      <td>16.123665</td>\n",
       "      <td>12.572972</td>\n",
       "      <td>9.567446</td>\n",
       "      <td>12.754694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.127281</td>\n",
       "      <td>0.4702</td>\n",
       "      <td>0.602199</td>\n",
       "      <td>0.315039</td>\n",
       "      <td>16.1611</td>\n",
       "      <td>12.824069</td>\n",
       "      <td>9.73713</td>\n",
       "      <td>12.907433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.195959</td>\n",
       "      <td>0.661528</td>\n",
       "      <td>0.762378</td>\n",
       "      <td>0.539955</td>\n",
       "      <td>14.188465</td>\n",
       "      <td>10.039581</td>\n",
       "      <td>7.299422</td>\n",
       "      <td>10.509156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TT-3061-3 TT-3061-5 LT-3061-2      mean  TT-3061-3  TT-3061-5 LT-3061-2  \\\n",
       "index        R2        R2        R2        R2      nRMSE      nRMSE     nRMSE   \n",
       "0        0.9091  0.913993  0.951672  0.924921   5.948916   5.156673  3.376807   \n",
       "1      0.815344  0.865295  0.921333  0.867324   8.326526   6.455542  4.309538   \n",
       "2      0.701051  0.824692  0.885894  0.803879  10.133035   7.367321  5.191751   \n",
       "3      0.585628  0.793889  0.859187  0.746235  11.531438   7.991198  5.768685   \n",
       "4       0.47862  0.767537  0.843643    0.6966  12.727887    8.49047  6.080141   \n",
       "5      0.381571  0.744129  0.834163  0.653287  13.815178   8.911728  6.262828   \n",
       "6      0.294258  0.722368  0.825022  0.613883   14.46882    9.28506  6.434417   \n",
       "7      0.215872  0.701731  0.814784  0.577462  14.959615    9.62612  6.621284   \n",
       "8      0.148178  0.682803  0.802885  0.544622  15.361607   9.928587  6.831881   \n",
       "9      0.091456   0.66307  0.785137  0.513221  15.634142  10.232886  7.133905   \n",
       "10     0.043925  0.642631  0.758933   0.48183  15.869563  10.539284  7.557516   \n",
       "11     0.003642  0.622383  0.730449  0.452158  16.094531  10.833102  7.992873   \n",
       "12    -0.029604  0.601217  0.708122  0.426579  16.133882  11.131758  8.319272   \n",
       "13    -0.056932  0.580611  0.692612   0.40543  16.124101  11.416642  8.540074   \n",
       "14    -0.080154  0.561639  0.678246  0.386577  16.133898  11.672472  8.739964   \n",
       "15    -0.098176  0.544373  0.662092   0.36943  16.105283  11.899507  8.959796   \n",
       "16    -0.111644  0.527489  0.645446  0.353764  16.046003  12.116178  9.181306   \n",
       "17    -0.120461  0.509668  0.630099  0.339769  16.070121  12.340056  9.381829   \n",
       "18    -0.125214  0.490847  0.615639  0.327091  16.123665  12.572972  9.567446   \n",
       "19    -0.127281    0.4702  0.602199  0.315039    16.1611  12.824069   9.73713   \n",
       "mean   0.195959  0.661528  0.762378  0.539955  14.188465  10.039581  7.299422   \n",
       "\n",
       "            mean  \n",
       "index      nRMSE  \n",
       "0       4.827465  \n",
       "1       6.363869  \n",
       "2       7.564036  \n",
       "3        8.43044  \n",
       "4       9.099499  \n",
       "5       9.663245  \n",
       "6      10.062766  \n",
       "7       10.40234  \n",
       "8      10.707358  \n",
       "9      11.000311  \n",
       "10     11.322121  \n",
       "11     11.640169  \n",
       "12     11.861637  \n",
       "13     12.026939  \n",
       "14     12.182111  \n",
       "15     12.321529  \n",
       "16     12.447829  \n",
       "17     12.597336  \n",
       "18     12.754694  \n",
       "19     12.907433  \n",
       "mean   10.509156  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history size: 40\n",
      "future size: 30\n",
      "Epoch 1/10000\n",
      "559/559 - 8s - loss: 0.3749 - val_loss: 0.3162 - 8s/epoch - 14ms/step\n",
      "Epoch 2/10000\n",
      "559/559 - 4s - loss: 0.2851 - val_loss: 0.2826 - 4s/epoch - 8ms/step\n",
      "Epoch 3/10000\n",
      "559/559 - 4s - loss: 0.2635 - val_loss: 0.2686 - 4s/epoch - 8ms/step\n",
      "Epoch 4/10000\n",
      "559/559 - 4s - loss: 0.2470 - val_loss: 0.2540 - 4s/epoch - 8ms/step\n",
      "Epoch 5/10000\n",
      "559/559 - 4s - loss: 0.2293 - val_loss: 0.2348 - 4s/epoch - 8ms/step\n",
      "Epoch 6/10000\n",
      "559/559 - 4s - loss: 0.2153 - val_loss: 0.2112 - 4s/epoch - 8ms/step\n",
      "Epoch 7/10000\n",
      "559/559 - 4s - loss: 0.2021 - val_loss: 0.2027 - 4s/epoch - 8ms/step\n",
      "Epoch 8/10000\n",
      "559/559 - 4s - loss: 0.1894 - val_loss: 0.1956 - 4s/epoch - 8ms/step\n",
      "Epoch 9/10000\n",
      "559/559 - 4s - loss: 0.1793 - val_loss: 0.1839 - 4s/epoch - 8ms/step\n",
      "Epoch 10/10000\n",
      "559/559 - 4s - loss: 0.1728 - val_loss: 0.1794 - 4s/epoch - 8ms/step\n",
      "Epoch 11/10000\n",
      "559/559 - 4s - loss: 0.1657 - val_loss: 0.1761 - 4s/epoch - 8ms/step\n",
      "Epoch 12/10000\n",
      "559/559 - 4s - loss: 0.1615 - val_loss: 0.1663 - 4s/epoch - 8ms/step\n",
      "Epoch 13/10000\n",
      "559/559 - 4s - loss: 0.1545 - val_loss: 0.1596 - 4s/epoch - 8ms/step\n",
      "Epoch 14/10000\n",
      "559/559 - 4s - loss: 0.1520 - val_loss: 0.1568 - 4s/epoch - 8ms/step\n",
      "Epoch 15/10000\n",
      "559/559 - 4s - loss: 0.1484 - val_loss: 0.1607 - 4s/epoch - 8ms/step\n",
      "Epoch 16/10000\n",
      "559/559 - 4s - loss: 0.1430 - val_loss: 0.1469 - 4s/epoch - 8ms/step\n",
      "Epoch 17/10000\n",
      "559/559 - 4s - loss: 0.1393 - val_loss: 0.1478 - 4s/epoch - 8ms/step\n",
      "Epoch 18/10000\n",
      "559/559 - 4s - loss: 0.1378 - val_loss: 0.1422 - 4s/epoch - 8ms/step\n",
      "Epoch 19/10000\n",
      "559/559 - 4s - loss: 0.1298 - val_loss: 0.1449 - 4s/epoch - 8ms/step\n",
      "Epoch 20/10000\n",
      "559/559 - 4s - loss: 0.1297 - val_loss: 0.1387 - 4s/epoch - 8ms/step\n",
      "Epoch 21/10000\n",
      "559/559 - 4s - loss: 0.1258 - val_loss: 0.1419 - 4s/epoch - 8ms/step\n",
      "Epoch 22/10000\n",
      "559/559 - 4s - loss: 0.1196 - val_loss: 0.1342 - 4s/epoch - 8ms/step\n",
      "Epoch 23/10000\n",
      "559/559 - 4s - loss: 0.1245 - val_loss: 0.1354 - 4s/epoch - 8ms/step\n",
      "Epoch 24/10000\n",
      "559/559 - 4s - loss: 0.1221 - val_loss: 0.1312 - 4s/epoch - 8ms/step\n",
      "Epoch 25/10000\n",
      "559/559 - 4s - loss: 0.1169 - val_loss: 0.1219 - 4s/epoch - 8ms/step\n",
      "Epoch 26/10000\n",
      "559/559 - 4s - loss: 0.1103 - val_loss: 0.1232 - 4s/epoch - 7ms/step\n",
      "Epoch 27/10000\n",
      "559/559 - 4s - loss: 0.1099 - val_loss: 0.1207 - 4s/epoch - 8ms/step\n",
      "Epoch 28/10000\n",
      "559/559 - 4s - loss: 0.1110 - val_loss: 0.1230 - 4s/epoch - 7ms/step\n",
      "Epoch 29/10000\n",
      "559/559 - 4s - loss: 0.1090 - val_loss: 0.1158 - 4s/epoch - 8ms/step\n",
      "Epoch 30/10000\n",
      "559/559 - 4s - loss: 0.1065 - val_loss: 0.1154 - 4s/epoch - 8ms/step\n",
      "Epoch 31/10000\n",
      "559/559 - 4s - loss: 0.1052 - val_loss: 0.1218 - 4s/epoch - 8ms/step\n",
      "Epoch 32/10000\n",
      "559/559 - 4s - loss: 0.1050 - val_loss: 0.1139 - 4s/epoch - 8ms/step\n",
      "Epoch 33/10000\n",
      "559/559 - 4s - loss: 0.1007 - val_loss: 0.1080 - 4s/epoch - 8ms/step\n",
      "Epoch 34/10000\n",
      "559/559 - 4s - loss: 0.0992 - val_loss: 0.1143 - 4s/epoch - 8ms/step\n",
      "Epoch 35/10000\n",
      "559/559 - 4s - loss: 0.0983 - val_loss: 0.1141 - 4s/epoch - 8ms/step\n",
      "Epoch 36/10000\n",
      "559/559 - 4s - loss: 0.1000 - val_loss: 0.1339 - 4s/epoch - 8ms/step\n",
      "Epoch 37/10000\n",
      "559/559 - 4s - loss: 0.1008 - val_loss: 0.1021 - 4s/epoch - 8ms/step\n",
      "Epoch 38/10000\n",
      "559/559 - 4s - loss: 0.0945 - val_loss: 0.1111 - 4s/epoch - 8ms/step\n",
      "Epoch 39/10000\n",
      "559/559 - 4s - loss: 0.0931 - val_loss: 0.1078 - 4s/epoch - 8ms/step\n",
      "Epoch 40/10000\n",
      "559/559 - 4s - loss: 0.0938 - val_loss: 0.1017 - 4s/epoch - 8ms/step\n",
      "Epoch 41/10000\n",
      "559/559 - 4s - loss: 0.0911 - val_loss: 0.0977 - 4s/epoch - 8ms/step\n",
      "Epoch 42/10000\n",
      "559/559 - 4s - loss: 0.0906 - val_loss: 0.0987 - 4s/epoch - 8ms/step\n",
      "Epoch 43/10000\n",
      "559/559 - 4s - loss: 0.0905 - val_loss: 0.1003 - 4s/epoch - 8ms/step\n",
      "Epoch 44/10000\n",
      "559/559 - 4s - loss: 0.0902 - val_loss: 0.1010 - 4s/epoch - 8ms/step\n",
      "Epoch 45/10000\n",
      "559/559 - 4s - loss: 0.0888 - val_loss: 0.1064 - 4s/epoch - 8ms/step\n",
      "Epoch 46/10000\n",
      "559/559 - 4s - loss: 0.0869 - val_loss: 0.0923 - 4s/epoch - 8ms/step\n",
      "Epoch 47/10000\n",
      "559/559 - 4s - loss: 0.0896 - val_loss: 0.0940 - 4s/epoch - 8ms/step\n",
      "Epoch 48/10000\n",
      "559/559 - 4s - loss: 0.0862 - val_loss: 0.0976 - 4s/epoch - 8ms/step\n",
      "Epoch 49/10000\n",
      "559/559 - 4s - loss: 0.0825 - val_loss: 0.0905 - 4s/epoch - 8ms/step\n",
      "Epoch 50/10000\n",
      "559/559 - 4s - loss: 0.0822 - val_loss: 0.0930 - 4s/epoch - 8ms/step\n",
      "Epoch 51/10000\n",
      "559/559 - 4s - loss: 0.0829 - val_loss: 0.1107 - 4s/epoch - 7ms/step\n",
      "Epoch 52/10000\n",
      "559/559 - 4s - loss: 0.0812 - val_loss: 0.0937 - 4s/epoch - 8ms/step\n",
      "Epoch 53/10000\n",
      "559/559 - 4s - loss: 0.0796 - val_loss: 0.0989 - 4s/epoch - 8ms/step\n",
      "Epoch 54/10000\n",
      "559/559 - 4s - loss: 0.0812 - val_loss: 0.0886 - 4s/epoch - 8ms/step\n",
      "Epoch 55/10000\n",
      "559/559 - 4s - loss: 0.0814 - val_loss: 0.0921 - 4s/epoch - 7ms/step\n",
      "Epoch 56/10000\n",
      "559/559 - 4s - loss: 0.0795 - val_loss: 0.0962 - 4s/epoch - 8ms/step\n",
      "Epoch 57/10000\n",
      "559/559 - 4s - loss: 0.0806 - val_loss: 0.0903 - 4s/epoch - 8ms/step\n",
      "Epoch 58/10000\n",
      "559/559 - 4s - loss: 0.0769 - val_loss: 0.0856 - 4s/epoch - 8ms/step\n",
      "Epoch 59/10000\n",
      "559/559 - 4s - loss: 0.0765 - val_loss: 0.0894 - 4s/epoch - 8ms/step\n",
      "Epoch 60/10000\n",
      "559/559 - 4s - loss: 0.0747 - val_loss: 0.0850 - 4s/epoch - 8ms/step\n",
      "Epoch 61/10000\n",
      "559/559 - 4s - loss: 0.0739 - val_loss: 0.0844 - 4s/epoch - 8ms/step\n",
      "Epoch 62/10000\n",
      "559/559 - 4s - loss: 0.0774 - val_loss: 0.0868 - 4s/epoch - 8ms/step\n",
      "Epoch 63/10000\n",
      "559/559 - 4s - loss: 0.0726 - val_loss: 0.0905 - 4s/epoch - 8ms/step\n",
      "Epoch 64/10000\n",
      "559/559 - 4s - loss: 0.0767 - val_loss: 0.0822 - 4s/epoch - 8ms/step\n",
      "Epoch 65/10000\n",
      "559/559 - 4s - loss: 0.0715 - val_loss: 0.0846 - 4s/epoch - 8ms/step\n",
      "Epoch 66/10000\n",
      "559/559 - 4s - loss: 0.0713 - val_loss: 0.0818 - 4s/epoch - 8ms/step\n",
      "Epoch 67/10000\n",
      "559/559 - 4s - loss: 0.0715 - val_loss: 0.0872 - 4s/epoch - 8ms/step\n",
      "Epoch 68/10000\n",
      "559/559 - 4s - loss: 0.0711 - val_loss: 0.0830 - 4s/epoch - 8ms/step\n",
      "Epoch 69/10000\n",
      "559/559 - 4s - loss: 0.0703 - val_loss: 0.0774 - 4s/epoch - 8ms/step\n",
      "Epoch 70/10000\n",
      "559/559 - 4s - loss: 0.0695 - val_loss: 0.0848 - 4s/epoch - 8ms/step\n",
      "Epoch 71/10000\n",
      "559/559 - 4s - loss: 0.0751 - val_loss: 0.0842 - 4s/epoch - 8ms/step\n",
      "Epoch 72/10000\n",
      "559/559 - 4s - loss: 0.0692 - val_loss: 0.0758 - 4s/epoch - 8ms/step\n",
      "Epoch 73/10000\n",
      "559/559 - 4s - loss: 0.0679 - val_loss: 0.0765 - 4s/epoch - 8ms/step\n",
      "Epoch 74/10000\n",
      "559/559 - 4s - loss: 0.0669 - val_loss: 0.0817 - 4s/epoch - 8ms/step\n",
      "Epoch 75/10000\n",
      "559/559 - 4s - loss: 0.0675 - val_loss: 0.0784 - 4s/epoch - 8ms/step\n",
      "Epoch 76/10000\n",
      "559/559 - 4s - loss: 0.0660 - val_loss: 0.0805 - 4s/epoch - 8ms/step\n",
      "Epoch 77/10000\n",
      "559/559 - 4s - loss: 0.0662 - val_loss: 0.0795 - 4s/epoch - 8ms/step\n",
      "Epoch 78/10000\n",
      "559/559 - 4s - loss: 0.0655 - val_loss: 0.0778 - 4s/epoch - 8ms/step\n",
      "Epoch 79/10000\n",
      "559/559 - 4s - loss: 0.0716 - val_loss: 0.0882 - 4s/epoch - 8ms/step\n",
      "Epoch 80/10000\n",
      "559/559 - 4s - loss: 0.0718 - val_loss: 0.0875 - 4s/epoch - 8ms/step\n",
      "Epoch 81/10000\n",
      "559/559 - 4s - loss: 0.0714 - val_loss: 0.0766 - 4s/epoch - 8ms/step\n",
      "Epoch 82/10000\n",
      "559/559 - 4s - loss: 0.0628 - val_loss: 0.0792 - 4s/epoch - 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_22_layer_call_fn, gru_cell_22_layer_call_and_return_conditional_losses, gru_cell_23_layer_call_fn, gru_cell_23_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/40_30_1_50_1_50_datt_seq2seq_gru_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/40_30_1_50_1_50_datt_seq2seq_gru_test\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B8801FADF0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001B7A54C0CA0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "      <th>TT-3061-3</th>\n",
       "      <th>TT-3061-5</th>\n",
       "      <th>LT-3061-2</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "      <td>nRMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.866964</td>\n",
       "      <td>0.864255</td>\n",
       "      <td>0.911928</td>\n",
       "      <td>0.881049</td>\n",
       "      <td>7.195307</td>\n",
       "      <td>6.478311</td>\n",
       "      <td>4.545779</td>\n",
       "      <td>6.073132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.76892</td>\n",
       "      <td>0.823652</td>\n",
       "      <td>0.872457</td>\n",
       "      <td>0.821677</td>\n",
       "      <td>9.485051</td>\n",
       "      <td>7.384375</td>\n",
       "      <td>5.473092</td>\n",
       "      <td>7.447506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.662352</td>\n",
       "      <td>0.787553</td>\n",
       "      <td>0.841929</td>\n",
       "      <td>0.763945</td>\n",
       "      <td>11.467871</td>\n",
       "      <td>8.105745</td>\n",
       "      <td>6.095866</td>\n",
       "      <td>8.556494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.567103</td>\n",
       "      <td>0.755747</td>\n",
       "      <td>0.813093</td>\n",
       "      <td>0.711981</td>\n",
       "      <td>12.987207</td>\n",
       "      <td>8.692672</td>\n",
       "      <td>6.63119</td>\n",
       "      <td>9.437023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.482726</td>\n",
       "      <td>0.73124</td>\n",
       "      <td>0.787828</td>\n",
       "      <td>0.667264</td>\n",
       "      <td>14.197117</td>\n",
       "      <td>9.120146</td>\n",
       "      <td>7.067593</td>\n",
       "      <td>10.128285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.409226</td>\n",
       "      <td>0.711687</td>\n",
       "      <td>0.764263</td>\n",
       "      <td>0.628392</td>\n",
       "      <td>15.17147</td>\n",
       "      <td>9.44845</td>\n",
       "      <td>7.451604</td>\n",
       "      <td>10.690508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.347392</td>\n",
       "      <td>0.695034</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.592713</td>\n",
       "      <td>15.944273</td>\n",
       "      <td>9.719812</td>\n",
       "      <td>7.891768</td>\n",
       "      <td>11.185284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.294446</td>\n",
       "      <td>0.678729</td>\n",
       "      <td>0.699114</td>\n",
       "      <td>0.557429</td>\n",
       "      <td>16.577138</td>\n",
       "      <td>9.978492</td>\n",
       "      <td>8.422652</td>\n",
       "      <td>11.659427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.24924</td>\n",
       "      <td>0.658992</td>\n",
       "      <td>0.655026</td>\n",
       "      <td>0.521086</td>\n",
       "      <td>17.098908</td>\n",
       "      <td>10.283169</td>\n",
       "      <td>9.020686</td>\n",
       "      <td>12.134254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.208726</td>\n",
       "      <td>0.635246</td>\n",
       "      <td>0.604371</td>\n",
       "      <td>0.482781</td>\n",
       "      <td>17.55401</td>\n",
       "      <td>10.636914</td>\n",
       "      <td>9.663072</td>\n",
       "      <td>12.617999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.169681</td>\n",
       "      <td>0.606684</td>\n",
       "      <td>0.549729</td>\n",
       "      <td>0.442031</td>\n",
       "      <td>17.982879</td>\n",
       "      <td>11.04736</td>\n",
       "      <td>10.311799</td>\n",
       "      <td>13.114013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.128571</td>\n",
       "      <td>0.574983</td>\n",
       "      <td>0.495847</td>\n",
       "      <td>0.3998</td>\n",
       "      <td>18.084255</td>\n",
       "      <td>11.485706</td>\n",
       "      <td>10.91501</td>\n",
       "      <td>13.49499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.085603</td>\n",
       "      <td>0.541865</td>\n",
       "      <td>0.449301</td>\n",
       "      <td>0.358923</td>\n",
       "      <td>17.71062</td>\n",
       "      <td>11.927719</td>\n",
       "      <td>11.41207</td>\n",
       "      <td>13.68347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.041696</td>\n",
       "      <td>0.508866</td>\n",
       "      <td>0.412046</td>\n",
       "      <td>0.320869</td>\n",
       "      <td>17.518856</td>\n",
       "      <td>12.353295</td>\n",
       "      <td>11.796174</td>\n",
       "      <td>13.889442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.47789</td>\n",
       "      <td>0.382346</td>\n",
       "      <td>0.286778</td>\n",
       "      <td>17.602126</td>\n",
       "      <td>12.741481</td>\n",
       "      <td>12.095102</td>\n",
       "      <td>14.146236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.038741</td>\n",
       "      <td>0.449413</td>\n",
       "      <td>0.357134</td>\n",
       "      <td>0.255935</td>\n",
       "      <td>17.875203</td>\n",
       "      <td>13.088293</td>\n",
       "      <td>12.343579</td>\n",
       "      <td>14.435692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.074008</td>\n",
       "      <td>0.421271</td>\n",
       "      <td>0.334417</td>\n",
       "      <td>0.227227</td>\n",
       "      <td>17.816568</td>\n",
       "      <td>13.419739</td>\n",
       "      <td>12.563956</td>\n",
       "      <td>14.600088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.104703</td>\n",
       "      <td>0.390806</td>\n",
       "      <td>0.314172</td>\n",
       "      <td>0.200091</td>\n",
       "      <td>17.722212</td>\n",
       "      <td>13.769636</td>\n",
       "      <td>12.757211</td>\n",
       "      <td>14.749686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.131763</td>\n",
       "      <td>0.358081</td>\n",
       "      <td>0.295591</td>\n",
       "      <td>0.17397</td>\n",
       "      <td>17.672647</td>\n",
       "      <td>14.136636</td>\n",
       "      <td>12.932177</td>\n",
       "      <td>14.91382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.154913</td>\n",
       "      <td>0.323215</td>\n",
       "      <td>0.278234</td>\n",
       "      <td>0.148845</td>\n",
       "      <td>17.596949</td>\n",
       "      <td>14.516513</td>\n",
       "      <td>13.093196</td>\n",
       "      <td>15.068886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.174247</td>\n",
       "      <td>0.288066</td>\n",
       "      <td>0.263289</td>\n",
       "      <td>0.125703</td>\n",
       "      <td>17.564333</td>\n",
       "      <td>14.890866</td>\n",
       "      <td>13.230787</td>\n",
       "      <td>15.228662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.192042</td>\n",
       "      <td>0.25476</td>\n",
       "      <td>0.251705</td>\n",
       "      <td>0.104808</td>\n",
       "      <td>17.589256</td>\n",
       "      <td>15.236036</td>\n",
       "      <td>13.337463</td>\n",
       "      <td>15.387585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.209344</td>\n",
       "      <td>0.226637</td>\n",
       "      <td>0.243727</td>\n",
       "      <td>0.087007</td>\n",
       "      <td>17.477804</td>\n",
       "      <td>15.520681</td>\n",
       "      <td>13.41174</td>\n",
       "      <td>15.470075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.22607</td>\n",
       "      <td>0.2043</td>\n",
       "      <td>0.238957</td>\n",
       "      <td>0.072396</td>\n",
       "      <td>17.365369</td>\n",
       "      <td>15.745133</td>\n",
       "      <td>13.457463</td>\n",
       "      <td>15.522655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.243426</td>\n",
       "      <td>0.187959</td>\n",
       "      <td>0.235981</td>\n",
       "      <td>0.060171</td>\n",
       "      <td>17.315849</td>\n",
       "      <td>15.907705</td>\n",
       "      <td>13.486652</td>\n",
       "      <td>15.570069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.260335</td>\n",
       "      <td>0.176097</td>\n",
       "      <td>0.234144</td>\n",
       "      <td>0.049968</td>\n",
       "      <td>17.263751</td>\n",
       "      <td>16.024444</td>\n",
       "      <td>13.506045</td>\n",
       "      <td>15.59808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.275543</td>\n",
       "      <td>0.16694</td>\n",
       "      <td>0.232508</td>\n",
       "      <td>0.041301</td>\n",
       "      <td>17.201108</td>\n",
       "      <td>16.111698</td>\n",
       "      <td>13.524061</td>\n",
       "      <td>15.612289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.289331</td>\n",
       "      <td>0.159628</td>\n",
       "      <td>0.230951</td>\n",
       "      <td>0.03375</td>\n",
       "      <td>17.25278</td>\n",
       "      <td>16.180629</td>\n",
       "      <td>13.541975</td>\n",
       "      <td>15.658461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.302172</td>\n",
       "      <td>0.153639</td>\n",
       "      <td>0.22863</td>\n",
       "      <td>0.026699</td>\n",
       "      <td>17.361106</td>\n",
       "      <td>16.237553</td>\n",
       "      <td>13.5662</td>\n",
       "      <td>15.72162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.315674</td>\n",
       "      <td>0.148311</td>\n",
       "      <td>0.226104</td>\n",
       "      <td>0.019581</td>\n",
       "      <td>17.476081</td>\n",
       "      <td>16.28852</td>\n",
       "      <td>13.591873</td>\n",
       "      <td>15.785491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.076348</td>\n",
       "      <td>0.465385</td>\n",
       "      <td>0.464685</td>\n",
       "      <td>0.335472</td>\n",
       "      <td>16.30427</td>\n",
       "      <td>12.549258</td>\n",
       "      <td>10.904594</td>\n",
       "      <td>13.252707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TT-3061-3 TT-3061-5 LT-3061-2      mean  TT-3061-3  TT-3061-5  \\\n",
       "index        R2        R2        R2        R2      nRMSE      nRMSE   \n",
       "0      0.866964  0.864255  0.911928  0.881049   7.195307   6.478311   \n",
       "1       0.76892  0.823652  0.872457  0.821677   9.485051   7.384375   \n",
       "2      0.662352  0.787553  0.841929  0.763945  11.467871   8.105745   \n",
       "3      0.567103  0.755747  0.813093  0.711981  12.987207   8.692672   \n",
       "4      0.482726   0.73124  0.787828  0.667264  14.197117   9.120146   \n",
       "5      0.409226  0.711687  0.764263  0.628392   15.17147    9.44845   \n",
       "6      0.347392  0.695034  0.735714  0.592713  15.944273   9.719812   \n",
       "7      0.294446  0.678729  0.699114  0.557429  16.577138   9.978492   \n",
       "8       0.24924  0.658992  0.655026  0.521086  17.098908  10.283169   \n",
       "9      0.208726  0.635246  0.604371  0.482781   17.55401  10.636914   \n",
       "10     0.169681  0.606684  0.549729  0.442031  17.982879   11.04736   \n",
       "11     0.128571  0.574983  0.495847    0.3998  18.084255  11.485706   \n",
       "12     0.085603  0.541865  0.449301  0.358923   17.71062  11.927719   \n",
       "13     0.041696  0.508866  0.412046  0.320869  17.518856  12.353295   \n",
       "14     0.000098   0.47789  0.382346  0.286778  17.602126  12.741481   \n",
       "15    -0.038741  0.449413  0.357134  0.255935  17.875203  13.088293   \n",
       "16    -0.074008  0.421271  0.334417  0.227227  17.816568  13.419739   \n",
       "17    -0.104703  0.390806  0.314172  0.200091  17.722212  13.769636   \n",
       "18    -0.131763  0.358081  0.295591   0.17397  17.672647  14.136636   \n",
       "19    -0.154913  0.323215  0.278234  0.148845  17.596949  14.516513   \n",
       "20    -0.174247  0.288066  0.263289  0.125703  17.564333  14.890866   \n",
       "21    -0.192042   0.25476  0.251705  0.104808  17.589256  15.236036   \n",
       "22    -0.209344  0.226637  0.243727  0.087007  17.477804  15.520681   \n",
       "23     -0.22607    0.2043  0.238957  0.072396  17.365369  15.745133   \n",
       "24    -0.243426  0.187959  0.235981  0.060171  17.315849  15.907705   \n",
       "25    -0.260335  0.176097  0.234144  0.049968  17.263751  16.024444   \n",
       "26    -0.275543   0.16694  0.232508  0.041301  17.201108  16.111698   \n",
       "27    -0.289331  0.159628  0.230951   0.03375   17.25278  16.180629   \n",
       "28    -0.302172  0.153639   0.22863  0.026699  17.361106  16.237553   \n",
       "29    -0.315674  0.148311  0.226104  0.019581  17.476081   16.28852   \n",
       "mean   0.076348  0.465385  0.464685  0.335472   16.30427  12.549258   \n",
       "\n",
       "       LT-3061-2       mean  \n",
       "index      nRMSE      nRMSE  \n",
       "0       4.545779   6.073132  \n",
       "1       5.473092   7.447506  \n",
       "2       6.095866   8.556494  \n",
       "3        6.63119   9.437023  \n",
       "4       7.067593  10.128285  \n",
       "5       7.451604  10.690508  \n",
       "6       7.891768  11.185284  \n",
       "7       8.422652  11.659427  \n",
       "8       9.020686  12.134254  \n",
       "9       9.663072  12.617999  \n",
       "10     10.311799  13.114013  \n",
       "11      10.91501   13.49499  \n",
       "12      11.41207   13.68347  \n",
       "13     11.796174  13.889442  \n",
       "14     12.095102  14.146236  \n",
       "15     12.343579  14.435692  \n",
       "16     12.563956  14.600088  \n",
       "17     12.757211  14.749686  \n",
       "18     12.932177   14.91382  \n",
       "19     13.093196  15.068886  \n",
       "20     13.230787  15.228662  \n",
       "21     13.337463  15.387585  \n",
       "22      13.41174  15.470075  \n",
       "23     13.457463  15.522655  \n",
       "24     13.486652  15.570069  \n",
       "25     13.506045   15.59808  \n",
       "26     13.524061  15.612289  \n",
       "27     13.541975  15.658461  \n",
       "28       13.5662   15.72162  \n",
       "29     13.591873  15.785491  \n",
       "mean   10.904594  13.252707  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_list = cts_list\n",
    "\n",
    "# history size and future size\n",
    "history_list = [10, 20, 30, 40]\n",
    "future_list = [10, 20, 30]\n",
    "step = 1\n",
    "\n",
    "# variable selection\n",
    "history_var = process_var\n",
    "future_var = output_var\n",
    "\n",
    "history_num = len(history_var)\n",
    "future_num = len(future_var)\n",
    "\n",
    "# supervised attention factor\n",
    "delta = 1\n",
    "att_type = 'linear'\n",
    "        \n",
    "# test data split        \n",
    "test_size = 0.2\n",
    "test_num = -1\n",
    "\n",
    "# model structure\n",
    "num_layers = 1\n",
    "num_neurons = 50\n",
    "dense_layers = 1\n",
    "dense_neurons = 50\n",
    "model_type = 'datt_seq2seq_gru'\n",
    "\n",
    "for history_size in history_list:\n",
    "    for future_size in future_list:\n",
    "        print(f\"history size: {history_size}\")\n",
    "        print(f\"future size: {future_size}\")\n",
    "        history_series = []\n",
    "        future_series = []\n",
    "\n",
    "        # data to series\n",
    "        for i in range(len(target_list)):\n",
    "            history, future = data2series(target_list[i], history_size, history_var, future_size, future_var,\n",
    "                                        step, start_idx=0, end_idx=None)\n",
    "            if not i:\n",
    "                history_series = history\n",
    "                future_series = future\n",
    "            else:\n",
    "                history_series = np.concatenate([history_series, history], axis=0)\n",
    "                future_series = np.concatenate([future_series, future], axis=0)\n",
    "        \n",
    "        factor = rnn.super_attention(delta, future_size, future_num, att_type)\n",
    "        # Dual-attention Seq2Seq model\n",
    "        DATT_seq2seq_GRU = rnn.RNN(history_series, history_var, future_series, future_var)\n",
    "        # TT split\n",
    "        DATT_seq2seq_GRU.train_test(test_size=test_size, test_num=test_num)\n",
    "        # TV split\n",
    "        valid_size = DATT_seq2seq_GRU.history_test.shape[0]/DATT_seq2seq_GRU.history_train.shape[0]\n",
    "        DATT_seq2seq_GRU.train_valid(valid_size=valid_size)\n",
    "        # scaling\n",
    "        DATT_seq2seq_GRU.scaling()\n",
    "        # modeling\n",
    "        DATT_seq2seq_GRU.build_model(num_layers=num_layers, num_neurons=num_neurons, dense_layers=dense_layers, dense_neurons=dense_neurons, model_type=model_type, factor=factor)\n",
    "        # training\n",
    "        model_num = 'test'\n",
    "        model_name = f\"{history_size}_{future_size}_{num_layers}_{num_neurons}_{dense_layers}_{dense_neurons}_{model_type}_{model_num}\"\n",
    "        if not exists(\"./model\", model_name, 'model'):\n",
    "            DATT_seq2seq_GRU.train()\n",
    "            DATT_seq2seq_GRU.save_model(f\"./model/{model_name}\")\n",
    "        else:\n",
    "            DATT_seq2seq_GRU.model = loadfile(\"./model\", model_name, 'model')\n",
    "        # test\n",
    "        test_result = DATT_seq2seq_GRU.test()\n",
    "        print(\"end training\")\n",
    "        \n",
    "print('end opitmization')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3cf56d631085086b1721b0064da1454dfad7e026414ec6e1cab7db73e55aa6df"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
